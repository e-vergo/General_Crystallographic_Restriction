<!DOCTYPE html>
<html lang="en">
<head>
<script>
  MathJax = { 
    tex: {
		    inlineMath: [['$','$'], ['\\(','\\)']]
	} }
</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
<meta name="generator" content="plasTeX" />
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>The Crystallographic Restriction Theorem</title>
<link rel="next" href="sect0006.html" title="Appendix" />
<link rel="prev" href="sect0004.html" title="Companion Matrices" />
<link rel="up" href="index.html" title="Crystallographic Restriction Theorem" />
<link rel="stylesheet" href="styles/theme-blue.css" />
<link rel="stylesheet" href="styles/showmore.css" />
<link rel="stylesheet" href="styles/blueprint.css" />
<link rel="stylesheet" href="styles/amsthm.css" />
<link rel="stylesheet" href="styles/style.css" />
</head>

<body>
<header>
<svg  id="toc-toggle" class="icon icon-list-numbered "><use xlink:href="symbol-defs.svg#icon-list-numbered"></use></svg>
<h1 id="doc_title"><a href="index.html">Crystallographic Restriction Theorem</a></h1>
</header>

<div class="wrapper">
<nav class="toc">
<ul class="sub-toc-0">
<li class="">
  <a href="sect0001.html"><span class="toc_ref">1</span> <span class="toc_entry">Introduction</span></a>
 </li>
<li class="">
  <a href="sect0002.html"><span class="toc_ref">2</span> <span class="toc_entry">The Psi Function</span></a>
 </li>
<li class="">
  <a href="sect0003.html"><span class="toc_ref">3</span> <span class="toc_entry">Integer Matrix Orders</span></a>
 </li>
<li class="">
  <a href="sect0004.html"><span class="toc_ref">4</span> <span class="toc_entry">Companion Matrices</span></a>
 </li>
<li class=" active current">
  <a href="sect0005.html"><span class="toc_ref">5</span> <span class="toc_entry">The Crystallographic Restriction Theorem</span></a>
 </li>
<li class="">
  <a href="sect0006.html"><span class="toc_ref">A</span> <span class="toc_entry">Appendix</span></a>
 </li>
<li ><a href="dep_graph_document.html">Dependency graph</a></li>
</ul>
</nav>

<div class="content">
<div class="content-wrapper">


<div class="main-text">
<h1 id="a0000000006">5 The Crystallographic Restriction Theorem</h1>
<p>The proof splits into two directions: showing \(\psi (m) \leq N\) is necessary (forward) and sufficient (backward) for \(m \in \mathrm{Ord}_N\). </p>
<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:pow-eq-one-of-minpoly-dvd">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.1</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#lem:pow-eq-one-of-minpoly-dvd">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000044"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Matrix.pow_eq_one_of_minpoly_dvd_X_pow_sub_one" class="lean_decl">Matrix.pow_eq_one_of_minpoly_dvd_X_pow_sub_one</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(\mu _A \mid X^k - 1\), then \(A^k = I\).  </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000044">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>The polynomial \(X^k - 1\) annihilates \(A\) (since the minimal polynomial does), meaning \(A^k - I = 0\). Transfer this identity from \(\mathbb {Q}\) back to \(\mathbb {Z}\) via the injectivity of \(\mathbb {Z} \to \mathbb {Q}\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> pow_eq_one_of_minpoly_dvd_X_pow_sub_one <span class="lean-bracket">{</span>N : ℕ<span class="lean-bracket">}</span> <span class="lean-bracket">(</span>A : Matrix <span class="lean-bracket">(</span>Fin N<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>Fin N<span class="lean-bracket">)</span> ℤ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>k : ℕ<span class="lean-bracket">)</span>
    <span class="lean-bracket">(</span>hdvd : minpoly ℚ <span class="lean-bracket">(</span>A.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span><span class="lean-bracket">)</span> ∣ X ^ k - <span class="lean-number">1</span><span class="lean-bracket">)</span> : A ^ k = <span class="lean-number">1</span> :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="The `let` tactic is for adding definitions to the local context of the main goal.
The definition can be unfolded, unlike definitions introduced by `have`.

* `let x : t := e` adds the definition `x : t := e` if `e` is a term of type `t`.
* `let x := e` uses the type of `e` for `t`.
* `let : t := e` and `let := e` use `this` for the name of the hypothesis.
* `let pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that let only one applicable constructor.
  For example, given `p : α × β × γ`, `let ⟨x, y, z⟩ := p` produces the
  local variables `x : α`, `y : β`, and `z : γ`.
* The syntax `let (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `let` term.

## Properties and relations

* Unlike `have`, it is possible to unfold definitions introduced using `let`, using tactics
  such as `simp`, `dsimp`, `unfold`, and `subst`.
* The `clear_value` tactic turns a `let` definition into a `have` definition after the fact.
  The tactic might fail if the local context depends on the value of the variable.
* The `let` tactic is preferred for data (non-propositions).
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
">let</span> A_Q := A.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span>
  <span class="lean-comment">-- If minpoly | X^k - <span class="lean-number">1</span>, then aeval A_Q <span class="lean-bracket">(</span>X^k - <span class="lean-number">1</span><span class="lean-bracket">)</span> = <span class="lean-number">0</span></span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> haeval : aeval A_Q <span class="lean-bracket">(</span>X ^ k - <span class="lean-number">1</span> : ℚ<span class="lean-bracket">[</span>X<span class="lean-bracket">]</span><span class="lean-bracket">)</span> = <span class="lean-number">0</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-bracket">⟨</span>q, hq<span class="lean-bracket">⟩</span> := hdvd
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>hq, map_mul, minpoly.aeval, zero_mul<span class="lean-bracket">]</span>
  <span class="lean-comment">-- This means A_Q^k = <span class="lean-number">1</span></span>
  <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket">[</span>map_sub, map_pow, aeval_X, map_one, sub_eq_zero<span class="lean-bracket">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> haeval
  <span class="lean-comment">-- Transfer back to A via injectivity</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hinj := Crystallographic.Matrix.map_algebraMap_int_injective N
  <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> hinj
  <span class="lean-keyword" data-docs="* `change tgt&#x27;` will change the goal from `tgt` to `tgt&#x27;`,
  assuming these are definitionally equal.
* `change t&#x27; at h` will change hypothesis `h : t` to have type `t&#x27;`, assuming
  assuming `t` and `t&#x27;` are definitionally equal.
">change</span> <span class="lean-bracket">(</span>A ^ k<span class="lean-bracket">)</span>.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span> =
    <span class="lean-bracket">(</span><span class="lean-number">1</span> : Matrix <span class="lean-bracket">(</span>Fin N<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>Fin N<span class="lean-bracket">)</span> ℤ<span class="lean-bracket">)</span>.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>Matrix.map_pow, Matrix.map_one <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>map_zero _<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>map_one _<span class="lean-bracket">)</span><span class="lean-bracket">]</span>
  <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> haeval</code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Forward.lean#L48-L71" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:pow-eq-one-of-minpoly-dvd');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:minpoly-dvd-X-pow-sub-one">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.2</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#lem:minpoly-dvd-X-pow-sub-one">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000045"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Matrix.minpoly_dvd_X_pow_sub_one_of_pow_eq_one" class="lean_decl">Matrix.minpoly_dvd_X_pow_sub_one_of_pow_eq_one</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(A^m = I\), then \(\mu _A \mid X^m - 1\).  </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000045">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>The polynomial \(X^m - 1\) annihilates \(A\) since \((A_{\mathbb {Q}})^m - I = 0\). The minimal polynomial divides any annihilating polynomial by definition. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> minpoly_dvd_X_pow_sub_one_of_pow_eq_one <span class="lean-bracket">{</span>N : ℕ<span class="lean-bracket">}</span> <span class="lean-bracket">(</span>A : Matrix <span class="lean-bracket">(</span>Fin N<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>Fin N<span class="lean-bracket">)</span> ℤ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>m : ℕ<span class="lean-bracket">)</span>
    <span class="lean-bracket">(</span>hpow : A ^ m = <span class="lean-number">1</span><span class="lean-bracket">)</span> : minpoly ℚ <span class="lean-bracket">(</span>A.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span><span class="lean-bracket">)</span> ∣ X ^ m - <span class="lean-number">1</span> :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> minpoly.dvd
  <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket">[</span>map_sub, map_pow, aeval_X, map_one<span class="lean-bracket">]</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span><span class="lean-operator">←</span> Matrix.map_pow, hpow,
    Matrix.map_one <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>map_zero _<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>map_one _<span class="lean-bracket">)</span>, sub_self<span class="lean-bracket">]</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Forward.lean#L73-L85" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:minpoly-dvd-X-pow-sub-one');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:cyclotomic-finset-product-dvd">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.3</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#lem:cyclotomic-finset-product-dvd">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000046"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.cyclotomic_finset_product_dvd" class="lean_decl">Crystallographic.cyclotomic_finset_product_dvd</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(\Phi _d \mid f\) for all \(d \in S\), then \(\prod _{d \in S} \Phi _d \mid f\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000046">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>By induction on \(S\). The empty product divides everything. For the insert case, use that cyclotomic polynomials with distinct indices are coprime over \(\mathbb {Q}\), so \(\Phi _d\) is coprime to \(\prod _{x \in s} \Phi _x\) when \(d \notin s\). Then apply coprime divisibility: if \(a, b\) are coprime and both divide \(f\), then \(ab \mid f\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> cyclotomic_finset_product_dvd <span class="lean-bracket">{</span>target : ℚ<span class="lean-bracket">[</span>X<span class="lean-bracket">]</span><span class="lean-bracket">}</span> <span class="lean-bracket">(</span>S : Finset ℕ<span class="lean-bracket">)</span>
    <span class="lean-bracket">(</span>hdvd_each : <span class="lean-operator">∀</span> d <span class="lean-operator">∈</span> S, cyclotomic d ℚ ∣ target<span class="lean-bracket">)</span> :
    <span class="lean-bracket">(</span><span class="lean-operator">∏</span> d <span class="lean-operator">∈</span> S, cyclotomic d ℚ<span class="lean-bracket">)</span> ∣ target :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
">induction</span> S <span class="lean-keyword">using</span> Finset.induction <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
">with</span>
  | empty =&gt; <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket">[</span>Finset.prod_empty, one_dvd<span class="lean-bracket">]</span>
  | @insert d s hd_notin IH =&gt;
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>Finset.prod_insert hd_notin<span class="lean-bracket">]</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hdvd_d : cyclotomic d ℚ ∣ target := hdvd_each d <span class="lean-bracket">(</span>Finset.mem_insert_self d s<span class="lean-bracket">)</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hdvd_prod : <span class="lean-bracket">(</span><span class="lean-operator">∏</span> x <span class="lean-operator">∈</span> s, cyclotomic x ℚ<span class="lean-bracket">)</span> ∣ target :=
        IH <span class="lean-bracket">(</span><span class="lean-keyword">fun</span> x hx =&gt; hdvd_each x <span class="lean-bracket">(</span>Finset.mem_insert_of_mem hx<span class="lean-bracket">)</span><span class="lean-bracket">)</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hcop : IsCoprime <span class="lean-bracket">(</span>cyclotomic d ℚ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span><span class="lean-operator">∏</span> x <span class="lean-operator">∈</span> s, cyclotomic x ℚ<span class="lean-bracket">)</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
      <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> IsCoprime.prod_right
      <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> x hx
      <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> cyclotomic.isCoprime_rat <span class="lean-bracket">(</span><span class="lean-keyword">fun</span> heq =&gt; hd_notin <span class="lean-bracket">(</span>heq ▸ hx<span class="lean-bracket">)</span><span class="lean-bracket">)</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> hcop.mul_dvd hdvd_d hdvd_prod</code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Forward.lean#L93-L115" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:cyclotomic-finset-product-dvd');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:minpoly-dvd-prod-cyclotomic">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.4</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#lem:minpoly-dvd-prod-cyclotomic">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000047"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0005.html#lem:cyclotomic-finset-product-dvd">Theorem 5.0.3</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.minpoly_dvd_prod_cyclotomic_of_dvd_X_pow_sub_one" class="lean_decl">Crystallographic.minpoly_dvd_prod_cyclotomic_of_dvd_X_pow_sub_one</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(\mu _A \mid X^m - 1\) and \(S = \{ d \mid m : \Phi _d \mid \mu _A\} \), then \(\mu _A \mid \prod _{d \in S} \Phi _d\).  </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000047">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>Split \(X^m - 1 = (\prod _{d \in S} \Phi _d) \cdot (\prod _{d \notin S} \Phi _d)\). Since \(\Phi _d\) is irreducible and does not divide \(\mu _A\) for \(d \notin S\), we have \(\gcd (\mu _A, \Phi _d) = 1\). Thus \(\mu _A\) is coprime to \(\prod _{d \notin S} \Phi _d\). Since \(\mu _A \mid X^m - 1\), it must divide \(\prod _{d \in S} \Phi _d\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> minpoly_dvd_prod_cyclotomic_of_dvd_X_pow_sub_one <span class="lean-bracket">{</span>N : ℕ<span class="lean-bracket">}</span> <span class="lean-bracket">[</span>NeZero N<span class="lean-bracket">]</span>
    <span class="lean-bracket">(</span>A : Matrix <span class="lean-bracket">(</span>Fin N<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>Fin N<span class="lean-bracket">)</span> ℤ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>m : ℕ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hm : <span class="lean-number">0</span> &lt; m<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>S : Finset ℕ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hS_sub : S <span class="lean-operator">⊆</span> m.divisors<span class="lean-bracket">)</span>
    <span class="lean-bracket">(</span>hS_def : <span class="lean-operator">∀</span> d <span class="lean-operator">∈</span> m.divisors, d <span class="lean-operator">∈</span> S <span class="lean-operator">↔</span> cyclotomic d ℚ ∣ minpoly ℚ <span class="lean-bracket">(</span>A.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span><span class="lean-bracket">)</span><span class="lean-bracket">)</span>
    <span class="lean-bracket">(</span>hminpoly_dvd : minpoly ℚ <span class="lean-bracket">(</span>A.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span><span class="lean-bracket">)</span> ∣ X ^ m - <span class="lean-number">1</span><span class="lean-bracket">)</span> :
    minpoly ℚ <span class="lean-bracket">(</span>A.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span><span class="lean-bracket">)</span> ∣ <span class="lean-operator">∏</span> d <span class="lean-operator">∈</span> S, cyclotomic d ℚ :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="The `let` tactic is for adding definitions to the local context of the main goal.
The definition can be unfolded, unlike definitions introduced by `have`.

* `let x : t := e` adds the definition `x : t := e` if `e` is a term of type `t`.
* `let x := e` uses the type of `e` for `t`.
* `let : t := e` and `let := e` use `this` for the name of the hypothesis.
* `let pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that let only one applicable constructor.
  For example, given `p : α × β × γ`, `let ⟨x, y, z⟩ := p` produces the
  local variables `x : α`, `y : β`, and `z : γ`.
* The syntax `let (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `let` term.

## Properties and relations

* Unlike `have`, it is possible to unfold definitions introduced using `let`, using tactics
  such as `simp`, `dsimp`, `unfold`, and `subst`.
* The `clear_value` tactic turns a `let` definition into a `have` definition after the fact.
  The tactic might fail if the local context depends on the value of the variable.
* The `let` tactic is preferred for data (non-propositions).
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
">let</span> A_Q := A.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span>
  <span class="lean-comment">-- Key: <span class="lean-bracket">{</span>x <span class="lean-operator">∈</span> m.divisors | x <span class="lean-operator">∈</span> S<span class="lean-bracket">}</span> = S since S <span class="lean-operator">⊆</span> m.divisors</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hS_eq : m.divisors.filter <span class="lean-bracket">(</span><span class="lean-operator">·</span> <span class="lean-operator">∈</span> S<span class="lean-bracket">)</span> = S := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="Applies extensionality lemmas that are registered with the `@[ext]` attribute.
* `ext pat*` applies extensionality theorems as much as possible,
  using the patterns `pat*` to introduce the variables in extensionality theorems using `rintro`.
  For example, the patterns are used to name the variables introduced by lemmas such as `funext`.
* Without patterns,`ext` applies extensionality lemmas as much
  as possible but introduces anonymous hypotheses whenever needed.
* `ext pat* : n` applies ext theorems only up to depth `n`.

The `ext1 pat*` tactic is like `ext pat*` except that it only applies a single extensionality theorem.

Unused patterns will generate warning.
Patterns that don&#x27;t match the variables will typically result in the introduction of anonymous hypotheses.
">ext</span> d
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket">[</span>Finset.mem_filter<span class="lean-bracket">]</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-bracket">⟨</span><span class="lean-keyword">fun</span> <span class="lean-bracket">⟨</span>_, hd<span class="lean-bracket">⟩</span> =&gt; hd, <span class="lean-keyword">fun</span> hd =&gt; <span class="lean-bracket">⟨</span>hS_sub hd, hd<span class="lean-bracket">⟩</span><span class="lean-bracket">⟩</span>
  <span class="lean-comment">-- minpoly is coprime to the product of cyclotomics NOT in S</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hcoprime_with_complement : IsCoprime <span class="lean-bracket">(</span>minpoly ℚ A_Q<span class="lean-bracket">)</span>
      <span class="lean-bracket">(</span><span class="lean-operator">∏</span> d <span class="lean-operator">∈</span> m.divisors.filter <span class="lean-bracket">(</span><span class="lean-operator">·</span> <span class="lean-operator">∉</span> S<span class="lean-bracket">)</span>, cyclotomic d ℚ<span class="lean-bracket">)</span> :=
    IsCoprime.prod_right <span class="lean-keyword">fun</span> d hd =&gt; <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hd_div := <span class="lean-bracket">(</span>Finset.mem_filter.mp hd<span class="lean-bracket">)</span>.<span class="lean-number">1</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hd_not_in_S := <span class="lean-bracket">(</span>Finset.mem_filter.mp hd<span class="lean-bracket">)</span>.<span class="lean-number">2</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hndvd : <span class="lean-operator">¬</span>cyclotomic d ℚ ∣ minpoly ℚ A_Q := <span class="lean-keyword">fun</span> hdvd =&gt;
        hd_not_in_S <span class="lean-bracket">(</span><span class="lean-bracket">(</span>hS_def d hd_div<span class="lean-bracket">)</span>.mpr hdvd<span class="lean-bracket">)</span>
      <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-bracket">(</span>cyclotomic_coprime_minpoly_of_not_mem A d <span class="lean-bracket">(</span>Nat.pos_of_mem_divisors hd_div<span class="lean-bracket">)</span> hndvd<span class="lean-bracket">)</span>.symm
  <span class="lean-comment">-- Split X^m - <span class="lean-number">1</span> = <span class="lean-bracket">(</span><span class="lean-operator">∏</span>_<span class="lean-bracket">{</span>d<span class="lean-operator">∈</span>S<span class="lean-bracket">}</span> Φ_d<span class="lean-bracket">)</span> * <span class="lean-bracket">(</span><span class="lean-operator">∏</span>_<span class="lean-bracket">{</span>d<span class="lean-operator">∉</span>S<span class="lean-bracket">}</span> Φ_d<span class="lean-bracket">)</span></span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hprod_split : <span class="lean-operator">∏</span> d <span class="lean-operator">∈</span> m.divisors, cyclotomic d ℚ =
      <span class="lean-bracket">(</span><span class="lean-operator">∏</span> d <span class="lean-operator">∈</span> S, cyclotomic d ℚ<span class="lean-bracket">)</span> * <span class="lean-bracket">(</span><span class="lean-operator">∏</span> d <span class="lean-operator">∈</span> m.divisors.filter <span class="lean-bracket">(</span><span class="lean-operator">·</span> <span class="lean-operator">∉</span> S<span class="lean-bracket">)</span>, cyclotomic d ℚ<span class="lean-bracket">)</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span><span class="lean-operator">←</span> Finset.prod_filter_mul_prod_filter_not m.divisors <span class="lean-bracket">(</span><span class="lean-operator">·</span> <span class="lean-operator">∈</span> S<span class="lean-bracket">)</span>, hS_eq<span class="lean-bracket">]</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span><span class="lean-operator">←</span> prod_cyclotomic_eq_X_pow_sub_one hm, hprod_split<span class="lean-bracket">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hminpoly_dvd
  <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> hcoprime_with_complement.dvd_of_dvd_mul_right hminpoly_dvd</code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Forward.lean#L125-L165" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:minpoly-dvd-prod-cyclotomic');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:minpoly-eq-prod-cyclotomic">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.5</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#lem:minpoly-eq-prod-cyclotomic">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000048"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0005.html#lem:minpoly-dvd-prod-cyclotomic">Theorem 5.0.4</a></li>
          
          <li><a href="sect0005.html#lem:cyclotomic-finset-product-dvd">Theorem 5.0.3</a></li>
          
          <li><a href="sect0005.html#lem:cyclotomic-finset-product-dvd">Theorem 5.0.3</a></li>
          
          <li><a href="sect0005.html#lem:minpoly-dvd-prod-cyclotomic">Theorem 5.0.4</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.minpoly_eq_prod_cyclotomic_of_dvd_X_pow_sub_one" class="lean_decl">Crystallographic.minpoly_eq_prod_cyclotomic_of_dvd_X_pow_sub_one</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(\mu _A \mid X^m - 1\), then there exists \(S \subseteq \mathrm{divisors}(m)\) such that \(\mu _A = \prod _{d \in S} \Phi _d\).  </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000048">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> Let \(S = \{ d \mid m : \Phi _d \mid \mu _A\} \). By the previous lemma, \(\mu _A \mid \prod _{d \in S} \Phi _d\). Conversely, by definition of \(S\), each \(\Phi _d\) for \(d \in S\) divides \(\mu _A\), so their coprime product divides \(\mu _A\). Mutual divisibility of monic polynomials implies equality. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> minpoly_eq_prod_cyclotomic_of_dvd_X_pow_sub_one <span class="lean-bracket">{</span>N : ℕ<span class="lean-bracket">}</span> <span class="lean-bracket">[</span>NeZero N<span class="lean-bracket">]</span>
    <span class="lean-bracket">(</span>A : Matrix <span class="lean-bracket">(</span>Fin N<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>Fin N<span class="lean-bracket">)</span> ℤ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>m : ℕ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hm : <span class="lean-number">0</span> &lt; m<span class="lean-bracket">)</span>
    <span class="lean-bracket">(</span>hminpoly_dvd : minpoly ℚ <span class="lean-bracket">(</span>A.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span><span class="lean-bracket">)</span> ∣ X ^ m - <span class="lean-number">1</span><span class="lean-bracket">)</span> :
    <span class="lean-operator">∃</span> S : Finset ℕ, <span class="lean-bracket">(</span><span class="lean-operator">∀</span> d <span class="lean-operator">∈</span> S, d ∣ m<span class="lean-bracket">)</span> <span class="lean-operator">∧</span>
      minpoly ℚ <span class="lean-bracket">(</span>A.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span><span class="lean-bracket">)</span> = <span class="lean-operator">∏</span> d <span class="lean-operator">∈</span> S, cyclotomic d ℚ :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="`classical tacs` runs `tacs` in a scope where `Classical.propDecidable` is a low priority
local instance.

Note that `classical` is a scoping tactic: it adds the instance only within the
scope of the tactic.
">classical</span>
  <span class="lean-keyword" data-docs="The `let` tactic is for adding definitions to the local context of the main goal.
The definition can be unfolded, unlike definitions introduced by `have`.

* `let x : t := e` adds the definition `x : t := e` if `e` is a term of type `t`.
* `let x := e` uses the type of `e` for `t`.
* `let : t := e` and `let := e` use `this` for the name of the hypothesis.
* `let pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that let only one applicable constructor.
  For example, given `p : α × β × γ`, `let ⟨x, y, z⟩ := p` produces the
  local variables `x : α`, `y : β`, and `z : γ`.
* The syntax `let (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `let` term.

## Properties and relations

* Unlike `have`, it is possible to unfold definitions introduced using `let`, using tactics
  such as `simp`, `dsimp`, `unfold`, and `subst`.
* The `clear_value` tactic turns a `let` definition into a `have` definition after the fact.
  The tactic might fail if the local context depends on the value of the variable.
* The `let` tactic is preferred for data (non-propositions).
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
">let</span> A_Q := A.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span>
  <span class="lean-keyword" data-docs="The `let` tactic is for adding definitions to the local context of the main goal.
The definition can be unfolded, unlike definitions introduced by `have`.

* `let x : t := e` adds the definition `x : t := e` if `e` is a term of type `t`.
* `let x := e` uses the type of `e` for `t`.
* `let : t := e` and `let := e` use `this` for the name of the hypothesis.
* `let pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that let only one applicable constructor.
  For example, given `p : α × β × γ`, `let ⟨x, y, z⟩ := p` produces the
  local variables `x : α`, `y : β`, and `z : γ`.
* The syntax `let (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `let` term.

## Properties and relations

* Unlike `have`, it is possible to unfold definitions introduced using `let`, using tactics
  such as `simp`, `dsimp`, `unfold`, and `subst`.
* The `clear_value` tactic turns a `let` definition into a `have` definition after the fact.
  The tactic might fail if the local context depends on the value of the variable.
* The `let` tactic is preferred for data (non-propositions).
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
">let</span> S := m.divisors.filter <span class="lean-bracket">(</span><span class="lean-keyword">fun</span> d =&gt; cyclotomic d ℚ ∣ minpoly ℚ A_Q<span class="lean-bracket">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hS_sub : S <span class="lean-operator">⊆</span> m.divisors := Finset.filter_subset _ _
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hS_dvd : <span class="lean-operator">∀</span> d <span class="lean-operator">∈</span> S, d ∣ m := <span class="lean-keyword">fun</span> d hd =&gt;
    <span class="lean-bracket">(</span>Nat.mem_divisors.mp <span class="lean-bracket">(</span>Finset.mem_filter.mp hd<span class="lean-bracket">)</span>.<span class="lean-number">1</span><span class="lean-bracket">)</span>.<span class="lean-number">1</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hS_def : <span class="lean-operator">∀</span> d <span class="lean-operator">∈</span> m.divisors, d <span class="lean-operator">∈</span> S <span class="lean-operator">↔</span> cyclotomic d ℚ ∣ minpoly ℚ A_Q := <span class="lean-keyword">fun</span> d hd =&gt;
    <span class="lean-bracket">⟨</span><span class="lean-keyword">fun</span> hS =&gt; <span class="lean-bracket">(</span>Finset.mem_filter.mp hS<span class="lean-bracket">)</span>.<span class="lean-number">2</span>, <span class="lean-keyword">fun</span> hdvd =&gt; Finset.mem_filter.mpr <span class="lean-bracket">⟨</span>hd, hdvd<span class="lean-bracket">⟩</span><span class="lean-bracket">⟩</span>
  <span class="lean-comment">-- minpoly ∣ <span class="lean-operator">∏</span>_<span class="lean-bracket">{</span>d<span class="lean-operator">∈</span>S<span class="lean-bracket">}</span> Φ_d <span class="lean-bracket">(</span>by coprimality argument<span class="lean-bracket">)</span></span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hminpoly_dvd_prod : minpoly ℚ A_Q ∣ <span class="lean-operator">∏</span> d <span class="lean-operator">∈</span> S, cyclotomic d ℚ :=
    minpoly_dvd_prod_cyclotomic_of_dvd_X_pow_sub_one A m hm S hS_sub hS_def hminpoly_dvd
  <span class="lean-comment">-- <span class="lean-operator">∏</span>_<span class="lean-bracket">{</span>d<span class="lean-operator">∈</span>S<span class="lean-bracket">}</span> Φ_d ∣ minpoly <span class="lean-bracket">(</span>by definition of S<span class="lean-bracket">)</span></span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hprod_dvd_minpoly : <span class="lean-bracket">(</span><span class="lean-operator">∏</span> d <span class="lean-operator">∈</span> S, cyclotomic d ℚ<span class="lean-bracket">)</span> ∣ minpoly ℚ A_Q :=
    cyclotomic_finset_product_dvd S <span class="lean-bracket">(</span><span class="lean-keyword">fun</span> d hd =&gt; <span class="lean-bracket">(</span>Finset.mem_filter.mp hd<span class="lean-bracket">)</span>.<span class="lean-number">2</span><span class="lean-bracket">)</span>
  <span class="lean-comment">-- Equality by mutual divisibility of monic polynomials</span>
  <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-bracket">⟨</span>S, hS_dvd, Polynomial.eq_of_monic_of_associated
    <span class="lean-bracket">(</span>minpoly.monic <span class="lean-bracket">(</span>Matrix.isIntegral A_Q<span class="lean-bracket">)</span><span class="lean-bracket">)</span>
    <span class="lean-bracket">(</span>Polynomial.monic_prod_of_monic _ _ <span class="lean-bracket">(</span><span class="lean-keyword">fun</span> d _ =&gt; cyclotomic.monic d ℚ<span class="lean-bracket">)</span><span class="lean-bracket">)</span>
    <span class="lean-bracket">(</span>associated_of_dvd_dvd hminpoly_dvd_prod hprod_dvd_minpoly<span class="lean-bracket">)</span><span class="lean-bracket">⟩</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Forward.lean#L167-L201" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:minpoly-eq-prod-cyclotomic');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:cyclotomic-divisors-lcm-eq">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.6</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#lem:cyclotomic-divisors-lcm-eq">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000049"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0005.html#lem:minpoly-eq-prod-cyclotomic">Theorem 5.0.5</a></li>
          
          <li><a href="sect0005.html#lem:pow-eq-one-of-minpoly-dvd">Theorem 5.0.1</a></li>
          
          <li><a href="sect0005.html#lem:cyclotomic-finset-product-dvd">Theorem 5.0.3</a></li>
          
          <li><a href="sect0005.html#lem:pow-eq-one-of-minpoly-dvd">Theorem 5.0.1</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.cyclotomic_divisors_lcm_eq_of_orderOf" class="lean_decl">Crystallographic.cyclotomic_divisors_lcm_eq_of_orderOf</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(\mathrm{ord}(A) = m\) and \(\mu _A = \prod _{d \in S} \Phi _d\) with \(S \subseteq \mathrm{divisors}(m)\), then \(\mathrm{lcm}(S) = m\).  </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000049">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> Suppose \(\ell = \mathrm{lcm}(S) {\lt} m\). Then \(\mu _A = \prod _{d \in S} \Phi _d\) divides \(\prod _{d \mid \ell } \Phi _d = X^\ell - 1\), since each \(d \in S\) divides \(\ell \). By the transfer lemma, \(A^\ell = I\). But this contradicts \(\mathrm{ord}(A) = m {\gt} \ell \). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> cyclotomic_divisors_lcm_eq_of_orderOf <span class="lean-bracket">{</span>N : ℕ<span class="lean-bracket">}</span> <span class="lean-bracket">[</span>NeZero N<span class="lean-bracket">]</span>
    <span class="lean-bracket">(</span>A : Matrix <span class="lean-bracket">(</span>Fin N<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>Fin N<span class="lean-bracket">)</span> ℤ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>m : ℕ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hm : <span class="lean-number">0</span> &lt; m<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hA_ord : orderOf A = m<span class="lean-bracket">)</span>
    <span class="lean-bracket">(</span>S : Finset ℕ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hS_sub : <span class="lean-operator">∀</span> d <span class="lean-operator">∈</span> S, d ∣ m<span class="lean-bracket">)</span>
    <span class="lean-bracket">(</span>hminpoly_eq_prod : minpoly ℚ <span class="lean-bracket">(</span>A.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span><span class="lean-bracket">)</span> = <span class="lean-operator">∏</span> d <span class="lean-operator">∈</span> S, cyclotomic d ℚ<span class="lean-bracket">)</span> :
    S.lcm id = m :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="The `let` tactic is for adding definitions to the local context of the main goal.
The definition can be unfolded, unlike definitions introduced by `have`.

* `let x : t := e` adds the definition `x : t := e` if `e` is a term of type `t`.
* `let x := e` uses the type of `e` for `t`.
* `let : t := e` and `let := e` use `this` for the name of the hypothesis.
* `let pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that let only one applicable constructor.
  For example, given `p : α × β × γ`, `let ⟨x, y, z⟩ := p` produces the
  local variables `x : α`, `y : β`, and `z : γ`.
* The syntax `let (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `let` term.

## Properties and relations

* Unlike `have`, it is possible to unfold definitions introduced using `let`, using tactics
  such as `simp`, `dsimp`, `unfold`, and `subst`.
* The `clear_value` tactic turns a `let` definition into a `have` definition after the fact.
  The tactic might fail if the local context depends on the value of the variable.
* The `let` tactic is preferred for data (non-propositions).
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
">let</span> A_Q := A.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span>
  <span class="lean-comment">-- If lcm<span class="lean-bracket">(</span>S<span class="lean-bracket">)</span> &lt; m, then minpoly | X^<span class="lean-bracket">{</span>lcm<span class="lean-bracket">(</span>S<span class="lean-bracket">)</span><span class="lean-bracket">}</span> - <span class="lean-number">1</span>, so A^<span class="lean-bracket">{</span>lcm<span class="lean-bracket">(</span>S<span class="lean-bracket">)</span><span class="lean-bracket">}</span> = <span class="lean-number">1</span></span>
  <span class="lean-comment">-- This contradicts orderOf A = m</span>
  <span class="lean-keyword" data-docs="`by_contra h` proves `⊢ p` by contradiction,
introducing a hypothesis `h : ¬p` and proving `False`.
* If `p` is a negation `¬q`, `h : q` will be introduced instead of `¬¬q`.
* If `p` is decidable, it uses `Decidable.byContradiction` instead of `Classical.byContradiction`.
* If `h` is omitted, the introduced variable will be called `this`.
">by_contra</span> hne
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hlcm_dvd_m : S.lcm id ∣ m := Finset.lcm_dvd <span class="lean-bracket">(</span><span class="lean-keyword">fun</span> d hd =&gt; hS_sub d hd<span class="lean-bracket">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hlcm_le : S.lcm id <span class="lean-operator">≤</span> m := Nat.le_of_dvd hm hlcm_dvd_m
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hlcm_lt : S.lcm id &lt; m := Nat.lt_of_le_of_ne hlcm_le hne
  <span class="lean-comment">-- minpoly | <span class="lean-operator">∏</span>_<span class="lean-bracket">{</span>d|lcm<span class="lean-bracket">(</span>S<span class="lean-bracket">)</span><span class="lean-bracket">}</span> Φ_d = X^<span class="lean-bracket">{</span>lcm<span class="lean-bracket">(</span>S<span class="lean-bracket">)</span><span class="lean-bracket">}</span> - <span class="lean-number">1</span></span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hlcm_pos : <span class="lean-number">0</span> &lt; S.lcm id := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> hS_empty : S = <span class="lean-operator">∅</span>
    <span class="lean-operator">·</span> <span class="lean-comment">-- If S = <span class="lean-operator">∅</span>, then minpoly = <span class="lean-number">1</span> <span class="lean-bracket">(</span>empty product<span class="lean-bracket">)</span>, contradiction since</span>
      <span class="lean-comment">-- minpoly has positive degree</span>
      <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket">[</span>hS_empty, Finset.prod_empty<span class="lean-bracket">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hminpoly_eq_prod
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hdeg := minpoly.natDegree_pos <span class="lean-bracket">(</span>Matrix.isIntegral A_Q<span class="lean-bracket">)</span>
      <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>hminpoly_eq_prod, natDegree_one<span class="lean-bracket">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hdeg
      <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
    <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hne_zero : S.lcm id <span class="lean-operator">≠</span> <span class="lean-number">0</span> := Finset.lcm_ne_zero_iff.mpr <span class="lean-keyword">fun</span> d hd =&gt;
        <span class="lean-bracket">(</span>Nat.pos_of_mem_divisors <span class="lean-bracket">(</span>Nat.mem_divisors.mpr <span class="lean-bracket">⟨</span>hS_sub d hd, hm.ne&#x27;<span class="lean-bracket">⟩</span><span class="lean-bracket">)</span><span class="lean-bracket">)</span>.ne&#x27;
      <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> Nat.pos_of_ne_zero hne_zero
  <span class="lean-comment">-- Helper: X^d - <span class="lean-number">1</span> | X^n - <span class="lean-number">1</span> when d | n</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> X_pow_sub_one_dvd : <span class="lean-operator">∀</span> <span class="lean-bracket">(</span>d n : ℕ<span class="lean-bracket">)</span>, d ∣ n <span class="lean-operator">→</span> <span class="lean-bracket">(</span>X ^ d - <span class="lean-number">1</span> : ℚ<span class="lean-bracket">[</span>X<span class="lean-bracket">]</span><span class="lean-bracket">)</span> ∣ X ^ n - <span class="lean-number">1</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> d n hdvd
    <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-bracket">⟨</span>k, hk<span class="lean-bracket">⟩</span> := hdvd
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>hk<span class="lean-bracket">]</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> pow_one_sub_dvd_pow_mul_sub_one X d k
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hminpoly_dvd_lcm : minpoly ℚ A_Q ∣ X ^ <span class="lean-bracket">(</span>S.lcm id<span class="lean-bracket">)</span> - <span class="lean-number">1</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>hminpoly_eq_prod<span class="lean-bracket">]</span>
    <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> cyclotomic_finset_product_dvd
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> d hd
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hd_dvd_lcm : d ∣ S.lcm id := Finset.dvd_lcm hd
    <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
">calc</span> cyclotomic d ℚ ∣ X ^ d - <span class="lean-number">1</span> := cyclotomic.dvd_X_pow_sub_one d ℚ
      _ ∣ X ^ <span class="lean-bracket">(</span>S.lcm id<span class="lean-bracket">)</span> - <span class="lean-number">1</span> := X_pow_sub_one_dvd d <span class="lean-bracket">(</span>S.lcm id<span class="lean-bracket">)</span> hd_dvd_lcm
  <span class="lean-comment">-- Therefore A^<span class="lean-bracket">{</span>lcm<span class="lean-bracket">(</span>S<span class="lean-bracket">)</span><span class="lean-bracket">}</span> = <span class="lean-number">1</span></span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hpow_lcm : A ^ <span class="lean-bracket">(</span>S.lcm id<span class="lean-bracket">)</span> = <span class="lean-number">1</span> :=
    Matrix.pow_eq_one_of_minpoly_dvd_X_pow_sub_one A <span class="lean-bracket">(</span>S.lcm id<span class="lean-bracket">)</span> hminpoly_dvd_lcm
  <span class="lean-comment">-- But orderOf A = m &gt; lcm<span class="lean-bracket">(</span>S<span class="lean-bracket">)</span>, so orderOf A | lcm<span class="lean-bracket">(</span>S<span class="lean-bracket">)</span> is false</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hord_dvd := orderOf_dvd_of_pow_eq_one hpow_lcm
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>hA_ord<span class="lean-bracket">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hord_dvd
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> := Nat.le_of_dvd hlcm_pos hord_dvd
  <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Forward.lean#L203-L257" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:cyclotomic-divisors-lcm-eq');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="thm:forward-direction">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.7</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#thm:forward-direction">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000050"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0003.html#integerMatrixOrders-def">Definition 3.0.1</a></li>
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0002.html#lem:sum-totient-ge-psi">Theorem 2.0.12</a></li>
          
          <li><a href="sect0005.html#lem:minpoly-eq-prod-cyclotomic">Theorem 5.0.5</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0005.html#lem:cyclotomic-divisors-lcm-eq">Theorem 5.0.6</a></li>
          
          <li><a href="sect0002.html#lem:sum-totient-ge-psi">Theorem 2.0.12</a></li>
          
          <li><a href="sect0005.html#lem:minpoly-dvd-X-pow-sub-one">Theorem 5.0.2</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psi_le_of_mem_integerMatrixOrders" class="lean_decl">Crystallographic.psi_le_of_mem_integerMatrixOrders</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        <b class="bfseries">Forward Direction:</b> If \(m \in \mathrm{Ord}_N\), then \(\psi (m) \leq N\). </p>
<p><b class="bfseries">Mathematical context:</b> The key insight is that integer matrices with finite order have constrained eigenvalues: if \(A^m = I\), all eigenvalues are \(m\)-th roots of unity. The minimal polynomial over \(\mathbb {Q}\) factors into cyclotomic polynomials \(\Phi _d\) for various divisors \(d\) of \(m\). The requirement that \(\mathrm{ord}(A) = m\) (not some proper divisor) forces the set of cyclotomic factors to have \(\mathrm{lcm} = m\), which constrains the total degree. </p>
<p><b class="bfseries">Proof outline:</b> </p>
<ol class="enumerate">
  <li><p>Let \(A\) be an \(N \times N\) integer matrix with \(\mathrm{ord}(A) = m\). </p>
</li>
  <li><p>The minimal polynomial of \(A\) over \(\mathbb {Q}\) divides \(X^m - 1 = \prod _{d \mid m} \Phi _d\). </p>
</li>
  <li><p>Since \(\Phi _d\) are irreducible and pairwise coprime over \(\mathbb {Q}\), the minimal polynomial equals \(\prod _{d \in S} \Phi _d\) for some \(S \subseteq \mathrm{divisors}(m)\). </p>
</li>
  <li><p>The condition \(\mathrm{ord}(A) = m\) forces \(\mathrm{lcm}(S) = m\): if \(\mathrm{lcm}(S) {\lt} m\), then \(A^{\mathrm{lcm}(S)} = I\), contradicting \(\mathrm{ord}(A) = m\). </p>
</li>
  <li><p>The degree of the minimal polynomial is \(\sum _{d \in S} \varphi (d)\). </p>
</li>
  <li><p>By the sum-totient lemma (applied to any \(S\) with \(\mathrm{lcm}(S) = m\)), \(\psi (m) \leq \sum _{d \in S} \varphi (d) = \deg (\mathrm{minpoly}) \leq \deg (\mathrm{charpoly}) = N\). </p>
</li>
</ol>


    </div>
    <div class="proof_wrapper proof_inline" id="a0000000050">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> Let \(A\) be an \(N \times N\) integer matrix with \(A^m = I\). The minimal polynomial \(\mu _A\) over \(\mathbb {Q}\) divides \(X^m - 1\) and factors into cyclotomic polynomials \(\Phi _d\) for various \(d \mid m\). Each factor contributes \(\varphi (d)\) to \(\deg (\mu _A) \leq N\). Since distinct \(\Phi _d\) are coprime and their lcm must be \(m\), summing the totients of appearing divisors gives \(\psi (m) \leq N\). - </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> psi_le_of_mem_integerMatrixOrders <span class="lean-bracket">(</span>N m : ℕ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hm : <span class="lean-number">0</span> &lt; m<span class="lean-bracket">)</span>
    <span class="lean-bracket">(</span>hord : m <span class="lean-operator">∈</span> integerMatrixOrders N<span class="lean-bracket">)</span> : Crystallographic.psi m <span class="lean-operator">≤</span> N :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-comment">-- Extract the matrix A with orderOf A = m</span>
  <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-bracket">⟨</span>A, hA_ord, _<span class="lean-bracket">⟩</span> := hord
  <span class="lean-comment">-- Handle the case N = <span class="lean-number">0</span> separately</span>
  <span class="lean-keyword" data-docs="`rcases` is a tactic that will perform `cases` recursively, according to a pattern. It is used to
destructure hypotheses or expressions composed of inductive types like `h1 : a ∧ b ∧ c ∨ d` or
`h2 : ∃ x y, trans_rel R x y`. Usual usage might be `rcases h1 with ⟨ha, hb, hc⟩ | hd` or
`rcases h2 with ⟨x, y, _ | ⟨z, hxz, hzy⟩⟩` for these examples.

Each element of an `rcases` pattern is matched against a particular local hypothesis (most of which
are generated during the execution of `rcases` and represent individual elements destructured from
the input expression). An `rcases` pattern has the following grammar:

* A name like `x`, which names the active hypothesis as `x`.
* A blank `_`, which does nothing (letting the automatic naming system used by `cases` name the
  hypothesis).
* A hyphen `-`, which clears the active hypothesis and any dependents.
* The keyword `rfl`, which expects the hypothesis to be `h : a = b`, and calls `subst` on the
  hypothesis (which has the effect of replacing `b` with `a` everywhere or vice versa).
* A type ascription `p : ty`, which sets the type of the hypothesis to `ty` and then matches it
  against `p`. (Of course, `ty` must unify with the actual type of `h` for this to work.)
* A tuple pattern `⟨p1, p2, p3⟩`, which matches a constructor with many arguments, or a series
  of nested conjunctions or existentials. For example if the active hypothesis is `a ∧ b ∧ c`,
  then the conjunction will be destructured, and `p1` will be matched against `a`, `p2` against `b`
  and so on.
* A `@` before a tuple pattern as in `@⟨p1, p2, p3⟩` will bind all arguments in the constructor,
  while leaving the `@` off will only use the patterns on the explicit arguments.
* An alternation pattern `p1 | p2 | p3`, which matches an inductive type with multiple constructors,
  or a nested disjunction like `a ∨ b ∨ c`.

A pattern like `⟨a, b, c⟩ | ⟨d, e⟩` will do a split over the inductive datatype,
naming the first three parameters of the first constructor as `a,b,c` and the
first two of the second constructor `d,e`. If the list is not as long as the
number of arguments to the constructor or the number of constructors, the
remaining variables will be automatically named. If there are nested brackets
such as `⟨⟨a⟩, b | c⟩ | d` then these will cause more case splits as necessary.
If there are too many arguments, such as `⟨a, b, c⟩` for splitting on
`∃ x, ∃ y, p x`, then it will be treated as `⟨a, ⟨b, c⟩⟩`, splitting the last
parameter as necessary.

`rcases` also has special support for quotient types: quotient induction into Prop works like
matching on the constructor `quot.mk`.

`rcases h : e with PAT` will do the same as `rcases e with PAT` with the exception that an
assumption `h : e = PAT` will be added to the context.
">rcases</span> Nat.eq_zero_or_pos N <span class="lean-keyword">with</span> rfl | hN_pos
  <span class="lean-operator">·</span> <span class="lean-comment">-- N = <span class="lean-number">0</span>: The only <span class="lean-number">0</span><span class="lean-operator">×</span><span class="lean-number">0</span> matrix is empty, with order <span class="lean-number">1</span></span>
    <span class="lean-keyword" data-docs="`haveI` behaves like `have`, but inlines the value instead of producing a `have` term. ">haveI</span> : IsEmpty <span class="lean-bracket">(</span>Fin <span class="lean-number">0</span><span class="lean-bracket">)</span> := Fin.isEmpty
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hA_eq_1 : A = <span class="lean-number">1</span> := Matrix.ext <span class="lean-keyword">fun</span> i =&gt; Fin.elim0 i
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>hA_eq_1, orderOf_one<span class="lean-bracket">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hA_ord
    <span class="lean-keyword" data-docs="`subst x...` substitutes each hypothesis `x` with a definition found in the local context,
then eliminates the hypothesis.
- If `x` is a local definition, then its definition is used.
- Otherwise, if there is a hypothesis of the form `x = e` or `e = x`,
  then `e` is used for the definition of `x`.

If `h : a = b`, then `subst h` may be used if either `a` or `b` unfolds to a local hypothesis.
This is similar to the `cases h` tactic.

See also: `subst_vars` for substituting all local hypotheses that have a defining equation.
">subst</span> hA_ord
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-bracket">[</span>Crystallographic.psi_one<span class="lean-bracket">]</span>
  <span class="lean-operator">·</span> <span class="lean-comment">-- N &gt; <span class="lean-number">0</span>: Use psi <span class="lean-operator">≤</span> deg<span class="lean-bracket">(</span>minpoly<span class="lean-bracket">)</span> <span class="lean-operator">≤</span> deg<span class="lean-bracket">(</span>charpoly<span class="lean-bracket">)</span> = N</span>
    <span class="lean-keyword" data-docs="`haveI` behaves like `have`, but inlines the value instead of producing a `have` term. ">haveI</span> : NeZero N := <span class="lean-bracket">⟨</span>Nat.pos_iff_ne_zero.mp hN_pos<span class="lean-bracket">⟩</span>
    <span class="lean-keyword" data-docs="The `let` tactic is for adding definitions to the local context of the main goal.
The definition can be unfolded, unlike definitions introduced by `have`.

* `let x : t := e` adds the definition `x : t := e` if `e` is a term of type `t`.
* `let x := e` uses the type of `e` for `t`.
* `let : t := e` and `let := e` use `this` for the name of the hypothesis.
* `let pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that let only one applicable constructor.
  For example, given `p : α × β × γ`, `let ⟨x, y, z⟩ := p` produces the
  local variables `x : α`, `y : β`, and `z : γ`.
* The syntax `let (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `let` term.

## Properties and relations

* Unlike `have`, it is possible to unfold definitions introduced using `let`, using tactics
  such as `simp`, `dsimp`, `unfold`, and `subst`.
* The `clear_value` tactic turns a `let` definition into a `have` definition after the fact.
  The tactic might fail if the local context depends on the value of the variable.
* The `let` tactic is preferred for data (non-propositions).
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
">let</span> A_Q := A.map <span class="lean-bracket">(</span>algebraMap ℤ ℚ<span class="lean-bracket">)</span>
    <span class="lean-comment">-- The minimal polynomial degree is at most N</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hminpoly_deg_le : <span class="lean-bracket">(</span>minpoly ℚ A_Q<span class="lean-bracket">)</span>.natDegree <span class="lean-operator">≤</span> N := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hdvd := Matrix.minpoly_dvd_charpoly A_Q
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hne : A_Q.charpoly <span class="lean-operator">≠</span> <span class="lean-number">0</span> := <span class="lean-bracket">(</span>Matrix.charpoly_monic A_Q<span class="lean-bracket">)</span>.ne_zero
      <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
">calc</span> <span class="lean-bracket">(</span>minpoly ℚ A_Q<span class="lean-bracket">)</span>.natDegree <span class="lean-operator">≤</span> A_Q.charpoly.natDegree :=
          Polynomial.natDegree_le_of_dvd hdvd hne
        _ = Fintype.card <span class="lean-bracket">(</span>Fin N<span class="lean-bracket">)</span> := Matrix.charpoly_natDegree_eq_dim A_Q
        _ = N := Fintype.card_fin N
    <span class="lean-comment">-- minpoly | X^m - <span class="lean-number">1</span> since A^m = <span class="lean-number">1</span></span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hpow : A ^ m = <span class="lean-number">1</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span><span class="lean-operator">←</span> hA_ord<span class="lean-bracket">]</span>; <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> pow_orderOf_eq_one A
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hminpoly_dvd : minpoly ℚ A_Q ∣ X ^ m - <span class="lean-number">1</span> :=
      Matrix.minpoly_dvd_X_pow_sub_one_of_pow_eq_one A m hpow
    <span class="lean-comment">-- Get S and the product decomposition from helper lemma</span>
    <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-bracket">⟨</span>S, hS_sub, hminpoly_eq_prod<span class="lean-bracket">⟩</span> :=
      minpoly_eq_prod_cyclotomic_of_dvd_X_pow_sub_one A m hm hminpoly_dvd
    <span class="lean-comment">-- The lcm of S equals m <span class="lean-bracket">(</span>otherwise order would be smaller<span class="lean-bracket">)</span></span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hS_lcm : S.lcm id = m :=
      cyclotomic_divisors_lcm_eq_of_orderOf A m hm hA_ord S hS_sub hminpoly_eq_prod
    <span class="lean-comment">-- Compute the degree as sum of totients</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hdeg_eq : <span class="lean-bracket">(</span>minpoly ℚ A_Q<span class="lean-bracket">)</span>.natDegree = <span class="lean-operator">∑</span> d <span class="lean-operator">∈</span> S, Nat.totient d := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
      <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>hminpoly_eq_prod, Polynomial.natDegree_prod _ _ <span class="lean-bracket">(</span><span class="lean-keyword">fun</span> d _ =&gt; cyclotomic_ne_zero d ℚ<span class="lean-bracket">)</span><span class="lean-bracket">]</span>
      <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> Finset.sum_congr rfl <span class="lean-bracket">(</span><span class="lean-keyword">fun</span> d _ =&gt; natDegree_cyclotomic d ℚ<span class="lean-bracket">)</span>
    <span class="lean-comment">-- Apply sum_totient_ge_psi_of_lcm_eq</span>
    <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
">calc</span> Crystallographic.psi m <span class="lean-operator">≤</span> <span class="lean-operator">∑</span> d <span class="lean-operator">∈</span> S, Nat.totient d :=
        sum_totient_ge_psi_of_lcm_eq m hm S hS_sub hS_lcm
      _ = <span class="lean-bracket">(</span>minpoly ℚ A_Q<span class="lean-bracket">)</span>.natDegree := hdeg_eq.symm
      _ <span class="lean-operator">≤</span> N := hminpoly_deg_le</code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Forward.lean#L259-L346" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('thm:forward-direction');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:permMatrix-one">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.8</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#lem:permMatrix-one">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000051"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.Equiv.Perm.permMatrix_one" class="lean_decl">Crystallographic.Equiv.Perm.permMatrix_one</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       The permutation matrix of the identity is the identity matrix: \(P_{\mathrm{id}} = I\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000051">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>Direct computation using \(\mathrm{toPEquiv}(\mathrm{id}) = \mathrm{refl}\) and \(\mathrm{toMatrix}(\mathrm{refl}) = I\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> permMatrix_one <span class="lean-bracket">{</span>n : <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-bracket">}</span> <span class="lean-bracket">[</span>DecidableEq n<span class="lean-bracket">]</span> <span class="lean-bracket">{</span>R : <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-bracket">}</span> <span class="lean-bracket">[</span>Zero R<span class="lean-bracket">]</span> <span class="lean-bracket">[</span>One R<span class="lean-bracket">]</span> :
    <span class="lean-bracket">(</span><span class="lean-number">1</span> : Equiv.Perm n<span class="lean-bracket">)</span>.permMatrix R = <span class="lean-bracket">(</span><span class="lean-number">1</span> : Matrix n n R<span class="lean-bracket">)</span> :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket">[</span>Equiv.Perm.permMatrix, Equiv.Perm.one_def, Equiv.toPEquiv_refl, PEquiv.toMatrix_refl<span class="lean-bracket">]</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Backward.lean#L67-L74" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:permMatrix-one');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:permMatrix-mul">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.9</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#lem:permMatrix-mul">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000052"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.Equiv.Perm.permMatrix_mul" class="lean_decl">Crystallographic.Equiv.Perm.permMatrix_mul</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       Permutation matrices satisfy \(P_{\sigma \cdot \tau } = P_\tau \cdot P_\sigma \) (contravariant homomorphism). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000052">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>Follows from \(\mathrm{toPEquiv}(\sigma \circ \tau ) = \mathrm{toPEquiv}(\tau ) \cdot \mathrm{toPEquiv}(\sigma )\) and the corresponding property for partial equivalence matrices. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> permMatrix_mul <span class="lean-bracket">{</span>n : <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-bracket">}</span> <span class="lean-bracket">[</span>DecidableEq n<span class="lean-bracket">]</span> <span class="lean-bracket">[</span>Fintype n<span class="lean-bracket">]</span> <span class="lean-bracket">{</span>R : <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-bracket">}</span> <span class="lean-bracket">[</span>Semiring R<span class="lean-bracket">]</span>
    <span class="lean-bracket">(</span>σ τ : Equiv.Perm n<span class="lean-bracket">)</span> :
    <span class="lean-bracket">(</span>σ * τ<span class="lean-bracket">)</span>.permMatrix R = τ.permMatrix R * σ.permMatrix R :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket">[</span>Equiv.Perm.permMatrix<span class="lean-bracket">]</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>Equiv.Perm.mul_def, Equiv.toPEquiv_trans, PEquiv.toMatrix_trans<span class="lean-bracket">]</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Backward.lean#L76-L86" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:permMatrix-mul');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:permMatrix-pow">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.10</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#lem:permMatrix-pow">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000053"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0005.html#lem:permMatrix-one">Theorem 5.0.8</a></li>
          
          <li><a href="sect0005.html#lem:permMatrix-mul">Theorem 5.0.9</a></li>
          
          <li><a href="sect0005.html#lem:permMatrix-one">Theorem 5.0.8</a></li>
          
          <li><a href="sect0005.html#lem:permMatrix-mul">Theorem 5.0.9</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.Equiv.Perm.permMatrix_pow" class="lean_decl">Crystallographic.Equiv.Perm.permMatrix_pow</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       Powers of permutation matrices satisfy \(P_{\sigma ^k} = P_\sigma ^k\).  </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000053">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> By induction on \(k\): the base case uses \(P_{\mathrm{id}} = I\), and the inductive step uses \(P_{\sigma \cdot \tau } = P_\tau \cdot P_\sigma \) together with commutativity of powers. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> permMatrix_pow <span class="lean-bracket">{</span>n : <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-bracket">}</span> <span class="lean-bracket">[</span>DecidableEq n<span class="lean-bracket">]</span> <span class="lean-bracket">[</span>Fintype n<span class="lean-bracket">]</span> <span class="lean-bracket">{</span>R : <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-bracket">}</span> <span class="lean-bracket">[</span>Semiring R<span class="lean-bracket">]</span>
    <span class="lean-bracket">(</span>σ : Equiv.Perm n<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>k : ℕ<span class="lean-bracket">)</span> :
    <span class="lean-bracket">(</span>σ ^ k<span class="lean-bracket">)</span>.permMatrix R = <span class="lean-bracket">(</span>σ.permMatrix R<span class="lean-bracket">)</span> ^ k :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
">induction</span> k <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
">with</span>
  | zero =&gt; <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-bracket">[</span>permMatrix_one<span class="lean-bracket">]</span>
  | succ k ih =&gt;
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>pow_succ, pow_succ, permMatrix_mul, ih<span class="lean-bracket">]</span>
    <span class="lean-comment">-- Goal: σ.permMatrix * <span class="lean-bracket">(</span>σ.permMatrix<span class="lean-bracket">)</span>^k = <span class="lean-bracket">(</span>σ.permMatrix<span class="lean-bracket">)</span>^k * σ.permMatrix</span>
    <span class="lean-comment">-- Use SemiconjBy or direct equality - both sides are equal</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-bracket">(</span>Commute.pow_self <span class="lean-bracket">(</span>σ.permMatrix R<span class="lean-bracket">)</span> k<span class="lean-bracket">)</span>.eq.symm</code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Backward.lean#L88-L103" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:permMatrix-pow');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:permMatrix-eq-one-iff">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.11</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#lem:permMatrix-eq-one-iff">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000054"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0005.html#lem:permMatrix-one">Theorem 5.0.8</a></li>
          
          <li><a href="sect0005.html#lem:permMatrix-one">Theorem 5.0.8</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.Equiv.Perm.permMatrix_eq_one_iff" class="lean_decl">Crystallographic.Equiv.Perm.permMatrix_eq_one_iff</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       \(P_\sigma = I\) if and only if \(\sigma = \mathrm{id}\).  </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000054">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> The forward direction shows that if \(P_\sigma = I\) then for each \(x\), the entry \((P_\sigma )_{x, \sigma (x)} = 1\) forces \(\sigma (x) = x\). The reverse is immediate from \(P_{\mathrm{id}} = I\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> permMatrix_eq_one_iff <span class="lean-bracket">{</span>n : <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-bracket">}</span> <span class="lean-bracket">[</span>DecidableEq n<span class="lean-bracket">]</span> <span class="lean-bracket">[</span>Fintype n<span class="lean-bracket">]</span> <span class="lean-bracket">{</span>R : <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-bracket">}</span> <span class="lean-bracket">[</span>Semiring R<span class="lean-bracket">]</span>
    <span class="lean-bracket">[</span>Nontrivial R<span class="lean-bracket">]</span> <span class="lean-bracket">(</span>σ : Equiv.Perm n<span class="lean-bracket">)</span> :
    σ.permMatrix R = <span class="lean-number">1</span> <span class="lean-operator">↔</span> σ = <span class="lean-number">1</span> :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="If the main goal&#x27;s target type is an inductive type, `constructor` solves it with
the first matching constructor, or else fails.
">constructor</span>
  <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> h
    <span class="lean-keyword" data-docs="Applies extensionality lemmas that are registered with the `@[ext]` attribute.
* `ext pat*` applies extensionality theorems as much as possible,
  using the patterns `pat*` to introduce the variables in extensionality theorems using `rintro`.
  For example, the patterns are used to name the variables introduced by lemmas such as `funext`.
* Without patterns,`ext` applies extensionality lemmas as much
  as possible but introduces anonymous hypotheses whenever needed.
* `ext pat* : n` applies ext theorems only up to depth `n`.

The `ext1 pat*` tactic is like `ext pat*` except that it only applies a single extensionality theorem.

Unused patterns will generate warning.
Patterns that don&#x27;t match the variables will typically result in the introduction of anonymous hypotheses.
">ext</span> x
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hx := congrFun <span class="lean-bracket">(</span>congrFun h x<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>σ x<span class="lean-bracket">)</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket">[</span>Equiv.Perm.permMatrix, Equiv.toPEquiv_apply, PEquiv.toMatrix_apply, Matrix.one_apply,
      Option.mem_def<span class="lean-bracket">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hx
    <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> hσx : σ x = x
    <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> hσx
    <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="`exfalso` converts a goal `⊢ tgt` into `⊢ False` by applying `False.elim`. ">exfalso</span>
      <span class="lean-comment">-- hx says: if σ <span class="lean-bracket">(</span>σ x<span class="lean-bracket">)</span> = σ x then <span class="lean-number">1</span> else <span class="lean-number">0</span> = if x = σ x then <span class="lean-number">1</span> else <span class="lean-number">0</span></span>
      <span class="lean-comment">-- After simp, lhs simplifies using σ <span class="lean-bracket">(</span>σ x<span class="lean-bracket">)</span> = σ x <span class="lean-operator">↔</span> σ x = x <span class="lean-bracket">(</span>by injectivity<span class="lean-bracket">)</span></span>
      <span class="lean-comment">-- which is true since Option.mem_def</span>
      <span class="lean-comment">-- rhs: x = σ x is false by hσx</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> h1 : <span class="lean-bracket">(</span><span class="lean-number">1</span> : R<span class="lean-bracket">)</span> = <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
">if</span> x = σ x <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
">then</span> <span class="lean-number">1</span> <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
">else</span> <span class="lean-number">0</span> := hx
      <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>if_neg <span class="lean-bracket">(</span>ne_comm.mpr hσx<span class="lean-bracket">)</span><span class="lean-bracket">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> h1
      <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> one_ne_zero h1
  <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> h; <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>h<span class="lean-bracket">]</span>; <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> permMatrix_one</code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Backward.lean#L105-L131" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:permMatrix-eq-one-iff');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:orderOf-permMatrix">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.12</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#lem:orderOf-permMatrix">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000055"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.Equiv.Perm.orderOf_permMatrix" class="lean_decl">Crystallographic.Equiv.Perm.orderOf_permMatrix</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       The order of \(P_\sigma \) equals the order of \(\sigma \) for a permutation matrix. </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000055">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> Since \(P_{\sigma ^k} = P_\sigma ^k\) and \(P_\sigma = I \iff \sigma = \mathrm{id}\), the order of \(P_\sigma \) equals the order of \(\sigma \). The key is that the permutation matrix map preserves powers and is injective on the group of permutation matrices. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> orderOf_permMatrix <span class="lean-bracket">{</span>n : <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-bracket">}</span> <span class="lean-bracket">[</span>DecidableEq n<span class="lean-bracket">]</span> <span class="lean-bracket">[</span>Fintype n<span class="lean-bracket">]</span> <span class="lean-bracket">{</span>R : <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-bracket">}</span> <span class="lean-bracket">[</span>Semiring R<span class="lean-bracket">]</span>
    <span class="lean-bracket">[</span>Nontrivial R<span class="lean-bracket">]</span> <span class="lean-bracket">(</span>σ : Equiv.Perm n<span class="lean-bracket">)</span> :
    orderOf <span class="lean-bracket">(</span>σ.permMatrix R<span class="lean-bracket">)</span> = orderOf σ :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="`rcases` is a tactic that will perform `cases` recursively, according to a pattern. It is used to
destructure hypotheses or expressions composed of inductive types like `h1 : a ∧ b ∧ c ∨ d` or
`h2 : ∃ x y, trans_rel R x y`. Usual usage might be `rcases h1 with ⟨ha, hb, hc⟩ | hd` or
`rcases h2 with ⟨x, y, _ | ⟨z, hxz, hzy⟩⟩` for these examples.

Each element of an `rcases` pattern is matched against a particular local hypothesis (most of which
are generated during the execution of `rcases` and represent individual elements destructured from
the input expression). An `rcases` pattern has the following grammar:

* A name like `x`, which names the active hypothesis as `x`.
* A blank `_`, which does nothing (letting the automatic naming system used by `cases` name the
  hypothesis).
* A hyphen `-`, which clears the active hypothesis and any dependents.
* The keyword `rfl`, which expects the hypothesis to be `h : a = b`, and calls `subst` on the
  hypothesis (which has the effect of replacing `b` with `a` everywhere or vice versa).
* A type ascription `p : ty`, which sets the type of the hypothesis to `ty` and then matches it
  against `p`. (Of course, `ty` must unify with the actual type of `h` for this to work.)
* A tuple pattern `⟨p1, p2, p3⟩`, which matches a constructor with many arguments, or a series
  of nested conjunctions or existentials. For example if the active hypothesis is `a ∧ b ∧ c`,
  then the conjunction will be destructured, and `p1` will be matched against `a`, `p2` against `b`
  and so on.
* A `@` before a tuple pattern as in `@⟨p1, p2, p3⟩` will bind all arguments in the constructor,
  while leaving the `@` off will only use the patterns on the explicit arguments.
* An alternation pattern `p1 | p2 | p3`, which matches an inductive type with multiple constructors,
  or a nested disjunction like `a ∨ b ∨ c`.

A pattern like `⟨a, b, c⟩ | ⟨d, e⟩` will do a split over the inductive datatype,
naming the first three parameters of the first constructor as `a,b,c` and the
first two of the second constructor `d,e`. If the list is not as long as the
number of arguments to the constructor or the number of constructors, the
remaining variables will be automatically named. If there are nested brackets
such as `⟨⟨a⟩, b | c⟩ | d` then these will cause more case splits as necessary.
If there are too many arguments, such as `⟨a, b, c⟩` for splitting on
`∃ x, ∃ y, p x`, then it will be treated as `⟨a, ⟨b, c⟩⟩`, splitting the last
parameter as necessary.

`rcases` also has special support for quotient types: quotient induction into Prop works like
matching on the constructor `quot.mk`.

`rcases h : e with PAT` will do the same as `rcases e with PAT` with the exception that an
assumption `h : e = PAT` will be added to the context.
">rcases</span> Nat.eq_zero_or_pos <span class="lean-bracket">(</span>orderOf σ<span class="lean-bracket">)</span> <span class="lean-keyword">with</span> hord | hord
  <span class="lean-operator">·</span> <span class="lean-comment">-- σ has infinite order <span class="lean-bracket">(</span>orderOf σ = <span class="lean-number">0</span><span class="lean-bracket">)</span></span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>hord, orderOf_eq_zero_iff&#x27;<span class="lean-bracket">]</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> k hk heq
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> h1 : <span class="lean-bracket">(</span>σ ^ k<span class="lean-bracket">)</span>.permMatrix R = <span class="lean-number">1</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>permMatrix_pow<span class="lean-bracket">]</span>; <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> heq
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>permMatrix_eq_one_iff<span class="lean-bracket">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> h1
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-bracket">(</span>orderOf_eq_zero_iff&#x27;.mp hord<span class="lean-bracket">)</span> k hk h1
  <span class="lean-operator">·</span> <span class="lean-comment">-- σ has finite order</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>orderOf_eq_iff hord<span class="lean-bracket">]</span>
    <span class="lean-keyword" data-docs="If the main goal&#x27;s target type is an inductive type, `constructor` solves it with
the first matching constructor, or else fails.
">constructor</span>
    <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span><span class="lean-operator">←</span> permMatrix_pow, pow_orderOf_eq_one<span class="lean-bracket">]</span>; <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> permMatrix_one
    <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> k hk_lt hk_pos heq
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hk&#x27; : <span class="lean-bracket">(</span>σ ^ k<span class="lean-bracket">)</span>.permMatrix R = <span class="lean-number">1</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>permMatrix_pow<span class="lean-bracket">]</span>; <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> heq
      <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>permMatrix_eq_one_iff<span class="lean-bracket">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hk&#x27;
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hdvd : orderOf σ ∣ k := orderOf_dvd_of_pow_eq_one hk&#x27;
      <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> Nat.not_lt.mpr <span class="lean-bracket">(</span>Nat.le_of_dvd hk_pos hdvd<span class="lean-bracket">)</span> hk_lt</code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Backward.lean#L133-L157" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:orderOf-permMatrix');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:orderOf-finRotate">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.13</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#lem:orderOf-finRotate">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000056"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.Equiv.Perm.orderOf_finRotate" class="lean_decl">Crystallographic.Equiv.Perm.orderOf_finRotate</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       The order of \(\mathrm{finRotate}(n)\) equals \(n\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000056">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>The \(\mathrm{finRotate}(n)\) permutation is an \(n\)-cycle with full support \(\mathrm{Fin}\  n\). By the cycle order theorem, the order of a cycle equals its length, which is \(n\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> orderOf_finRotate <span class="lean-bracket">(</span>n : ℕ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hn : <span class="lean-number">2</span> <span class="lean-operator">≤</span> n<span class="lean-bracket">)</span> : orderOf <span class="lean-bracket">(</span>finRotate n<span class="lean-bracket">)</span> = n :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hcycle := isCycle_finRotate_of_le hn
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hord := Equiv.Perm.IsCycle.orderOf hcycle
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hsupp := support_finRotate_of_le hn
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>hord, hsupp, Finset.card_univ, Fintype.card_fin<span class="lean-bracket">]</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Backward.lean#L159-L168" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:orderOf-finRotate');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:orderOf-permMatrix-finRotate">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.14</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#lem:orderOf-permMatrix-finRotate">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000057"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0005.html#lem:orderOf-permMatrix">Theorem 5.0.12</a></li>
          
          <li><a href="sect0005.html#lem:orderOf-finRotate">Theorem 5.0.13</a></li>
          
          <li><a href="sect0005.html#lem:orderOf-finRotate">Theorem 5.0.13</a></li>
          
          <li><a href="sect0005.html#lem:orderOf-permMatrix">Theorem 5.0.12</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.Equiv.Perm.orderOf_permMatrix_finRotate" class="lean_decl">Crystallographic.Equiv.Perm.orderOf_permMatrix_finRotate</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       The permutation matrix of \(\mathrm{finRotate}(n)\) has order \(n\) over \(\mathbb {Z}\).  </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000057">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> Combines the order-preservation property \(\mathrm{ord}(P_\sigma ) = \mathrm{ord}(\sigma )\) with \(\mathrm{ord}(\mathrm{finRotate}(n)) = n\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> orderOf_permMatrix_finRotate <span class="lean-bracket">(</span>n : ℕ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hn : <span class="lean-number">2</span> <span class="lean-operator">≤</span> n<span class="lean-bracket">)</span> :
    orderOf <span class="lean-bracket">(</span><span class="lean-bracket">(</span>finRotate n<span class="lean-bracket">)</span>.permMatrix ℤ<span class="lean-bracket">)</span> = n :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>orderOf_permMatrix, orderOf_finRotate n hn<span class="lean-bracket">]</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Backward.lean#L170-L178" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:orderOf-permMatrix-finRotate');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:mem-integerMatrixOrders-self">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.15</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#lem:mem-integerMatrixOrders-self">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000058"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0003.html#integerMatrixOrders-def">Definition 3.0.1</a></li>
          
          <li><a href="sect0005.html#lem:orderOf-permMatrix-finRotate">Theorem 5.0.14</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.mem_integerMatrixOrders_self" class="lean_decl">Crystallographic.mem_integerMatrixOrders_self</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        \(m \in \mathrm{Ord}_m\) for \(m \geq 2\) via permutation matrix. </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000058">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> The permutation matrix \(P_{\mathrm{finRotate}(m)}\) is an \(m \times m\) integer matrix with order exactly \(m\), since \(\mathrm{finRotate}(m)\) has order \(m\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> mem_integerMatrixOrders_self <span class="lean-bracket">(</span>n : ℕ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hn : <span class="lean-number">2</span> <span class="lean-operator">≤</span> n<span class="lean-bracket">)</span> : n <span class="lean-operator">∈</span> integerMatrixOrders n :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="`use e₁, e₂, ⋯` is similar to `exists`, but unlike `exists` it is equivalent to applying the tactic
`refine ⟨e₁, e₂, ⋯, ?_, ⋯, ?_⟩` with any number of placeholders (rather than just one) and
then trying to close goals associated to the placeholders with a configurable discharger (rather
than just `try trivial`).

Examples:

```lean
example : ∃ x : Nat, x = x := by use 42

example : ∃ x : Nat, ∃ y : Nat, x = y := by use 42, 42

example : ∃ x : String × String, x.1 = x.2 := by use (&quot;forty-two&quot;, &quot;forty-two&quot;)
```

`use! e₁, e₂, ⋯` is similar but it applies constructors everywhere rather than just for
goals that correspond to the last argument of a constructor. This gives the effect that
nested constructors are being flattened out, with the supplied values being used along the
leaves and nodes of the tree of constructors.
With `use!` one can feed in each `42` one at a time:

```lean
example : ∃ p : Nat × Nat, p.1 = p.2 := by use! 42, 42

example : ∃ p : Nat × Nat, p.1 = p.2 := by use! (42, 42)
```

The second line makes use of the fact that `use!` tries refining with the argument before
applying a constructor. Also note that `use`/`use!` by default uses a tactic
called `use_discharger` to discharge goals, so `use! 42` will close the goal in this example since
`use_discharger` applies `rfl`, which as a consequence solves for the other `Nat` metavariable.

These tactics take an optional discharger to handle remaining explicit `Prop` constructor arguments.
By default it is `use (discharger := try with_reducible use_discharger) e₁, e₂, ⋯`.
To turn off the discharger and keep all goals, use `(discharger := skip)`.
To allow &quot;heavy refls&quot;, use `(discharger := try use_discharger)`.
">use</span> <span class="lean-bracket">(</span>finRotate n<span class="lean-bracket">)</span>.permMatrix ℤ
  <span class="lean-keyword" data-docs="If the main goal&#x27;s target type is an inductive type, `constructor` solves it with
the first matching constructor, or else fails.
">constructor</span>
  <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> Equiv.Perm.orderOf_permMatrix_finRotate n hn
  <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Backward.lean#L182-L191" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:mem-integerMatrixOrders-self');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="thm:primePow-mem-integerMatrixOrders-psi">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.16</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#thm:primePow-mem-integerMatrixOrders-psi">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000059"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0003.html#integerMatrixOrders-def">Definition 3.0.1</a></li>
          
          <li><a href="sect0002.html#lem:psi-prime-pow">Theorem 2.0.1</a></li>
          
          <li><a href="sect0004.html#thm:mem-orders-totient">Theorem 4.0.7</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.primePow_mem_integerMatrixOrders_psi" class="lean_decl">Crystallographic.primePow_mem_integerMatrixOrders_psi</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        For a prime power \(p^k\) with \(p\) odd or \(k \geq 2\), we have \(p^k \in \mathrm{Ord}_{\psi (p^k)}\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000059">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> For these prime powers, \(\psi (p^k) = \varphi (p^k)\). The companion matrix of \(\Phi _{p^k}\) has dimension \(\varphi (p^k)\) and order exactly \(p^k\), so \(p^k \in \mathrm{Ord}_{\varphi (p^k)} = \mathrm{Ord}_{\psi (p^k)}\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> primePow_mem_integerMatrixOrders_psi <span class="lean-bracket">(</span>p k : ℕ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hp : p.Prime<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hk : <span class="lean-number">0</span> &lt; k<span class="lean-bracket">)</span>
    <span class="lean-bracket">(</span>hpk : <span class="lean-operator">¬</span><span class="lean-bracket">(</span>p = <span class="lean-number">2</span> <span class="lean-operator">∧</span> k = <span class="lean-number">1</span><span class="lean-bracket">)</span><span class="lean-bracket">)</span> :
    p ^ k <span class="lean-operator">∈</span> integerMatrixOrders <span class="lean-bracket">(</span>psi <span class="lean-bracket">(</span>p ^ k<span class="lean-bracket">)</span><span class="lean-bracket">)</span> :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-comment">-- psi<span class="lean-bracket">(</span>p^k<span class="lean-bracket">)</span> = totient<span class="lean-bracket">(</span>p^k<span class="lean-bracket">)</span> for this case</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hpsi_eq : psi <span class="lean-bracket">(</span>p ^ k<span class="lean-bracket">)</span> = Nat.totient <span class="lean-bracket">(</span>p ^ k<span class="lean-bracket">)</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>psi_prime_pow p k hp hk<span class="lean-bracket">]</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket">[</span>hpk, ite_false<span class="lean-bracket">]</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>hpsi_eq<span class="lean-bracket">]</span>
  <span class="lean-comment">-- Use companion matrix lemma</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hpk_ge2 : <span class="lean-number">2</span> <span class="lean-operator">≤</span> p ^ k := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hp_ge2 : <span class="lean-number">2</span> <span class="lean-operator">≤</span> p := hp.two_le
    <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
">calc</span> p ^ k <span class="lean-operator">≥</span> p ^ <span class="lean-number">1</span> := Nat.pow_le_pow_right <span class="lean-bracket">(</span>Nat.le_of_lt hp.one_lt<span class="lean-bracket">)</span> hk
      _ = p := pow_one p
      _ <span class="lean-operator">≥</span> <span class="lean-number">2</span> := hp_ge2
  <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> mem_integerMatrixOrders_totient <span class="lean-bracket">(</span>p ^ k<span class="lean-bracket">)</span> hpk_ge2</code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Backward.lean#L195-L215" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('thm:primePow-mem-integerMatrixOrders-psi');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="thm:mem-integerMatrixOrders-psi">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.17</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#thm:mem-integerMatrixOrders-psi">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000060"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0005.html#thm:primePow-mem-integerMatrixOrders-psi">Theorem 5.0.16</a></li>
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0003.html#lem:one-mem-orders">Theorem 3.0.1</a></li>
          
          <li><a href="sect0006.html#lem:orderOf-neg-of-odd-order">Theorem A.0.7</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0003.html#lem:mul-mem-orders-coprime">Theorem 3.0.10</a></li>
          
          <li><a href="sect0005.html#thm:primePow-mem-integerMatrixOrders-psi">Theorem 5.0.16</a></li>
          
          <li><a href="sect0002.html#lem:factorization-split-lt">Theorem 2.0.6</a></li>
          
          <li><a href="sect0002.html#lem:psi-coprime-add">Theorem 2.0.3</a></li>
          
          <li><a href="sect0003.html#lem:one-mem-orders">Theorem 3.0.1</a></li>
          
          <li><a href="sect0002.html#lem:psi-pos-of-odd">Theorem 2.0.7</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.mem_integerMatrixOrders_psi" class="lean_decl">Crystallographic.mem_integerMatrixOrders_psi</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        For \(m \geq 1\) with \(m \neq 2\), we have \(m \in \mathrm{Ord}_{\psi (m)}\). The construction achieves order \(m\) using exactly \(\psi (m)\) dimensions via block diagonal matrices of cyclotomic companion matrices.  </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000060">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> By strong induction on \(m\). For \(m = 1\), the identity achieves order 1 in dimension \(\psi (1) = 0\). For prime powers \(p^k\) (excluding \(2^1\)), the companion matrix of \(\Phi _{p^k}\) has order \(p^k\) in dimension \(\varphi (p^k) = \psi (p^k)\). For composite \(m = p^e \cdot m'\) with coprime factors, we use block diagonal of matrices achieving orders \(p^e\) and \(m'\) from the induction hypothesis, with dimension \(\psi (p^e) + \psi (m') = \psi (m)\) by additivity of \(\psi \) on coprime factors. For \(m = 2 \cdot m'\) with \(m'\) odd, negating the order-\(m'\) matrix doubles the order without changing dimension. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> mem_integerMatrixOrders_psi <span class="lean-bracket">(</span>m : ℕ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hm : <span class="lean-number">0</span> &lt; m<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hm2 : m <span class="lean-operator">≠</span> <span class="lean-number">2</span><span class="lean-bracket">)</span> :
    m <span class="lean-operator">∈</span> integerMatrixOrders <span class="lean-bracket">(</span>psi m<span class="lean-bracket">)</span> :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-comment">-- Use strong induction on m</span>
  <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
">induction</span> m <span class="lean-keyword">using</span> Nat.strong_induction_on <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
">with</span>
  | _ m IH =&gt;
  <span class="lean-comment">-- Case: m = <span class="lean-number">1</span></span>
  <span class="lean-keyword" data-docs="`rcases` is a tactic that will perform `cases` recursively, according to a pattern. It is used to
destructure hypotheses or expressions composed of inductive types like `h1 : a ∧ b ∧ c ∨ d` or
`h2 : ∃ x y, trans_rel R x y`. Usual usage might be `rcases h1 with ⟨ha, hb, hc⟩ | hd` or
`rcases h2 with ⟨x, y, _ | ⟨z, hxz, hzy⟩⟩` for these examples.

Each element of an `rcases` pattern is matched against a particular local hypothesis (most of which
are generated during the execution of `rcases` and represent individual elements destructured from
the input expression). An `rcases` pattern has the following grammar:

* A name like `x`, which names the active hypothesis as `x`.
* A blank `_`, which does nothing (letting the automatic naming system used by `cases` name the
  hypothesis).
* A hyphen `-`, which clears the active hypothesis and any dependents.
* The keyword `rfl`, which expects the hypothesis to be `h : a = b`, and calls `subst` on the
  hypothesis (which has the effect of replacing `b` with `a` everywhere or vice versa).
* A type ascription `p : ty`, which sets the type of the hypothesis to `ty` and then matches it
  against `p`. (Of course, `ty` must unify with the actual type of `h` for this to work.)
* A tuple pattern `⟨p1, p2, p3⟩`, which matches a constructor with many arguments, or a series
  of nested conjunctions or existentials. For example if the active hypothesis is `a ∧ b ∧ c`,
  then the conjunction will be destructured, and `p1` will be matched against `a`, `p2` against `b`
  and so on.
* A `@` before a tuple pattern as in `@⟨p1, p2, p3⟩` will bind all arguments in the constructor,
  while leaving the `@` off will only use the patterns on the explicit arguments.
* An alternation pattern `p1 | p2 | p3`, which matches an inductive type with multiple constructors,
  or a nested disjunction like `a ∨ b ∨ c`.

A pattern like `⟨a, b, c⟩ | ⟨d, e⟩` will do a split over the inductive datatype,
naming the first three parameters of the first constructor as `a,b,c` and the
first two of the second constructor `d,e`. If the list is not as long as the
number of arguments to the constructor or the number of constructors, the
remaining variables will be automatically named. If there are nested brackets
such as `⟨⟨a⟩, b | c⟩ | d` then these will cause more case splits as necessary.
If there are too many arguments, such as `⟨a, b, c⟩` for splitting on
`∃ x, ∃ y, p x`, then it will be treated as `⟨a, ⟨b, c⟩⟩`, splitting the last
parameter as necessary.

`rcases` also has special support for quotient types: quotient induction into Prop works like
matching on the constructor `quot.mk`.

`rcases h : e with PAT` will do the same as `rcases e with PAT` with the exception that an
assumption `h : e = PAT` will be added to the context.
">rcases</span> <span class="lean-bracket">(</span>Nat.one_le_iff_ne_zero.mpr hm.ne&#x27;<span class="lean-bracket">)</span>.eq_or_lt&#x27; <span class="lean-keyword">with</span> rfl | hm_gt1
  <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket">[</span>psi_one<span class="lean-bracket">]</span>; <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> one_mem_integerMatrixOrders <span class="lean-number">0</span>
  <span class="lean-operator">·</span> <span class="lean-comment">-- Case: m &gt; <span class="lean-number">1</span>, i.e., m &gt;= <span class="lean-number">2</span></span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hm_gt2 : <span class="lean-number">2</span> &lt; m := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
    <span class="lean-comment">-- Check if m is a prime power</span>
    <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> hpow : IsPrimePow m
    <span class="lean-operator">·</span> <span class="lean-comment">-- m is a prime power p^k</span>
      <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span>isPrimePow_nat_iff<span class="lean-bracket">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hpow
      <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-bracket">⟨</span>p, k, hp, hk, hpk<span class="lean-bracket">⟩</span> := hpow
      <span class="lean-keyword" data-docs="`subst x...` substitutes each hypothesis `x` with a definition found in the local context,
then eliminates the hypothesis.
- If `x` is a local definition, then its definition is used.
- Otherwise, if there is a hypothesis of the form `x = e` or `e = x`,
  then `e` is used for the definition of `x`.

If `h : a = b`, then `subst h` may be used if either `a` or `b` unfolds to a local hypothesis.
This is similar to the `cases h` tactic.

See also: `subst_vars` for substituting all local hypotheses that have a defining equation.
">subst</span> hpk
      <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> h21 : p = <span class="lean-number">2</span> <span class="lean-operator">∧</span> k = <span class="lean-number">1</span>
      <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-bracket">⟨</span>rfl, rfl<span class="lean-bracket">⟩</span> := h21; <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket">[</span>pow_one<span class="lean-bracket">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hm_gt2; <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
      <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> primePow_mem_integerMatrixOrders_psi p k hp hk h21
    <span class="lean-operator">·</span> <span class="lean-comment">-- m is not a prime power: use factorization_split_lt</span>
      <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-bracket">⟨</span>p, e, m&#x27;, hp, he_pos, hm_eq, hcop, _, hm&#x27;_lt, _<span class="lean-bracket">⟩</span> :=
        factorization_split_lt <span class="lean-bracket">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span> : <span class="lean-number">2</span> &lt; m<span class="lean-bracket">)</span> hpow
      <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> h_pe_is_2 : p = <span class="lean-number">2</span> <span class="lean-operator">∧</span> e = <span class="lean-number">1</span>
      <span class="lean-operator">·</span> <span class="lean-comment">-- p^e = <span class="lean-number">2</span>, so m = <span class="lean-number">2</span> * m&#x27; with m&#x27; odd</span>
        <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hcop&#x27; : Nat.Coprime <span class="lean-number">2</span> m&#x27; := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket">[</span>h_pe_is_2.<span class="lean-number">1</span>, h_pe_is_2.<span class="lean-number">2</span>, pow_one<span class="lean-bracket">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hcop <span class="lean-operator">⊢</span>; <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> hcop
        <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-bracket">⟨</span>hm&#x27;_odd, hm&#x27;_ne_2, hm&#x27;_ge3<span class="lean-bracket">⟩</span> := odd_ne_two_ge_three_of_coprime_two hcop&#x27; <span class="lean-bracket">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span><span class="lean-bracket">)</span>
        <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span><span class="lean-keyword">show</span> m = <span class="lean-number">2</span> * m&#x27; <span class="lean-keyword">by</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket">[</span>h_pe_is_2.<span class="lean-number">1</span>, h_pe_is_2.<span class="lean-number">2</span>, pow_one<span class="lean-bracket">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hm_eq; <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span><span class="lean-bracket">]</span>
        <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> mem_integerMatrixOrders_psi_2_times_odd m&#x27; <span class="lean-bracket">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span><span class="lean-bracket">)</span> hm&#x27;_odd hm&#x27;_ge3
          <span class="lean-bracket">(</span>IH m&#x27; hm&#x27;_lt <span class="lean-bracket">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span><span class="lean-bracket">)</span> hm&#x27;_ne_2<span class="lean-bracket">)</span>
      <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> hm&#x27;_eq_2 : m&#x27; = <span class="lean-number">2</span>
        <span class="lean-operator">·</span> <span class="lean-comment">-- m&#x27; = <span class="lean-number">2</span>, so m = p^e * <span class="lean-number">2</span> with p^e odd</span>
          <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-bracket">⟨</span>hpe_odd, hpe_ge3<span class="lean-bracket">⟩</span> := primePow_odd_ge_three_of_coprime_two hp he_pos <span class="lean-bracket">(</span>hm&#x27;_eq_2 ▸ hcop<span class="lean-bracket">)</span>
          <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span><span class="lean-operator">←</span> hm_eq, hm&#x27;_eq_2<span class="lean-bracket">]</span>
          <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> mem_integerMatrixOrders_psi_odd_times_2 <span class="lean-bracket">(</span>p ^ e<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>Nat.pow_pos hp.pos<span class="lean-bracket">)</span> hpe_odd hpe_ge3
            <span class="lean-bracket">(</span>primePow_mem_integerMatrixOrders_psi p e hp he_pos h_pe_is_2<span class="lean-bracket">)</span>
        <span class="lean-operator">·</span> <span class="lean-comment">-- Neither is <span class="lean-number">2</span>, use block diagonal construction</span>
          <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket">[</span><span class="lean-operator">←</span> hm_eq<span class="lean-bracket">]</span>
          <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> mem_integerMatrixOrders_psi_composite p e m&#x27; hp <span class="lean-bracket">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span><span class="lean-bracket">)</span> hcop
            <span class="lean-bracket">(</span>primePow_mem_integerMatrixOrders_psi p e hp he_pos h_pe_is_2<span class="lean-bracket">)</span>
            <span class="lean-bracket">(</span>IH m&#x27; hm&#x27;_lt <span class="lean-bracket">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span><span class="lean-bracket">)</span> hm&#x27;_eq_2<span class="lean-bracket">)</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Backward.lean#L295-L360" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('thm:mem-integerMatrixOrders-psi');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="thm:backward-direction">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.18</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#thm:backward-direction">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000061"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0003.html#integerMatrixOrders-def">Definition 3.0.1</a></li>
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0004.html#companion-def">Definition 4.0.1</a></li>
          
          <li><a href="sect0004.html#thm:companion-charpoly">Theorem 4.0.1</a></li>
          
          <li><a href="sect0004.html#thm:companion-cycl-order">Theorem 4.0.5</a></li>
          
          <li><a href="sect0004.html#thm:mem-orders-totient">Theorem 4.0.7</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0003.html#lem:orders-mono">Theorem 3.0.3</a></li>
          
          <li><a href="sect0002.html#lem:psi-prime-pow">Theorem 2.0.1</a></li>
          
          <li><a href="sect0004.html#thm:companion-cycl-mem">Theorem 4.0.6</a></li>
          
          <li><a href="sect0005.html#thm:mem-integerMatrixOrders-psi">Theorem 5.0.17</a></li>
          
          <li><a href="sect0005.html#lem:mem-integerMatrixOrders-self">Theorem 5.0.15</a></li>
          
          <li><a href="sect0002.html#lem:psi-coprime-add">Theorem 2.0.3</a></li>
          
          <li><a href="sect0004.html#thm:mem-orders-totient">Theorem 4.0.7</a></li>
          
          <li><a href="sect0003.html#lem:one-mem-orders">Theorem 3.0.1</a></li>
          
          <li><a href="sect0003.html#lem:two-mem-orders">Theorem 3.0.2</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.mem_integerMatrixOrders_of_psi_le" class="lean_decl">Crystallographic.mem_integerMatrixOrders_of_psi_le</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        <b class="bfseries">Backward Direction:</b> If \(\psi (m) \leq N\), then \(m \in \mathrm{Ord}_N\). </p>
<p><b class="bfseries">Mathematical context:</b> The companion matrix of a monic polynomial \(p(X)\) has \(p(X)\) as both its characteristic and minimal polynomial. For the cyclotomic polynomial \(\Phi _m\), the companion matrix \(C_m\) satisfies \(\Phi _m(C_m) = 0\), so \(C_m^m = I\), and since \(\Phi _m\) is minimal (irreducible over \(\mathbb {Q}\) and dividing \(X^m - 1\) but not \(X^k - 1\) for \(k {\lt} m\)), we get \(\mathrm{ord}(C_m) = m\). The key optimization in the \(\psi \) function is that \(\psi (2) = 0\): order 2 is achieved by \(-I\) in any dimension, so we do not need to “pay” \(\varphi (2) = 1\) for the factor of 2. </p>
<p><b class="bfseries">Proof by explicit construction:</b> </p>
<ol class="enumerate">
  <li><p>For \(m = 1\): Use the identity matrix (any dimension). </p>
</li>
  <li><p>For \(m = 2\): Use \(-I\) (dimension \(\geq 1\)), achieving order 2 without adding to \(\psi \). </p>
</li>
  <li><p>For odd prime power \(p^k\): The companion matrix of \(\Phi _{p^k}\) has size \(\varphi (p^k)\). </p>
</li>
  <li><p>For \(2^k\) with \(k \geq 2\): The companion matrix of \(\Phi _{2^k}\) has size \(\varphi (2^k) = 2^{k-1}\). </p>
</li>
  <li><p>For \(m = 2m'\) with \(m'\) odd: If \(A\) has order \(m'\), then \(-A\) has order \(2m'\) (same dimension). </p>
</li>
  <li><p>For general \(m = \prod p_i^{k_i}\): Block diagonal of companion matrices for \(p_i^{k_i}\) with \(p_i \neq 2\) or \(k_i \geq 2\). The orders combine via \(\mathrm{lcm}\) (which equals the product for coprime factors), giving total order \(m\) in dimension \(\psi (m)\). </p>
</li>
  <li><p>Pad with identity blocks to reach size \(N \times N\) (padding does not change order). </p>
</li>
</ol>
<p>  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000061">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> We construct a matrix of order \(m\) in dimension \(\psi (m)\) by taking block diagonals of companion matrices for cyclotomic polynomials \(\Phi _{p^k}\) of each prime power factor. The companion matrix \(C(\Phi _{p^k})\) has order exactly \(p^k\) and size \(\varphi (p^k)\). Block diagonal matrices have order equal to the lcm of block orders, which equals \(m\) for coprime factors. Identity padding extends to dimension \(N \geq \psi (m)\). - </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> mem_integerMatrixOrders_of_psi_le <span class="lean-bracket">(</span>N m : ℕ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hm : <span class="lean-number">0</span> &lt; m<span class="lean-bracket">)</span>
    <span class="lean-bracket">(</span>hpsi : psi m <span class="lean-operator">≤</span> N<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hNm : m = <span class="lean-number">1</span> <span class="lean-operator">∨</span> <span class="lean-number">0</span> &lt; N<span class="lean-bracket">)</span> :
    m <span class="lean-operator">∈</span> integerMatrixOrders N :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-comment">-- Handle base cases m = <span class="lean-number">1</span>, <span class="lean-number">2</span></span>
  <span class="lean-keyword" data-docs="`rcases` is a tactic that will perform `cases` recursively, according to a pattern. It is used to
destructure hypotheses or expressions composed of inductive types like `h1 : a ∧ b ∧ c ∨ d` or
`h2 : ∃ x y, trans_rel R x y`. Usual usage might be `rcases h1 with ⟨ha, hb, hc⟩ | hd` or
`rcases h2 with ⟨x, y, _ | ⟨z, hxz, hzy⟩⟩` for these examples.

Each element of an `rcases` pattern is matched against a particular local hypothesis (most of which
are generated during the execution of `rcases` and represent individual elements destructured from
the input expression). An `rcases` pattern has the following grammar:

* A name like `x`, which names the active hypothesis as `x`.
* A blank `_`, which does nothing (letting the automatic naming system used by `cases` name the
  hypothesis).
* A hyphen `-`, which clears the active hypothesis and any dependents.
* The keyword `rfl`, which expects the hypothesis to be `h : a = b`, and calls `subst` on the
  hypothesis (which has the effect of replacing `b` with `a` everywhere or vice versa).
* A type ascription `p : ty`, which sets the type of the hypothesis to `ty` and then matches it
  against `p`. (Of course, `ty` must unify with the actual type of `h` for this to work.)
* A tuple pattern `⟨p1, p2, p3⟩`, which matches a constructor with many arguments, or a series
  of nested conjunctions or existentials. For example if the active hypothesis is `a ∧ b ∧ c`,
  then the conjunction will be destructured, and `p1` will be matched against `a`, `p2` against `b`
  and so on.
* A `@` before a tuple pattern as in `@⟨p1, p2, p3⟩` will bind all arguments in the constructor,
  while leaving the `@` off will only use the patterns on the explicit arguments.
* An alternation pattern `p1 | p2 | p3`, which matches an inductive type with multiple constructors,
  or a nested disjunction like `a ∨ b ∨ c`.

A pattern like `⟨a, b, c⟩ | ⟨d, e⟩` will do a split over the inductive datatype,
naming the first three parameters of the first constructor as `a,b,c` and the
first two of the second constructor `d,e`. If the list is not as long as the
number of arguments to the constructor or the number of constructors, the
remaining variables will be automatically named. If there are nested brackets
such as `⟨⟨a⟩, b | c⟩ | d` then these will cause more case splits as necessary.
If there are too many arguments, such as `⟨a, b, c⟩` for splitting on
`∃ x, ∃ y, p x`, then it will be treated as `⟨a, ⟨b, c⟩⟩`, splitting the last
parameter as necessary.

`rcases` also has special support for quotient types: quotient induction into Prop works like
matching on the constructor `quot.mk`.

`rcases h : e with PAT` will do the same as `rcases e with PAT` with the exception that an
assumption `h : e = PAT` will be added to the context.
">rcases</span> Nat.lt_trichotomy m <span class="lean-number">2</span> <span class="lean-keyword">with</span> hm_lt2 | rfl | hm_gt2
  <span class="lean-operator">·</span> <span class="lean-comment">-- m &lt; <span class="lean-number">2</span> and <span class="lean-number">0</span> &lt; m, so m = <span class="lean-number">1</span></span>
    <span class="lean-keyword" data-docs="`interval_cases n` searches for upper and lower bounds on a variable `n`,
and if bounds are found,
splits into separate cases for each possible value of `n`.

As an example, in
```
example (n : ℕ) (w₁ : n ≥ 3) (w₂ : n &lt; 5) : n = 3 ∨ n = 4 := by
  interval_cases n
  all_goals simp
```
after `interval_cases n`, the goals are `3 = 3 ∨ 3 = 4` and `4 = 3 ∨ 4 = 4`.

You can also explicitly specify a lower and upper bound to use,
as `interval_cases using hl, hu`.
The hypotheses should be in the form `hl : a ≤ n` and `hu : n &lt; b`,
in which case `interval_cases` calls `fin_cases` on the resulting fact `n ∈ Set.Ico a b`.

You can specify a name `h` for the new hypothesis,
as `interval_cases h : n` or `interval_cases h : n using hl, hu`.
">interval_cases</span> m
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> one_mem_integerMatrixOrders N
  <span class="lean-operator">·</span> <span class="lean-comment">-- m = <span class="lean-number">2</span>: use -I, need N &gt; <span class="lean-number">0</span></span>
    <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`cases x` splits the main goal, producing one goal for each constructor of the
inductive type, in which the target is replaced by a general instance of that constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the case split affects that hypothesis as well.
`cases` detects unreachable cases and closes them automatically.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`cases n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypothesis `h : P (Nat.succ a)` and target `Q (Nat.succ a)`.
Here the name `a` is chosen automatically and is not accessible.
You can use `with` to provide the variables names for each constructor.
- `cases e`, where `e` is an expression instead of a variable, generalizes `e` in the goal,
  and then cases on the resulting variable.
- Given `as : List α`, `cases as with | nil =&gt; tac₁ | cons a as&#x27; =&gt; tac₂`,
  uses tactic `tac₁` for the `nil` case, and `tac₂` for the `cons` case,
  and `a` and `as&#x27;` are used as names for the new variables introduced.
- `cases h : e`, where `e` is a variable or an expression,
  performs cases on `e` as above, but also adds a hypothesis `h : e = ...` to each goal,
  where `...` is the constructor instance for that particular case.
">cases</span> hNm <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
">with</span>
    | inl h =&gt; <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
    | inr hN_pos =&gt;
      <span class="lean-keyword" data-docs="`haveI` behaves like `have`, but inlines the value instead of producing a `have` term. ">haveI</span> : NeZero N := <span class="lean-bracket">⟨</span>Nat.pos_iff_ne_zero.mp hN_pos<span class="lean-bracket">⟩</span>
      <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> two_mem_integerMatrixOrders N
  <span class="lean-operator">·</span> <span class="lean-comment">-- m &gt; <span class="lean-number">2</span>, i.e., m &gt;= <span class="lean-number">3</span></span>
    <span class="lean-comment">-- If m <span class="lean-operator">≤</span> N, use permutation matrix directly</span>
    <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> hle : m <span class="lean-operator">≤</span> N
    <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> integerMatrixOrders_mono hle <span class="lean-bracket">(</span>mem_integerMatrixOrders_self m <span class="lean-bracket">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span><span class="lean-bracket">)</span><span class="lean-bracket">)</span>
    <span class="lean-operator">·</span> <span class="lean-comment">-- m &gt; N: need companion matrices</span>
      <span class="lean-keyword" data-docs="Push negations into the conclusion or a hypothesis.
For instance, a hypothesis `h : ¬ ∀ x, ∃ y, x ≤ y` will be transformed by `push_neg at h` into
`h : ∃ x, ∀ y, y &lt; x`. Binder names are preserved.

`push_neg` is a special case of the more general `push` tactic, namely `push Not`.
The `push` tactic can be extended using the `@[push]` attribute. `push` has special-casing
built in for `push Not`, so that it can preserve binder names, and so that `¬ (p ∧ q)` can be
transformed to either `p → ¬ q` (default) or `¬ p ∨ ¬ q` (`push_neg +distrib`).

Tactics that introduce a negation usually have a version that automatically calls `push_neg` on
that negation. These include `by_cases!`, `contrapose!` and `by_contra!`.

Another example: given a hypothesis
```lean
h : ¬ ∀ ε &gt; 0, ∃ δ &gt; 0, ∀ x, |x - x₀| ≤ δ → |f x - y₀| ≤ ε
```
writing `push_neg at h` will turn `h` into
```lean
h : ∃ ε &gt; 0, ∀ δ &gt; 0, ∃ x, |x - x₀| ≤ δ ∧ ε &lt; |f x - y₀|
```
Note that binder names are preserved by this tactic, contrary to what would happen with `simp`
using the relevant lemmas. One can use this tactic at the goal using `push_neg`,
at every hypothesis and the goal using `push_neg at *` or at selected hypotheses and the goal
using say `push_neg at h h&#x27; ⊢`, as usual.
">push_neg</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hle
      <span class="lean-comment">-- Case split on m</span>
      <span class="lean-keyword" data-docs="`rcases` is a tactic that will perform `cases` recursively, according to a pattern. It is used to
destructure hypotheses or expressions composed of inductive types like `h1 : a ∧ b ∧ c ∨ d` or
`h2 : ∃ x y, trans_rel R x y`. Usual usage might be `rcases h1 with ⟨ha, hb, hc⟩ | hd` or
`rcases h2 with ⟨x, y, _ | ⟨z, hxz, hzy⟩⟩` for these examples.

Each element of an `rcases` pattern is matched against a particular local hypothesis (most of which
are generated during the execution of `rcases` and represent individual elements destructured from
the input expression). An `rcases` pattern has the following grammar:

* A name like `x`, which names the active hypothesis as `x`.
* A blank `_`, which does nothing (letting the automatic naming system used by `cases` name the
  hypothesis).
* A hyphen `-`, which clears the active hypothesis and any dependents.
* The keyword `rfl`, which expects the hypothesis to be `h : a = b`, and calls `subst` on the
  hypothesis (which has the effect of replacing `b` with `a` everywhere or vice versa).
* A type ascription `p : ty`, which sets the type of the hypothesis to `ty` and then matches it
  against `p`. (Of course, `ty` must unify with the actual type of `h` for this to work.)
* A tuple pattern `⟨p1, p2, p3⟩`, which matches a constructor with many arguments, or a series
  of nested conjunctions or existentials. For example if the active hypothesis is `a ∧ b ∧ c`,
  then the conjunction will be destructured, and `p1` will be matched against `a`, `p2` against `b`
  and so on.
* A `@` before a tuple pattern as in `@⟨p1, p2, p3⟩` will bind all arguments in the constructor,
  while leaving the `@` off will only use the patterns on the explicit arguments.
* An alternation pattern `p1 | p2 | p3`, which matches an inductive type with multiple constructors,
  or a nested disjunction like `a ∨ b ∨ c`.

A pattern like `⟨a, b, c⟩ | ⟨d, e⟩` will do a split over the inductive datatype,
naming the first three parameters of the first constructor as `a,b,c` and the
first two of the second constructor `d,e`. If the list is not as long as the
number of arguments to the constructor or the number of constructors, the
remaining variables will be automatically named. If there are nested brackets
such as `⟨⟨a⟩, b | c⟩ | d` then these will cause more case splits as necessary.
If there are too many arguments, such as `⟨a, b, c⟩` for splitting on
`∃ x, ∃ y, p x`, then it will be treated as `⟨a, ⟨b, c⟩⟩`, splitting the last
parameter as necessary.

`rcases` also has special support for quotient types: quotient induction into Prop works like
matching on the constructor `quot.mk`.

`rcases h : e with PAT` will do the same as `rcases e with PAT` with the exception that an
assumption `h : e = PAT` will be added to the context.
">rcases</span> Nat.lt_trichotomy m <span class="lean-number">5</span> <span class="lean-keyword">with</span> hm_lt5 | rfl | hm_gt5
      <span class="lean-operator">·</span> <span class="lean-comment">-- m <span class="lean-operator">∈</span> <span class="lean-bracket">{</span><span class="lean-number">3</span>, <span class="lean-number">4</span><span class="lean-bracket">}</span>: use small case helper</span>
        <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hm34 : m <span class="lean-operator">∈</span> <span class="lean-bracket">(</span><span class="lean-bracket">{</span><span class="lean-number">3</span>, <span class="lean-number">4</span>, <span class="lean-number">6</span><span class="lean-bracket">}</span> : Finset ℕ<span class="lean-bracket">)</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
          <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket">[</span>Finset.mem_insert, Finset.mem_singleton<span class="lean-bracket">]</span>
          <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
        <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> mem_integerMatrixOrders_small m N hm34 hpsi
      <span class="lean-operator">·</span> <span class="lean-comment">-- m = <span class="lean-number">5</span></span>
        <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> mem_integerMatrixOrders_five N hpsi
      <span class="lean-operator">·</span> <span class="lean-comment">-- m &gt; <span class="lean-number">5</span></span>
        <span class="lean-keyword" data-docs="`rcases` is a tactic that will perform `cases` recursively, according to a pattern. It is used to
destructure hypotheses or expressions composed of inductive types like `h1 : a ∧ b ∧ c ∨ d` or
`h2 : ∃ x y, trans_rel R x y`. Usual usage might be `rcases h1 with ⟨ha, hb, hc⟩ | hd` or
`rcases h2 with ⟨x, y, _ | ⟨z, hxz, hzy⟩⟩` for these examples.

Each element of an `rcases` pattern is matched against a particular local hypothesis (most of which
are generated during the execution of `rcases` and represent individual elements destructured from
the input expression). An `rcases` pattern has the following grammar:

* A name like `x`, which names the active hypothesis as `x`.
* A blank `_`, which does nothing (letting the automatic naming system used by `cases` name the
  hypothesis).
* A hyphen `-`, which clears the active hypothesis and any dependents.
* The keyword `rfl`, which expects the hypothesis to be `h : a = b`, and calls `subst` on the
  hypothesis (which has the effect of replacing `b` with `a` everywhere or vice versa).
* A type ascription `p : ty`, which sets the type of the hypothesis to `ty` and then matches it
  against `p`. (Of course, `ty` must unify with the actual type of `h` for this to work.)
* A tuple pattern `⟨p1, p2, p3⟩`, which matches a constructor with many arguments, or a series
  of nested conjunctions or existentials. For example if the active hypothesis is `a ∧ b ∧ c`,
  then the conjunction will be destructured, and `p1` will be matched against `a`, `p2` against `b`
  and so on.
* A `@` before a tuple pattern as in `@⟨p1, p2, p3⟩` will bind all arguments in the constructor,
  while leaving the `@` off will only use the patterns on the explicit arguments.
* An alternation pattern `p1 | p2 | p3`, which matches an inductive type with multiple constructors,
  or a nested disjunction like `a ∨ b ∨ c`.

A pattern like `⟨a, b, c⟩ | ⟨d, e⟩` will do a split over the inductive datatype,
naming the first three parameters of the first constructor as `a,b,c` and the
first two of the second constructor `d,e`. If the list is not as long as the
number of arguments to the constructor or the number of constructors, the
remaining variables will be automatically named. If there are nested brackets
such as `⟨⟨a⟩, b | c⟩ | d` then these will cause more case splits as necessary.
If there are too many arguments, such as `⟨a, b, c⟩` for splitting on
`∃ x, ∃ y, p x`, then it will be treated as `⟨a, ⟨b, c⟩⟩`, splitting the last
parameter as necessary.

`rcases` also has special support for quotient types: quotient induction into Prop works like
matching on the constructor `quot.mk`.

`rcases h : e with PAT` will do the same as `rcases e with PAT` with the exception that an
assumption `h : e = PAT` will be added to the context.
">rcases</span> Nat.lt_trichotomy m <span class="lean-number">6</span> <span class="lean-keyword">with</span> hm_lt6 | rfl | hm_gt6
        <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span> <span class="lean-comment">-- impossible: <span class="lean-number">5</span> &lt; m &lt; <span class="lean-number">6</span></span>
        <span class="lean-operator">·</span> <span class="lean-comment">-- m = <span class="lean-number">6</span></span>
          <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> mem_integerMatrixOrders_small <span class="lean-number">6</span> N <span class="lean-bracket">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span><span class="lean-bracket">)</span> hpsi
        <span class="lean-operator">·</span> <span class="lean-comment">-- m &gt; <span class="lean-number">6</span>: general case</span>
          <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> mem_integerMatrixOrders_of_psi_le_large m N hm_gt6 hpsi</code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/CrystallographicRestriction/Backward.lean#L404-L485" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('thm:backward-direction');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="thm:main-theorem">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">5.0.19</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0005.html#thm:main-theorem">#</a>
    
    <a class="icon proof" href="sect0005.html#a0000000062"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0003.html#integerMatrixOrders-def">Definition 3.0.1</a></li>
          
          <li><a href="sect0005.html#thm:backward-direction">Theorem 5.0.18</a></li>
          
          <li><a href="sect0005.html#thm:forward-direction">Theorem 5.0.7</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.crystallographic_restriction" class="lean_decl">Crystallographic.crystallographic_restriction</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        <b class="bfseries">The Crystallographic Restriction Theorem:</b> An \(N \times N\) integer matrix can have finite order \(m\) if and only if \(\psi (m) \leq N\). </p>
<p>Equivalently: \(m \in \mathrm{Ord}_N \iff \psi (m) \leq N\). </p>
<p>This theorem completely characterizes which rotation orders are achievable by integer matrices in each dimension. The function \(\psi \) is defined as: \(\psi (1) = \psi (2) = 0\), and for other \(m\), \(\psi (m) = \sum _{p^k \|  m, p \neq 2 \text{ or } k \geq 2} \varphi (p^k)\). </p>
<p><b class="bfseries">Forward direction:</b> If \(A \in \mathbb {Z}^{N \times N}\) has order \(m\), the minimal polynomial of \(A\) over \(\mathbb {Q}\) divides \(X^m - 1\) and must include cyclotomic factors \(\Phi _d\) for divisors \(d\) whose lcm equals \(m\). The sum of \(\varphi (d)\) over these divisors is at least \(\psi (m)\), and this sum bounds the degree of the minimal polynomial, which is at most \(N\). </p>
<p><b class="bfseries">Backward direction:</b> For each prime power \(p^k\) (with \(p \neq 2\) or \(k \geq 2\)), the companion matrix of \(\Phi _{p^k}\) has size \(\varphi (p^k)\) and order \(p^k\). For general \(m\), block diagonal combinations of these companion matrices achieve order \(m\) in dimension \(\psi (m)\). - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000062">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> The proof combines the forward and backward directions. The forward direction shows that eigenvalue constraints force \(\psi (m) \leq N\). The backward direction constructs explicit matrices achieving each order using companion matrices of cyclotomic polynomials. - </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> crystallographic_restriction <span class="lean-bracket">(</span>N m : ℕ<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hm : <span class="lean-number">0</span> &lt; m<span class="lean-bracket">)</span> <span class="lean-bracket">(</span>hNm : m = <span class="lean-number">1</span> <span class="lean-operator">∨</span> <span class="lean-number">0</span> &lt; N<span class="lean-bracket">)</span> :
    m <span class="lean-operator">∈</span> integerMatrixOrders N <span class="lean-operator">↔</span> psi m <span class="lean-operator">≤</span> N :=</code><code class="lean-proof-body">
  <span class="lean-bracket">⟨</span>psi_le_of_mem_integerMatrixOrders N m hm,
   <span class="lean-keyword">fun</span> hpsi =&gt; mem_integerMatrixOrders_of_psi_le N m hm hpsi hNm<span class="lean-bracket">⟩</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/MainTheorem.lean#L42-L75" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('thm:main-theorem');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>




</div> <!--main-text -->
</div> <!-- content-wrapper -->
</div> <!-- content -->
</div> <!-- wrapper -->

<nav class="prev_up_next">
  <svg  id="showmore-minus" class="icon icon-eye-minus showmore"><use xlink:href="symbol-defs.svg#icon-eye-minus"></use></svg>

  <svg  id="showmore-plus" class="icon icon-eye-plus showmore"><use xlink:href="symbol-defs.svg#icon-eye-plus"></use></svg>

  <a href="sect0004.html" title="Companion Matrices"><svg  class="icon icon-arrow-left "><use xlink:href="symbol-defs.svg#icon-arrow-left"></use></svg>
</a>
  <a href="index.html" title="Crystallographic Restriction Theorem"><svg  class="icon icon-arrow-up "><use xlink:href="symbol-defs.svg#icon-arrow-up"></use></svg>
</a>
  <a href="sect0006.html" title="Appendix"><svg  class="icon icon-arrow-right "><use xlink:href="symbol-defs.svg#icon-arrow-right"></use></svg>
</a>
</nav>

<script type="text/javascript" src="js/jquery.min.js"></script>
<script type="text/javascript" src="js/plastex.js"></script>
<script type="text/javascript" src="js/svgxuse.js"></script>
<script type="text/javascript" src="js/js.cookie.min.js"></script>
<script type="text/javascript" src="js/showmore.js"></script>
</body>
</html>