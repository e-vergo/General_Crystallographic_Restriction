<!DOCTYPE html>
<html lang="en">
<head>
<script>
  MathJax = { 
    tex: {
		    inlineMath: [['$','$'], ['\\(','\\)']]
	} }
</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
<meta name="generator" content="plasTeX" />
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>The Psi Function</title>
<link rel="next" href="sect0003.html" title="Integer Matrix Orders" />
<link rel="prev" href="sect0001.html" title="Introduction" />
<link rel="up" href="index.html" title="Crystallographic Restriction Theorem" />
<link rel="stylesheet" href="styles/theme-blue.css" />
<link rel="stylesheet" href="styles/showmore.css" />
<link rel="stylesheet" href="styles/blueprint.css" />
<link rel="stylesheet" href="styles/amsthm.css" />
<link rel="stylesheet" href="styles/style.css" />
</head>

<body>
<header>
<svg  id="toc-toggle" class="icon icon-list-numbered "><use xlink:href="symbol-defs.svg#icon-list-numbered"></use></svg>
<h1 id="doc_title"><a href="index.html">Crystallographic Restriction Theorem</a></h1>
</header>

<div class="wrapper">
<nav class="toc">
<ul class="sub-toc-0">
<li class="">
  <a href="sect0001.html"><span class="toc_ref">1</span> <span class="toc_entry">Introduction</span></a>
 </li>
<li class=" active current">
  <a href="sect0002.html"><span class="toc_ref">2</span> <span class="toc_entry">The Psi Function</span></a>
 </li>
<li class="">
  <a href="sect0003.html"><span class="toc_ref">3</span> <span class="toc_entry">Integer Matrix Orders</span></a>
 </li>
<li class="">
  <a href="sect0004.html"><span class="toc_ref">4</span> <span class="toc_entry">Companion Matrices</span></a>
 </li>
<li class="">
  <a href="sect0005.html"><span class="toc_ref">5</span> <span class="toc_entry">The Crystallographic Restriction Theorem</span></a>
 </li>
<li class="">
  <a href="sect0006.html"><span class="toc_ref">A</span> <span class="toc_entry">Appendix</span></a>
 </li>
<li ><a href="dep_graph_document.html">Dependency graph</a></li>
</ul>
</nav>

<div class="content">
<div class="content-wrapper">


<div class="main-text">
<h1 id="a0000000003">2 The Psi Function</h1>
<p>The \(\psi \) function measures the “arithmetic complexity” of a positive integer \(m\). For a prime power \(p^k\), we define: </p>
<ul class="itemize">
  <li><p>\(\psi _{\mathrm{pp}}(p,k) = \varphi (p^k)\) for \(p\) odd or \(k \geq 2\) </p>
</li>
  <li><p>\(\psi _{\mathrm{pp}}(2,1) = 0\) </p>
</li>
</ul>
<p>For a general integer \(m\) with prime factorization \(m = \prod _i p_i^{k_i}\), we have: </p>
<div class="displaymath" id="a0000000011">
  \[ \psi (m) = \sum _i \psi _{\mathrm{pp}}(p_i, k_i) \]
</div>
<div class="definition_thmwrapper sbs-container theorem-style-definition" id="psiPrimePow-def">
  <div class="sbs-latex-column">
    <div class="definition_thmheading">
      <span class="definition_thmcaption">
      Definition
      </span>
      <span class="definition_thmlabel">2.0.1</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#psiPrimePow-def">#</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psiPrimePow" class="lean_decl">Crystallographic.psiPrimePow</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="definition_thmcontent">
    <p>      The function \(\psi _{\text{pp}}(p, k)\) computes the contribution of a single prime power \(p^k\) to \(\psi \). Returns \(0\) if \(k = 0\) or if \(p = 2\) and \(k = 1\), otherwise returns \(\varphi (p^k)\). </p>
<p>The special case \(\psi _{\text{pp}}(2, 1) = 0\) reflects that \(-I\) achieves order \(2\) in any dimension \(\geq 1\), so order \(2\) does not require additional dimensions. For all other prime powers \(p^k\), we need \(\varphi (p^k)\) dimensions to achieve order \(p^k\). </p>

    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">def</span> <span class="lean-text">psiPrimePow</span> <span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">k</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span> <span class="lean-text">:=</span>
  <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
">if</span> <span class="lean-text">k</span> <span class="lean-text">=</span> <span class="lean-text">0</span> <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
">then</span> <span class="lean-text">0</span>
  <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
">else</span> <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
">if</span> <span class="lean-text">p</span> <span class="lean-text">=</span> <span class="lean-text">2</span> <span class="lean-text">∧</span> <span class="lean-text">k</span> <span class="lean-text">=</span> <span class="lean-text">1</span> <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
">then</span> <span class="lean-text">0</span>
  <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
">else</span> <span class="lean-text">Nat.totient</span> <span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">k</span><span class="lean-text">)</span></code><code class="lean-proof-body"><span class="lean-plain">(p k : ℕ) : ℕ :=
  if k = 0 then 0
  else if p = 2 ∧ k = 1 then 0
  else Nat.totient (p ^ k)</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Basic.lean#L49-L63" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>

<div class="definition_thmwrapper sbs-container theorem-style-definition" id="psi-def">
  <div class="sbs-latex-column">
    <div class="definition_thmheading">
      <span class="definition_thmcaption">
      Definition
      </span>
      <span class="definition_thmlabel">2.0.2</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#psi-def">#</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psi" class="lean_decl">Crystallographic.psi</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="definition_thmcontent">
    <p>       The psi function \(\psi (m) = \sum _{p^k \|  m} \psi _{\text{pp}}(p, k)\), which gives the minimum dimension \(N\) such that an \(N \times N\) integer matrix can have order \(m\). </p>
<p>For \(m\) with prime factorization \(m = \prod _i p_i^{k_i}\): </p>
<div class="displaymath" id="a0000000012">
  \[ \psi (m) = \sum _i \psi _{\text{pp}}(p_i, k_i) = \sum _{\substack {p^k \|  m \\ (p,k) \neq (2,1)}} \varphi (p^k) \]
</div>
<p> This gives the minimum dimension needed to realize order \(m\).  </p>

    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">def</span> <span class="lean-text">psi</span> <span class="lean-text">(</span><span class="lean-text">m</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span> <span class="lean-text">:=</span>
  <span class="lean-text">m.factorization.sum</span> <span class="lean-keyword">fun</span> <span class="lean-text">p</span> <span class="lean-text">k</span> <span class="lean-text">=&gt;</span> <span class="lean-text">psiPrimePow</span> <span class="lean-text">p</span> <span class="lean-text">k</span></code><code class="lean-proof-body"><span class="lean-plain">(m : ℕ) : ℕ :=
  m.factorization.sum fun p k =&gt; psiPrimePow p k</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Basic.lean#L70-L87" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>

<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:psi-prime-pow">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.1</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:psi-prime-pow">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000013"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psi_prime_pow" class="lean_decl">Crystallographic.psi_prime_pow</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        For prime \(p\) and \(k {\gt} 0\): \(\psi (p^k) = \varphi (p^k)\) unless \(p = 2, k = 1\). </p>
<p>For a prime power \(p^k\), the factorization has a single term, so \(\psi (p^k) = \psi _{\text{pp}}(p, k)\). This equals \(\varphi (p^k) = p^{k-1}(p-1)\) except when \(p = 2\) and \(k = 1\).  </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000013">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> For prime power \(p^k\), the factorization has a single term, so \(\psi (p^k) = \psi _{pp}(p, k)\). This equals \(\varphi (p^k)\) except when \(p = 2, k = 1\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> <span class="lean-text">psi_prime_pow</span> <span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">k</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hp</span> <span class="lean-text">:</span> <span class="lean-text">p.Prime</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hk</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">k</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">psi</span> <span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">k</span><span class="lean-text">)</span> <span class="lean-text">=</span> <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
">if</span> <span class="lean-text">p</span> <span class="lean-text">=</span> <span class="lean-text">2</span> <span class="lean-text">∧</span> <span class="lean-text">k</span> <span class="lean-text">=</span> <span class="lean-text">1</span> <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
">then</span> <span class="lean-text">0</span> <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
">else</span> <span class="lean-text">Nat.totient</span> <span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">k</span><span class="lean-text">)</span> <span class="lean-text">:=</span></code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">psi</span><span class="lean-text">]</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">hp.factorization_pow</span><span class="lean-text">]</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">Finsupp.sum_single_index</span> <span class="lean-text">(</span><span class="lean-text">psiPrimePow_zero</span> <span class="lean-text">p</span><span class="lean-text">)</span><span class="lean-text">]</span>
  <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">psiPrimePow</span><span class="lean-text">,</span> <span class="lean-text">hk.ne&#x27;</span><span class="lean-text">,</span> <span class="lean-text">ite_false</span><span class="lean-text">]</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Basic.lean#L107-L122" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:psi-prime-pow');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:factorization-disjoint">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.2</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:factorization-disjoint">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000014"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.factorization_support_disjoint" class="lean_decl">Crystallographic.factorization_support_disjoint</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       Coprime numbers have disjoint prime factorization supports. </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000014">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>If \(p\) divides both \(m\) and \(n\), then \(p \mid \gcd (m,n) = 1\), contradicting \(p\) prime. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> <span class="lean-text">factorization_support_disjoint</span> <span class="lean-text">{</span><span class="lean-text">m</span> <span class="lean-text">n</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">}</span> <span class="lean-text">(</span><span class="lean-text">h</span> <span class="lean-text">:</span> <span class="lean-text">m.Coprime</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">Disjoint</span> <span class="lean-text">m.factorization.support</span> <span class="lean-text">n.factorization.support</span> <span class="lean-text">:=</span></code><code class="lean-proof-body">
  <span class="lean-text">Nat.support_factorization</span> <span class="lean-text">m</span> <span class="lean-text">▸</span> <span class="lean-text">Nat.support_factorization</span> <span class="lean-text">n</span> <span class="lean-text">▸</span> <span class="lean-text">h.disjoint_primeFactors</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Basic.lean#L161-L169" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:factorization-disjoint');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:psi-coprime-add">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.3</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:psi-coprime-add">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000015"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0002.html#lem:factorization-disjoint">Theorem 2.0.2</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0002.html#lem:factorization-disjoint">Theorem 2.0.2</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psi_coprime_add" class="lean_decl">Crystallographic.psi_coprime_add</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        \(\psi (mn) = \psi (m) + \psi (n)\) for coprime \(m, n\). </p>
<p>When \(\gcd (m, n) = 1\), the prime factorizations of \(m\) and \(n\) share no common primes, so </p>
<div class="displaymath" id="a0000000016">
  \[ \psi (mn) = \sum _{p^k \|  mn} \psi _{\text{pp}}(p, k) = \sum _{p^k \|  m} \psi _{\text{pp}}(p, k) + \sum _{p^k \|  n} \psi _{\text{pp}}(p, k) = \psi (m) + \psi (n). \]
</div>


    </div>
    <div class="proof_wrapper proof_inline" id="a0000000015">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> When \(\gcd (m, n) = 1\), the factorizations of \(m\) and \(n\) are disjoint. Each prime power in \(mn\) comes from exactly one of \(m\) or \(n\), so the \(\psi \) contributions add. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> <span class="lean-text">psi_coprime_add</span> <span class="lean-text">(</span><span class="lean-text">m</span> <span class="lean-text">n</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hm</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">m</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hn</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">h</span> <span class="lean-text">:</span> <span class="lean-text">m.Coprime</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">psi</span> <span class="lean-text">(</span><span class="lean-text">m</span> <span class="lean-text">*</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">=</span> <span class="lean-text">psi</span> <span class="lean-text">m</span> <span class="lean-text">+</span> <span class="lean-text">psi</span> <span class="lean-text">n</span> <span class="lean-text">:=</span></code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">psi</span><span class="lean-text">,</span> <span class="lean-text">Finsupp.sum</span><span class="lean-text">]</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">Nat.factorization_mul</span> <span class="lean-text">(</span><span class="lean-text">Nat.pos_iff_ne_zero.mp</span> <span class="lean-text">hm</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">Nat.pos_iff_ne_zero.mp</span> <span class="lean-text">hn</span><span class="lean-text">)</span><span class="lean-text">]</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hdisj</span> <span class="lean-text">:=</span> <span class="lean-text">factorization_support_disjoint</span> <span class="lean-text">h</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">Finsupp.support_add_eq</span> <span class="lean-text">hdisj</span><span class="lean-text">]</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">Finset.sum_union</span> <span class="lean-text">hdisj</span><span class="lean-text">]</span>
  <span class="lean-keyword" data-docs="Apply congruence (recursively) to goals of the form `⊢ f as = f bs` and `⊢ f as ≍ f bs`.
The optional parameter is the depth of the recursive applications.
This is useful when `congr` is too aggressive in breaking down the goal.
For example, given `⊢ f (g (x + y)) = f (g (y + x))`,
`congr` produces the goals `⊢ x = y` and `⊢ y = x`,
while `congr 2` produces the intended `⊢ x + y = y + x`.
">congr</span> <span class="lean-text">1</span>
  <span class="lean-text">·</span> <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> <span class="lean-text">Finset.sum_congr</span> <span class="lean-text">rfl</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">p</span> <span class="lean-text">hp</span>
    <span class="lean-keyword" data-docs="Apply congruence (recursively) to goals of the form `⊢ f as = f bs` and `⊢ f as ≍ f bs`.
The optional parameter is the depth of the recursive applications.
This is useful when `congr` is too aggressive in breaking down the goal.
For example, given `⊢ f (g (x + y)) = f (g (y + x))`,
`congr` produces the goals `⊢ x = y` and `⊢ y = x`,
while `congr 2` produces the intended `⊢ x + y = y + x`.
">congr</span> <span class="lean-text">1</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">Finsupp.add_apply</span><span class="lean-text">,</span> <span class="lean-text">factorization_eq_zero_of_disjoint_support</span> <span class="lean-text">hdisj</span> <span class="lean-text">hp</span><span class="lean-text">,</span> <span class="lean-text">add_zero</span><span class="lean-text">]</span>
  <span class="lean-text">·</span> <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> <span class="lean-text">Finset.sum_congr</span> <span class="lean-text">rfl</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">p</span> <span class="lean-text">hp</span>
    <span class="lean-keyword" data-docs="Apply congruence (recursively) to goals of the form `⊢ f as = f bs` and `⊢ f as ≍ f bs`.
The optional parameter is the depth of the recursive applications.
This is useful when `congr` is too aggressive in breaking down the goal.
For example, given `⊢ f (g (x + y)) = f (g (y + x))`,
`congr` produces the goals `⊢ x = y` and `⊢ y = x`,
while `congr 2` produces the intended `⊢ x + y = y + x`.
">congr</span> <span class="lean-text">1</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">Finsupp.add_apply</span><span class="lean-text">,</span> <span class="lean-text">factorization_eq_zero_of_disjoint_support</span> <span class="lean-text">hdisj.symm</span> <span class="lean-text">hp</span><span class="lean-text">,</span> <span class="lean-text">zero_add</span><span class="lean-text">]</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Basic.lean#L177-L208" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:psi-coprime-add');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:psi-ge-psiPrimePow">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.4</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:psi-ge-psiPrimePow">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000017"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psi_ge_psiPrimePow_of_mem_support" class="lean_decl">Crystallographic.psi_ge_psiPrimePow_of_mem_support</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        \(\psi (m) \geq \psi _{\mathrm{pp}}(p, v_p(m))\) for each prime \(p \mid m\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000017">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>The sum \(\psi (m)\) includes the term \(\psi _{\mathrm{pp}}(p, v_p(m))\), and all terms are non-negative. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> <span class="lean-text">psi_ge_psiPrimePow_of_mem_support</span> <span class="lean-text">{</span><span class="lean-text">m</span> <span class="lean-text">p</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">}</span>
    <span class="lean-text">(</span><span class="lean-text">hp</span> <span class="lean-text">:</span> <span class="lean-text">p</span> <span class="lean-text">∈</span> <span class="lean-text">m.factorization.support</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">psiPrimePow</span> <span class="lean-text">p</span> <span class="lean-text">(</span><span class="lean-text">m.factorization</span> <span class="lean-text">p</span><span class="lean-text">)</span> <span class="lean-text">≤</span> <span class="lean-text">psi</span> <span class="lean-text">m</span> <span class="lean-text">:=</span></code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">psi</span><span class="lean-text">,</span> <span class="lean-text">Finsupp.sum</span><span class="lean-text">]</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hnonneg</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">i</span> <span class="lean-text">∈</span> <span class="lean-text">m.factorization.support</span><span class="lean-text">,</span> <span class="lean-text">0</span> <span class="lean-text">≤</span> <span class="lean-text">psiPrimePow</span> <span class="lean-text">i</span> <span class="lean-text">(</span><span class="lean-text">m.factorization</span> <span class="lean-text">i</span><span class="lean-text">)</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">i</span> <span class="lean-text">_</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">psiPrimePow</span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="Splits all if-then-else-expressions into multiple goals.
Given a goal of the form `g (if p then x else y)`, `split_ifs` will produce
two goals: `p ⊢ g x` and `¬p ⊢ g y`.
If there are multiple ite-expressions, then `split_ifs` will split them all,
starting with a top-most one whose condition does not contain another
ite-expression.
`split_ifs at *` splits all ite-expressions in all hypotheses as well as the goal.
`split_ifs with h₁ h₂ h₃` overrides the default names for the hypotheses.
">split_ifs</span> <span class="lean-text">&lt;;&gt;</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
  <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">Finset.single_le_sum</span> <span class="lean-text">hnonneg</span> <span class="lean-text">hp</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Basic.lean#L230-L244" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:psi-ge-psiPrimePow');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:two-le-totient-prime-pow">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.5</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:two-le-totient-prime-pow">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000018"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.two_le_totient_primePow" class="lean_decl">Crystallographic.two_le_totient_primePow</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       For any prime power \(p^k {\gt} 2\), we have \(2 \leq \varphi (p^k)\). </p>
<p>Specifically, \(\varphi (p^k) = p^{k-1}(p-1) \geq 2\) unless \((p, k) = (2, 1)\), in which case \(\varphi (2) = 1\). This bound is essential for showing that sums of totients are bounded by products when factors are coprime.  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000018">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>By cases on \(p = 2\): if \(p \neq 2\), then \(p \geq 3\) so \(\varphi (p^k) = p^{k-1}(p-1) \geq 1 \cdot 2 = 2\). If \(p = 2\) and \(k \geq 2\), then \(\varphi (2^k) = 2^{k-1} \geq 2\). The case \((2, 1)\) is excluded by hypothesis. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> <span class="lean-text">two_le_totient_primePow</span> <span class="lean-text">{</span><span class="lean-text">p</span> <span class="lean-text">k</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">}</span> <span class="lean-text">(</span><span class="lean-text">hp</span> <span class="lean-text">:</span> <span class="lean-text">p.Prime</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hk</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">k</span><span class="lean-text">)</span>
    <span class="lean-text">(</span><span class="lean-text">h</span> <span class="lean-text">:</span> <span class="lean-text">¬</span><span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">=</span> <span class="lean-text">2</span> <span class="lean-text">∧</span> <span class="lean-text">k</span> <span class="lean-text">=</span> <span class="lean-text">1</span><span class="lean-text">)</span><span class="lean-text">)</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">≤</span> <span class="lean-text">Nat.totient</span> <span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">k</span><span class="lean-text">)</span> <span class="lean-text">:=</span></code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">Nat.totient_prime_pow</span> <span class="lean-text">hp</span> <span class="lean-text">hk</span><span class="lean-text">]</span>
  <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> <span class="lean-text">hp2</span> <span class="lean-text">:</span> <span class="lean-text">p</span> <span class="lean-text">=</span> <span class="lean-text">2</span>
  <span class="lean-text">·</span> <span class="lean-keyword" data-docs="This is a &quot;finishing&quot; tactic modification of `simp`. It has two forms.

* `simpa [rules, ⋯] using e` will simplify the goal and the type of
`e` using `rules`, then try to close the goal using `e`.

Simplifying the type of `e` makes it more likely to match the goal
(which has also been simplified). This construction also tends to be
more robust under changes to the simp lemma set.

* `simpa [rules, ⋯]` will simplify the goal and the type of a
hypothesis `this` if present in the context, then try to close the goal using
the `assumption` tactic.
">simpa</span> <span class="lean-text">[</span><span class="lean-text">hp2</span><span class="lean-text">]</span> <span class="lean-keyword">using</span> <span class="lean-text">Nat.pow_le_pow_right</span> <span class="lean-text">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span> <span class="lean-text">:</span> <span class="lean-text">1</span> <span class="lean-text">≤</span> <span class="lean-text">k</span> <span class="lean-text">-</span> <span class="lean-text">1</span><span class="lean-text">)</span>
  <span class="lean-text">·</span> <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hp3</span> <span class="lean-text">:</span> <span class="lean-text">3</span> <span class="lean-text">≤</span> <span class="lean-text">p</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.lt_of_le_of_ne</span> <span class="lean-text">hp.two_le</span> <span class="lean-text">(</span><span class="lean-text">Ne.symm</span> <span class="lean-text">hp2</span><span class="lean-text">)</span>
    <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
">calc</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">(</span><span class="lean-text">k</span> <span class="lean-text">-</span> <span class="lean-text">1</span><span class="lean-text">)</span> <span class="lean-text">*</span> <span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">-</span> <span class="lean-text">1</span><span class="lean-text">)</span> <span class="lean-text">≥</span> <span class="lean-text">1</span> <span class="lean-text">*</span> <span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">-</span> <span class="lean-text">1</span><span class="lean-text">)</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.mul_le_mul_right</span> <span class="lean-text">_</span> <span class="lean-text">(</span><span class="lean-text">Nat.one_le_pow</span> <span class="lean-text">_</span> <span class="lean-text">_</span> <span class="lean-text">hp.pos</span><span class="lean-text">)</span>
      <span class="lean-text">_</span> <span class="lean-text">≥</span> <span class="lean-text">2</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L39-L56" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:two-le-totient-prime-pow');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:factorization-split-lt">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.6</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:factorization-split-lt">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000019"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.factorization_split_lt" class="lean_decl">Crystallographic.factorization_split_lt</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       A composite number \(m {\gt} 2\) that is not a prime power can be written as \(m = p^e \cdot m'\) where \(p\) is prime, \(e {\gt} 0\), \(\gcd (p^e, m') = 1\), and both \(p^e {\lt} m\) and \(1 {\lt} m' {\lt} m\). </p>
<p>This decomposition is essential for strong induction proofs on composite numbers: it provides strictly smaller coprime factors to which the inductive hypothesis applies.  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000019">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>Take \(p = \mathrm{minFac}(m)\) and \(e = \nu _p(m)\), the \(p\)-adic valuation. Then \(m' = m / p^e\) is coprime to \(p^e\) (disjoint prime support). Since \(m\) is not a prime power, \(m' \neq 1\). The bounds \(p^e {\lt} m\) and \(m' {\lt} m\) follow from \(m' {\gt} 1\) and \(p^e \geq 2\) respectively. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> <span class="lean-text">factorization_split_lt</span> <span class="lean-text">{</span><span class="lean-text">m</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">}</span> <span class="lean-text">(</span><span class="lean-text">hm</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">&lt;</span> <span class="lean-text">m</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">h_not_pp</span> <span class="lean-text">:</span> <span class="lean-text">¬</span><span class="lean-text">IsPrimePow</span> <span class="lean-text">m</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">∃</span> <span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">e</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span><span class="lean-text">,</span> <span class="lean-text">p.Prime</span> <span class="lean-text">∧</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">e</span> <span class="lean-text">∧</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span> <span class="lean-text">*</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">=</span> <span class="lean-text">m</span> <span class="lean-text">∧</span>
    <span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">Coprime</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">∧</span> <span class="lean-text">1</span> <span class="lean-text">&lt;</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">∧</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">&lt;</span> <span class="lean-text">m</span> <span class="lean-text">∧</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span> <span class="lean-text">&lt;</span> <span class="lean-text">m</span> <span class="lean-text">:=</span></code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hm_ne_zero</span> <span class="lean-text">:</span> <span class="lean-text">m</span> <span class="lean-text">≠</span> <span class="lean-text">0</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hm_ne_one</span> <span class="lean-text">:</span> <span class="lean-text">m</span> <span class="lean-text">≠</span> <span class="lean-text">1</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hm_pos</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">m</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hminFac_prime</span> <span class="lean-text">:</span> <span class="lean-text">m.minFac.Prime</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.minFac_prime</span> <span class="lean-text">hm_ne_one</span>
  <span class="lean-keyword" data-docs="`set a := t with h` is a variant of `let a := t`. It adds the hypothesis `h : a = t` to
the local context and replaces `t` with `a` everywhere it can.

`set a := t with ← h` will add `h : t = a` instead.

`set! a := t with h` does not do any replacing.

```lean
example (x : Nat) (h : x + x - x = 3) : x + x - x = 3 := by
  set y := x with ← h2
  sorry
/-
x : Nat
y : Nat := x
h : y + y - y = 3
h2 : x = y
⊢ y + y - y = 3
-/
```
">set</span> <span class="lean-text">p</span> <span class="lean-text">:=</span> <span class="lean-text">m.minFac</span>
  <span class="lean-keyword" data-docs="`set a := t with h` is a variant of `let a := t`. It adds the hypothesis `h : a = t` to
the local context and replaces `t` with `a` everywhere it can.

`set a := t with ← h` will add `h : t = a` instead.

`set! a := t with h` does not do any replacing.

```lean
example (x : Nat) (h : x + x - x = 3) : x + x - x = 3 := by
  set y := x with ← h2
  sorry
/-
x : Nat
y : Nat := x
h : y + y - y = 3
h2 : x = y
⊢ y + y - y = 3
-/
```
">set</span> <span class="lean-text">e</span> <span class="lean-text">:=</span> <span class="lean-text">m.factorization</span> <span class="lean-text">p</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">he_pos</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">e</span> <span class="lean-text">:=</span>
    <span class="lean-text">Nat.Prime.factorization_pos_of_dvd</span> <span class="lean-text">hminFac_prime</span> <span class="lean-text">hm_ne_zero</span> <span class="lean-text">(</span><span class="lean-text">Nat.minFac_dvd</span> <span class="lean-text">m</span><span class="lean-text">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hdvd</span> <span class="lean-text">:</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span> <span class="lean-text">∣</span> <span class="lean-text">m</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.ordProj_dvd</span> <span class="lean-text">m</span> <span class="lean-text">p</span>
  <span class="lean-keyword" data-docs="`set a := t with h` is a variant of `let a := t`. It adds the hypothesis `h : a = t` to
the local context and replaces `t` with `a` everywhere it can.

`set a := t with ← h` will add `h : t = a` instead.

`set! a := t with h` does not do any replacing.

```lean
example (x : Nat) (h : x + x - x = 3) : x + x - x = 3 := by
  set y := x with ← h2
  sorry
/-
x : Nat
y : Nat := x
h : y + y - y = 3
h2 : x = y
⊢ y + y - y = 3
-/
```
">set</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">:=</span> <span class="lean-text">m</span> <span class="lean-text">/</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hm&#x27;_pos</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.div_pos</span> <span class="lean-text">(</span><span class="lean-text">Nat.le_of_dvd</span> <span class="lean-text">hm_pos</span> <span class="lean-text">hdvd</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">Nat.pow_pos</span> <span class="lean-text">hminFac_prime.pos</span><span class="lean-text">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hm_eq</span> <span class="lean-text">:</span> <span class="lean-text">m</span> <span class="lean-text">=</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span> <span class="lean-text">*</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">:=</span> <span class="lean-text">(</span><span class="lean-text">Nat.mul_div_cancel&#x27;</span> <span class="lean-text">hdvd</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">symm</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hcop</span> <span class="lean-text">:</span> <span class="lean-text">Nat.Coprime</span> <span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span><span class="lean-text">)</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.coprime_ordCompl</span> <span class="lean-text">hminFac_prime</span> <span class="lean-text">hm_ne_zero</span> <span class="lean-text">|&gt;.</span><span class="lean-text">pow_left</span> <span class="lean-text">e</span>
  <span class="lean-comment">-- m&#x27; <span class="lean-operator">≠</span> <span class="lean-number">1</span> because m is not a prime power</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hm&#x27;_ne_one</span> <span class="lean-text">:</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">≠</span> <span class="lean-text">1</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">hm&#x27;_one</span>
    <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> <span class="lean-text">h_not_pp</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">isPrimePow_nat_iff</span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">⟨</span><span class="lean-text">p</span><span class="lean-text">,</span> <span class="lean-text">e</span><span class="lean-text">,</span> <span class="lean-text">hminFac_prime</span><span class="lean-text">,</span> <span class="lean-text">he_pos</span><span class="lean-text">,</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">hm_eq</span><span class="lean-text">,</span> <span class="lean-text">hm&#x27;_one</span><span class="lean-text">,</span> <span class="lean-text">mul_one</span><span class="lean-text">]</span><span class="lean-text">⟩</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hm&#x27;_gt_one</span> <span class="lean-text">:</span> <span class="lean-text">1</span> <span class="lean-text">&lt;</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hm&#x27;_lt</span> <span class="lean-text">:</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">&lt;</span> <span class="lean-text">m</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hpe_ge2</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">≤</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
      <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
">calc</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span> <span class="lean-text">≥</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">1</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.pow_le_pow_right</span> <span class="lean-text">hminFac_prime.one_lt.le</span> <span class="lean-text">he_pos</span>
        <span class="lean-text">_</span> <span class="lean-text">=</span> <span class="lean-text">p</span> <span class="lean-text">:=</span> <span class="lean-text">pow_one</span> <span class="lean-text">p</span>
        <span class="lean-text">_</span> <span class="lean-text">≥</span> <span class="lean-text">2</span> <span class="lean-text">:=</span> <span class="lean-text">hminFac_prime.two_le</span>
    <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
">calc</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">=</span> <span class="lean-text">1</span> <span class="lean-text">*</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">:=</span> <span class="lean-text">(</span><span class="lean-text">one_mul</span> <span class="lean-text">_</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">symm</span>
      <span class="lean-text">_</span> <span class="lean-text">&lt;</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span> <span class="lean-text">*</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.mul_lt_mul_of_pos_right</span>
          <span class="lean-text">(</span><span class="lean-text">Nat.one_lt_pow</span> <span class="lean-text">he_pos.ne&#x27;</span> <span class="lean-text">hminFac_prime.one_lt</span><span class="lean-text">)</span> <span class="lean-text">hm&#x27;_pos</span>
      <span class="lean-text">_</span> <span class="lean-text">=</span> <span class="lean-text">m</span> <span class="lean-text">:=</span> <span class="lean-text">hm_eq.symm</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hpe_lt</span> <span class="lean-text">:</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span> <span class="lean-text">&lt;</span> <span class="lean-text">m</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
">calc</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span> <span class="lean-text">=</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span> <span class="lean-text">*</span> <span class="lean-text">1</span> <span class="lean-text">:=</span> <span class="lean-text">(</span><span class="lean-text">mul_one</span> <span class="lean-text">_</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">symm</span>
      <span class="lean-text">_</span> <span class="lean-text">&lt;</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span> <span class="lean-text">*</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.mul_lt_mul_of_pos_left</span> <span class="lean-text">hm&#x27;_gt_one</span> <span class="lean-text">(</span><span class="lean-text">Nat.pow_pos</span> <span class="lean-text">hminFac_prime.pos</span><span class="lean-text">)</span>
      <span class="lean-text">_</span> <span class="lean-text">=</span> <span class="lean-text">m</span> <span class="lean-text">:=</span> <span class="lean-text">hm_eq.symm</span>
  <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">⟨</span><span class="lean-text">p</span><span class="lean-text">,</span> <span class="lean-text">e</span><span class="lean-text">,</span> <span class="lean-text">m&#x27;</span><span class="lean-text">,</span> <span class="lean-text">hminFac_prime</span><span class="lean-text">,</span> <span class="lean-text">he_pos</span><span class="lean-text">,</span> <span class="lean-text">hm_eq.symm</span><span class="lean-text">,</span> <span class="lean-text">hcop</span><span class="lean-text">,</span> <span class="lean-text">hm&#x27;_gt_one</span><span class="lean-text">,</span> <span class="lean-text">hm&#x27;_lt</span><span class="lean-text">,</span> <span class="lean-text">hpe_lt</span><span class="lean-text">⟩</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L71-L119" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:factorization-split-lt');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:psi-pos-of-odd">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.7</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:psi-pos-of-odd">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000020"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0002.html#lem:psi-ge-psiPrimePow">Theorem 2.0.4</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psi_pos_of_odd_ge_three" class="lean_decl">Crystallographic.psi_pos_of_odd_ge_three</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        For odd \(m \geq 3\), we have \(\psi (m) {\gt} 0\). </p>
<p>Since \(m \geq 3\) and \(m\) is odd, \(m\) has a prime factor \(q \geq 3\) (specifically, \(q = \mathrm{minFac}(m)\)). The prime power \(q^{\nu _q(m)}\) contributes \(\psi _{\mathrm{pp}}(q, \nu _q(m)) = \varphi (q^{\nu _q(m)}) {\gt} 0\) to \(\psi (m)\), since \((q, \nu _q(m)) \neq (2, 1)\).  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000020">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> The minimal prime factor \(q = \mathrm{minFac}(m)\) satisfies \(q \geq 3\) (since \(2 \nmid m\)). Thus \((q, \nu _q(m))\) is a nontrivial pair, and \(\psi (m) \geq \psi _{\mathrm{pp}}(q, \nu _q(m)) = \varphi (q^{\nu _q(m)}) {\gt} 0\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> <span class="lean-text">psi_pos_of_odd_ge_three</span> <span class="lean-text">{</span><span class="lean-text">m</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">}</span> <span class="lean-text">(</span><span class="lean-text">hm</span> <span class="lean-text">:</span> <span class="lean-text">3</span> <span class="lean-text">≤</span> <span class="lean-text">m</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hm_odd</span> <span class="lean-text">:</span> <span class="lean-text">Odd</span> <span class="lean-text">m</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">psi</span> <span class="lean-text">m</span> <span class="lean-text">:=</span></code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-comment">-- m &gt;= <span class="lean-number">3</span> implies m != <span class="lean-number">1</span>, so minFac<span class="lean-bracket">(</span>m<span class="lean-bracket">)</span> is prime</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hm_ne_one</span> <span class="lean-text">:</span> <span class="lean-text">m</span> <span class="lean-text">≠</span> <span class="lean-text">1</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hm_ne_zero</span> <span class="lean-text">:</span> <span class="lean-text">m</span> <span class="lean-text">≠</span> <span class="lean-text">0</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
  <span class="lean-keyword" data-docs="`set a := t with h` is a variant of `let a := t`. It adds the hypothesis `h : a = t` to
the local context and replaces `t` with `a` everywhere it can.

`set a := t with ← h` will add `h : t = a` instead.

`set! a := t with h` does not do any replacing.

```lean
example (x : Nat) (h : x + x - x = 3) : x + x - x = 3 := by
  set y := x with ← h2
  sorry
/-
x : Nat
y : Nat := x
h : y + y - y = 3
h2 : x = y
⊢ y + y - y = 3
-/
```
">set</span> <span class="lean-text">q</span> <span class="lean-text">:=</span> <span class="lean-text">m.minFac</span> <span class="lean-keyword">with</span> <span class="lean-text">hq_def</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hq_prime</span> <span class="lean-text">:</span> <span class="lean-text">q.Prime</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.minFac_prime</span> <span class="lean-text">hm_ne_one</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hq_dvd</span> <span class="lean-text">:</span> <span class="lean-text">q</span> <span class="lean-text">∣</span> <span class="lean-text">m</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.minFac_dvd</span> <span class="lean-text">m</span>
  <span class="lean-comment">-- m is odd, so minFac<span class="lean-bracket">(</span>m<span class="lean-bracket">)</span> != <span class="lean-number">2</span> <span class="lean-bracket">(</span>otherwise <span class="lean-number">2</span> would divide m<span class="lean-bracket">)</span></span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hq_ne2</span> <span class="lean-text">:</span> <span class="lean-text">q</span> <span class="lean-text">≠</span> <span class="lean-text">2</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">hq2eq</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">hq2eq</span><span class="lean-text">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> <span class="lean-text">hq_dvd</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">hm_odd.not_two_dvd_nat</span> <span class="lean-text">hq_dvd</span>
  <span class="lean-comment">-- Therefore minFac<span class="lean-bracket">(</span>m<span class="lean-bracket">)</span> &gt;= <span class="lean-number">3</span></span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hq_ge3</span> <span class="lean-text">:</span> <span class="lean-text">3</span> <span class="lean-text">≤</span> <span class="lean-text">q</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hq2</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">≤</span> <span class="lean-text">q</span> <span class="lean-text">:=</span> <span class="lean-text">hq_prime.two_le</span>
    <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
  <span class="lean-comment">-- q is in the factorization support</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hq_in_support</span> <span class="lean-text">:</span> <span class="lean-text">q</span> <span class="lean-text">∈</span> <span class="lean-text">m.factorization.support</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">Finsupp.mem_support_iff</span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">(</span><span class="lean-text">Nat.Prime.factorization_pos_of_dvd</span> <span class="lean-text">hq_prime</span> <span class="lean-text">hm_ne_zero</span> <span class="lean-text">hq_dvd</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">ne&#x27;</span>
  <span class="lean-comment">-- psi<span class="lean-bracket">(</span>m<span class="lean-bracket">)</span> &gt;= psiPrimePow<span class="lean-bracket">(</span>q, ord_q<span class="lean-bracket">(</span>m<span class="lean-bracket">)</span><span class="lean-bracket">)</span></span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hcontrib</span> <span class="lean-text">:</span> <span class="lean-text">psiPrimePow</span> <span class="lean-text">q</span> <span class="lean-text">(</span><span class="lean-text">m.factorization</span> <span class="lean-text">q</span><span class="lean-text">)</span> <span class="lean-text">≤</span> <span class="lean-text">psi</span> <span class="lean-text">m</span> <span class="lean-text">:=</span>
    <span class="lean-text">psi_ge_psiPrimePow_of_mem_support</span> <span class="lean-text">hq_in_support</span>
  <span class="lean-comment">-- psiPrimePow<span class="lean-bracket">(</span>q, k<span class="lean-bracket">)</span> = totient<span class="lean-bracket">(</span>q^k<span class="lean-bracket">)</span> &gt; <span class="lean-number">0</span> for q &gt;= <span class="lean-number">3</span> <span class="lean-bracket">(</span>since q != <span class="lean-number">2</span> means <span class="lean-bracket">(</span>q, k<span class="lean-bracket">)</span> != <span class="lean-bracket">(</span><span class="lean-number">2</span>, <span class="lean-number">1</span><span class="lean-bracket">)</span><span class="lean-bracket">)</span></span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hcontrib_pos</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">psiPrimePow</span> <span class="lean-text">q</span> <span class="lean-text">(</span><span class="lean-text">m.factorization</span> <span class="lean-text">q</span><span class="lean-text">)</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">psiPrimePow</span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hk_pos</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">m.factorization</span> <span class="lean-text">q</span> <span class="lean-text">:=</span>
      <span class="lean-text">Nat.Prime.factorization_pos_of_dvd</span> <span class="lean-text">hq_prime</span> <span class="lean-text">hm_ne_zero</span> <span class="lean-text">hq_dvd</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">hk_pos.ne&#x27;</span><span class="lean-text">,</span> <span class="lean-text">ite_false</span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">hq_ne2</span><span class="lean-text">,</span> <span class="lean-text">false_and</span><span class="lean-text">,</span> <span class="lean-text">ite_false</span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">Nat.totient_pos.mpr</span> <span class="lean-text">(</span><span class="lean-text">Nat.pow_pos</span> <span class="lean-text">hq_prime.pos</span><span class="lean-text">)</span>
  <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L121-L164" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:psi-pos-of-odd');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:psi-le-totient">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.8</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:psi-le-totient">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000021"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0006.html#lem:totient-ge-two">Theorem A.0.4</a></li>
          
          <li><a href="sect0002.html#lem:two-le-totient-prime-pow">Theorem 2.0.5</a></li>
          
          <li><a href="sect0002.html#lem:psi-prime-pow">Theorem 2.0.1</a></li>
          
          <li><a href="sect0002.html#lem:factorization-split-lt">Theorem 2.0.6</a></li>
          
          <li><a href="sect0002.html#lem:psi-coprime-add">Theorem 2.0.3</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psi_le_totient" class="lean_decl">Crystallographic.psi_le_totient</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        For all \(m \geq 1\), we have \(\psi (m) \leq \varphi (m)\). </p>
<p>We prove \(\psi (m) \leq \varphi (m)\) by strong induction on \(m\). The key observation is that \(\psi \) excludes the contribution from \((2, 1)\), while \(\varphi \) includes \(\varphi (2) = 1\), so \(\psi \leq \varphi \) with equality when \(2 \nmid m\) or \(4 \mid m\). </p>
<p>The proof proceeds by strong induction on \(m\): </p>
<ul class="itemize">
  <li><p>For \(m = 1\): \(\psi (1) = 0 \leq 1 = \varphi (1)\) </p>
</li>
  <li><p>For prime powers \(p^k\): \(\psi (p^k) = \varphi (p^k)\) (with the exception \(\psi (2) = 0\)) </p>
</li>
  <li><p>For composite \(m = 2 \cdot \text{odd}\): \(\psi (m) = \psi (\text{odd}) \leq \varphi (\text{odd}) = \varphi (m)\) </p>
</li>
  <li><p>For general composite without \(2^1\) factor: each \(\varphi (p^k) \geq 2\), so sum \(\leq \) product </p>
</li>
</ul>
<p>  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000021">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> By strong induction on \(m\). For \(m = 1\): both sides are \(0\). For \(m {\gt} 1\): use coprime factorization \(m = a \cdot b\) with \(1 {\lt} a, b {\lt} m\). Then \(\psi (m) = \psi (a) + \psi (b) \leq \varphi (a) + \varphi (b) \leq \varphi (m)\) by the inductive hypothesis and multiplicativity of \(\varphi \). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> <span class="lean-text">psi_le_totient</span> <span class="lean-text">(</span><span class="lean-text">m</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hm</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">m</span><span class="lean-text">)</span> <span class="lean-text">:</span> <span class="lean-text">psi</span> <span class="lean-text">m</span> <span class="lean-text">≤</span> <span class="lean-text">Nat.totient</span> <span class="lean-text">m</span> <span class="lean-text">:=</span></code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-comment">-- Strong induction on m</span>
  <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
">induction</span> <span class="lean-text">m</span> <span class="lean-keyword">using</span> <span class="lean-text">Nat.strong_induction_on</span> <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
">with</span>
  <span class="lean-text">|</span> <span class="lean-text">_</span> <span class="lean-text">m</span> <span class="lean-text">IH</span> <span class="lean-text">=&gt;</span>
  <span class="lean-comment">-- Handle small cases separately</span>
  <span class="lean-keyword" data-docs="`rcases` is a tactic that will perform `cases` recursively, according to a pattern. It is used to
destructure hypotheses or expressions composed of inductive types like `h1 : a ∧ b ∧ c ∨ d` or
`h2 : ∃ x y, trans_rel R x y`. Usual usage might be `rcases h1 with ⟨ha, hb, hc⟩ | hd` or
`rcases h2 with ⟨x, y, _ | ⟨z, hxz, hzy⟩⟩` for these examples.

Each element of an `rcases` pattern is matched against a particular local hypothesis (most of which
are generated during the execution of `rcases` and represent individual elements destructured from
the input expression). An `rcases` pattern has the following grammar:

* A name like `x`, which names the active hypothesis as `x`.
* A blank `_`, which does nothing (letting the automatic naming system used by `cases` name the
  hypothesis).
* A hyphen `-`, which clears the active hypothesis and any dependents.
* The keyword `rfl`, which expects the hypothesis to be `h : a = b`, and calls `subst` on the
  hypothesis (which has the effect of replacing `b` with `a` everywhere or vice versa).
* A type ascription `p : ty`, which sets the type of the hypothesis to `ty` and then matches it
  against `p`. (Of course, `ty` must unify with the actual type of `h` for this to work.)
* A tuple pattern `⟨p1, p2, p3⟩`, which matches a constructor with many arguments, or a series
  of nested conjunctions or existentials. For example if the active hypothesis is `a ∧ b ∧ c`,
  then the conjunction will be destructured, and `p1` will be matched against `a`, `p2` against `b`
  and so on.
* A `@` before a tuple pattern as in `@⟨p1, p2, p3⟩` will bind all arguments in the constructor,
  while leaving the `@` off will only use the patterns on the explicit arguments.
* An alternation pattern `p1 | p2 | p3`, which matches an inductive type with multiple constructors,
  or a nested disjunction like `a ∨ b ∨ c`.

A pattern like `⟨a, b, c⟩ | ⟨d, e⟩` will do a split over the inductive datatype,
naming the first three parameters of the first constructor as `a,b,c` and the
first two of the second constructor `d,e`. If the list is not as long as the
number of arguments to the constructor or the number of constructors, the
remaining variables will be automatically named. If there are nested brackets
such as `⟨⟨a⟩, b | c⟩ | d` then these will cause more case splits as necessary.
If there are too many arguments, such as `⟨a, b, c⟩` for splitting on
`∃ x, ∃ y, p x`, then it will be treated as `⟨a, ⟨b, c⟩⟩`, splitting the last
parameter as necessary.

`rcases` also has special support for quotient types: quotient induction into Prop works like
matching on the constructor `quot.mk`.

`rcases h : e with PAT` will do the same as `rcases e with PAT` with the exception that an
assumption `h : e = PAT` will be added to the context.
">rcases</span> <span class="lean-text">Nat.lt_trichotomy</span> <span class="lean-text">m</span> <span class="lean-text">1</span> <span class="lean-keyword">with</span> <span class="lean-text">hm0</span> <span class="lean-text">|</span> <span class="lean-text">rfl</span> <span class="lean-text">|</span> <span class="lean-text">hm_gt1</span>
  <span class="lean-text">·</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span> <span class="lean-comment">-- m &lt; <span class="lean-number">1</span> contradicts hm</span>
  <span class="lean-text">·</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-text">[</span><span class="lean-text">psi_one</span><span class="lean-text">]</span> <span class="lean-comment">-- m = <span class="lean-number">1</span></span>
  <span class="lean-text">·</span> <span class="lean-keyword" data-docs="`rcases` is a tactic that will perform `cases` recursively, according to a pattern. It is used to
destructure hypotheses or expressions composed of inductive types like `h1 : a ∧ b ∧ c ∨ d` or
`h2 : ∃ x y, trans_rel R x y`. Usual usage might be `rcases h1 with ⟨ha, hb, hc⟩ | hd` or
`rcases h2 with ⟨x, y, _ | ⟨z, hxz, hzy⟩⟩` for these examples.

Each element of an `rcases` pattern is matched against a particular local hypothesis (most of which
are generated during the execution of `rcases` and represent individual elements destructured from
the input expression). An `rcases` pattern has the following grammar:

* A name like `x`, which names the active hypothesis as `x`.
* A blank `_`, which does nothing (letting the automatic naming system used by `cases` name the
  hypothesis).
* A hyphen `-`, which clears the active hypothesis and any dependents.
* The keyword `rfl`, which expects the hypothesis to be `h : a = b`, and calls `subst` on the
  hypothesis (which has the effect of replacing `b` with `a` everywhere or vice versa).
* A type ascription `p : ty`, which sets the type of the hypothesis to `ty` and then matches it
  against `p`. (Of course, `ty` must unify with the actual type of `h` for this to work.)
* A tuple pattern `⟨p1, p2, p3⟩`, which matches a constructor with many arguments, or a series
  of nested conjunctions or existentials. For example if the active hypothesis is `a ∧ b ∧ c`,
  then the conjunction will be destructured, and `p1` will be matched against `a`, `p2` against `b`
  and so on.
* A `@` before a tuple pattern as in `@⟨p1, p2, p3⟩` will bind all arguments in the constructor,
  while leaving the `@` off will only use the patterns on the explicit arguments.
* An alternation pattern `p1 | p2 | p3`, which matches an inductive type with multiple constructors,
  or a nested disjunction like `a ∨ b ∨ c`.

A pattern like `⟨a, b, c⟩ | ⟨d, e⟩` will do a split over the inductive datatype,
naming the first three parameters of the first constructor as `a,b,c` and the
first two of the second constructor `d,e`. If the list is not as long as the
number of arguments to the constructor or the number of constructors, the
remaining variables will be automatically named. If there are nested brackets
such as `⟨⟨a⟩, b | c⟩ | d` then these will cause more case splits as necessary.
If there are too many arguments, such as `⟨a, b, c⟩` for splitting on
`∃ x, ∃ y, p x`, then it will be treated as `⟨a, ⟨b, c⟩⟩`, splitting the last
parameter as necessary.

`rcases` also has special support for quotient types: quotient induction into Prop works like
matching on the constructor `quot.mk`.

`rcases h : e with PAT` will do the same as `rcases e with PAT` with the exception that an
assumption `h : e = PAT` will be added to the context.
">rcases</span> <span class="lean-text">Nat.lt_trichotomy</span> <span class="lean-text">m</span> <span class="lean-text">2</span> <span class="lean-keyword">with</span> <span class="lean-text">hm_lt2</span> <span class="lean-text">|</span> <span class="lean-text">rfl</span> <span class="lean-text">|</span> <span class="lean-text">hm_ge3</span>
    <span class="lean-text">·</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span> <span class="lean-comment">-- m &lt; <span class="lean-number">2</span> but m &gt; <span class="lean-number">1</span>, contradiction</span>
    <span class="lean-text">·</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-text">[</span><span class="lean-text">psi_two</span><span class="lean-text">]</span> <span class="lean-comment">-- m = <span class="lean-number">2</span></span>
    <span class="lean-text">·</span> <span class="lean-comment">-- m <span class="lean-operator">≥</span> <span class="lean-number">3</span></span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hm_gt1</span> <span class="lean-text">:</span> <span class="lean-text">1</span> <span class="lean-text">&lt;</span> <span class="lean-text">m</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
      <span class="lean-comment">-- Check if m is a prime power</span>
      <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> <span class="lean-text">hpow</span> <span class="lean-text">:</span> <span class="lean-text">IsPrimePow</span> <span class="lean-text">m</span>
      <span class="lean-text">·</span> <span class="lean-comment">-- m is a prime power p^k</span>
        <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">isPrimePow_nat_iff</span><span class="lean-text">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> <span class="lean-text">hpow</span>
        <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-text">⟨</span><span class="lean-text">p</span><span class="lean-text">,</span> <span class="lean-text">k</span><span class="lean-text">,</span> <span class="lean-text">hp</span><span class="lean-text">,</span> <span class="lean-text">hk</span><span class="lean-text">,</span> <span class="lean-text">rfl</span><span class="lean-text">⟩</span> <span class="lean-text">:=</span> <span class="lean-text">hpow</span>
        <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">psi_prime_pow</span> <span class="lean-text">p</span> <span class="lean-text">k</span> <span class="lean-text">hp</span> <span class="lean-text">hk</span><span class="lean-text">]</span>
        <span class="lean-keyword" data-docs="Splits all if-then-else-expressions into multiple goals.
Given a goal of the form `g (if p then x else y)`, `split_ifs` will produce
two goals: `p ⊢ g x` and `¬p ⊢ g y`.
If there are multiple ite-expressions, then `split_ifs` will split them all,
starting with a top-most one whose condition does not contain another
ite-expression.
`split_ifs at *` splits all ite-expressions in all hypotheses as well as the goal.
`split_ifs with h₁ h₂ h₃` overrides the default names for the hypotheses.
">split_ifs</span> <span class="lean-keyword">with</span> <span class="lean-text">h21</span>
        <span class="lean-text">·</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-comment">-- psi<span class="lean-bracket">(</span><span class="lean-number">2</span><span class="lean-bracket">)</span> = <span class="lean-number">0</span> <span class="lean-operator">≤</span> totient<span class="lean-bracket">(</span><span class="lean-number">2</span><span class="lean-bracket">)</span></span>
        <span class="lean-text">·</span> <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">le_refl</span> <span class="lean-text">_</span> <span class="lean-comment">-- psi<span class="lean-bracket">(</span>p^k<span class="lean-bracket">)</span> = totient<span class="lean-bracket">(</span>p^k<span class="lean-bracket">)</span> for other prime powers</span>
      <span class="lean-text">·</span> <span class="lean-comment">-- m is not a prime power, so it has multiple distinct prime factors</span>
        <span class="lean-comment">-- Factor m = p^e * m&#x27; using factorization_split_lt</span>
        <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-text">⟨</span><span class="lean-text">p</span><span class="lean-text">,</span> <span class="lean-text">e</span><span class="lean-text">,</span> <span class="lean-text">m&#x27;</span><span class="lean-text">,</span> <span class="lean-text">hp</span><span class="lean-text">,</span> <span class="lean-text">he_pos</span><span class="lean-text">,</span> <span class="lean-text">hm_eq</span><span class="lean-text">,</span> <span class="lean-text">hcop</span><span class="lean-text">,</span> <span class="lean-text">hm&#x27;_gt_one</span><span class="lean-text">,</span> <span class="lean-text">hm&#x27;_lt</span><span class="lean-text">,</span> <span class="lean-text">_</span><span class="lean-text">⟩</span> <span class="lean-text">:=</span>
          <span class="lean-text">factorization_split_lt</span> <span class="lean-text">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">&lt;</span> <span class="lean-text">m</span><span class="lean-text">)</span> <span class="lean-text">hpow</span>
        <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hm&#x27;_pos</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
        <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hm&#x27;_ne_one</span> <span class="lean-text">:</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">≠</span> <span class="lean-text">1</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
        <span class="lean-comment">-- psi and totient are additive/multiplicative on coprime factors</span>
        <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">←</span> <span class="lean-text">hm_eq</span><span class="lean-text">,</span> <span class="lean-text">psi_coprime_add</span> <span class="lean-text">_</span> <span class="lean-text">_</span> <span class="lean-text">(</span><span class="lean-text">Nat.pow_pos</span> <span class="lean-text">hp.pos</span><span class="lean-text">)</span> <span class="lean-text">hm&#x27;_pos</span> <span class="lean-text">hcop</span><span class="lean-text">,</span>
            <span class="lean-text">Nat.totient_mul</span> <span class="lean-text">hcop</span><span class="lean-text">]</span>
        <span class="lean-comment">-- By IH: psi<span class="lean-bracket">(</span>m&#x27;<span class="lean-bracket">)</span> <span class="lean-operator">≤</span> totient<span class="lean-bracket">(</span>m&#x27;<span class="lean-bracket">)</span></span>
        <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">IH_m&#x27;</span> <span class="lean-text">:</span> <span class="lean-text">psi</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">≤</span> <span class="lean-text">Nat.totient</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">:=</span> <span class="lean-text">IH</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">hm&#x27;_lt</span> <span class="lean-text">hm&#x27;_pos</span>
        <span class="lean-comment">-- For the prime power part: psi<span class="lean-bracket">(</span>p^e<span class="lean-bracket">)</span> <span class="lean-operator">≤</span> totient<span class="lean-bracket">(</span>p^e<span class="lean-bracket">)</span></span>
        <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hpsi_pe</span> <span class="lean-text">:</span> <span class="lean-text">psi</span> <span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span><span class="lean-text">)</span> <span class="lean-text">≤</span> <span class="lean-text">Nat.totient</span> <span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span><span class="lean-text">)</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
          <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">psi_prime_pow</span> <span class="lean-text">p</span> <span class="lean-text">e</span> <span class="lean-text">hp</span> <span class="lean-text">he_pos</span><span class="lean-text">]</span>
          <span class="lean-keyword" data-docs="Splits all if-then-else-expressions into multiple goals.
Given a goal of the form `g (if p then x else y)`, `split_ifs` will produce
two goals: `p ⊢ g x` and `¬p ⊢ g y`.
If there are multiple ite-expressions, then `split_ifs` will split them all,
starting with a top-most one whose condition does not contain another
ite-expression.
`split_ifs at *` splits all ite-expressions in all hypotheses as well as the goal.
`split_ifs with h₁ h₂ h₃` overrides the default names for the hypotheses.
">split_ifs</span> <span class="lean-text">&lt;;&gt;</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span>
        <span class="lean-comment">-- Three cases based on whether p^e or m&#x27; equals <span class="lean-number">2</span></span>
        <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> <span class="lean-text">h21</span> <span class="lean-text">:</span> <span class="lean-text">p</span> <span class="lean-text">=</span> <span class="lean-text">2</span> <span class="lean-text">∧</span> <span class="lean-text">e</span> <span class="lean-text">=</span> <span class="lean-text">1</span>
        <span class="lean-text">·</span> <span class="lean-comment">-- Case <span class="lean-number">1</span>: p^e = <span class="lean-number">2</span>, so psi<span class="lean-bracket">(</span><span class="lean-number">2</span><span class="lean-bracket">)</span> = <span class="lean-number">0</span> and totient<span class="lean-bracket">(</span><span class="lean-number">2</span><span class="lean-bracket">)</span> = <span class="lean-number">1</span></span>
          <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-text">⟨</span><span class="lean-text">hp2</span><span class="lean-text">,</span> <span class="lean-text">he1</span><span class="lean-text">⟩</span> <span class="lean-text">:=</span> <span class="lean-text">h21</span>
          <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">hp2</span><span class="lean-text">,</span> <span class="lean-text">he1</span><span class="lean-text">,</span> <span class="lean-text">pow_one</span><span class="lean-text">,</span> <span class="lean-text">psi_two</span><span class="lean-text">,</span> <span class="lean-text">Nat.totient_two</span><span class="lean-text">,</span> <span class="lean-text">zero_add</span><span class="lean-text">,</span>
            <span class="lean-text">one_mul</span><span class="lean-text">]</span>
          <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">IH_m&#x27;</span>
        <span class="lean-text">·</span> <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> <span class="lean-text">hm&#x27;2</span> <span class="lean-text">:</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">=</span> <span class="lean-text">2</span>
          <span class="lean-text">·</span> <span class="lean-comment">-- Case <span class="lean-number">2</span>: m&#x27; = <span class="lean-number">2</span>, so psi<span class="lean-bracket">(</span><span class="lean-number">2</span><span class="lean-bracket">)</span> = <span class="lean-number">0</span> and totient<span class="lean-bracket">(</span><span class="lean-number">2</span><span class="lean-bracket">)</span> = <span class="lean-number">1</span></span>
            <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">hm&#x27;2</span><span class="lean-text">,</span> <span class="lean-text">psi_two</span><span class="lean-text">,</span> <span class="lean-text">Nat.totient_two</span><span class="lean-text">,</span> <span class="lean-text">add_zero</span><span class="lean-text">,</span> <span class="lean-text">mul_one</span><span class="lean-text">]</span>
            <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">hpsi_pe</span>
          <span class="lean-text">·</span> <span class="lean-comment">-- Case <span class="lean-number">3</span>: Neither is <span class="lean-number">2</span>^<span class="lean-number">1</span>, so both totients &gt;= <span class="lean-number">2</span></span>
            <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">htot_m&#x27;_ge2</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">≤</span> <span class="lean-text">Nat.totient</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">:=</span>
              <span class="lean-text">two_le_totient_of_two_lt</span> <span class="lean-text">m&#x27;</span> <span class="lean-text">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">&lt;</span> <span class="lean-text">m&#x27;</span><span class="lean-text">)</span>
            <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">htot_pe_ge2</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">≤</span> <span class="lean-text">Nat.totient</span> <span class="lean-text">(</span><span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">e</span><span class="lean-text">)</span> <span class="lean-text">:=</span> <span class="lean-text">two_le_totient_primePow</span> <span class="lean-text">hp</span> <span class="lean-text">he_pos</span> <span class="lean-text">h21</span>
            <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">psi_sum_le_totient_prod_of_ge_two</span> <span class="lean-text">hpsi_pe</span> <span class="lean-text">IH_m&#x27;</span> <span class="lean-text">htot_pe_ge2</span> <span class="lean-text">htot_m&#x27;_ge2</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L168-L251" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:psi-le-totient');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:prime-pow-achieved-of-lcm-eq">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.9</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:prime-pow-achieved-of-lcm-eq">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000022"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0006.html#lem:lcm-factorization-le-sup">Theorem A.0.2</a></li>
          
          <li><a href="sect0006.html#lem:lcm-factorization-le-sup">Theorem A.0.2</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.primePow_achieved_of_lcm_eq" class="lean_decl">Crystallographic.primePow_achieved_of_lcm_eq</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(S\) is a finite set of divisors of \(m\) with \(\mathrm{lcm}(S) = m\), then for each prime \(q\) dividing \(m\), some element \(d \in S\) is divisible by \(q^{\nu _q(m)}\). </p>
<p>In other words, the full \(q\)-power component of \(m\) must be "achieved" by some element of \(S\). This is the key combinatorial fact ensuring that \(\psi (m) \leq \sum _{d \in S} \varphi (d)\).  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000022">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> By contradiction: if all \(d \in S\) have \(\nu _q(d) {\lt} \nu _q(m)\), then \(\nu _q(\mathrm{lcm}(S)) = \sup _{d \in S} \nu _q(d) {\lt} \nu _q(m)\), contradicting \(\mathrm{lcm}(S) = m\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> <span class="lean-text">primePow_achieved_of_lcm_eq</span> <span class="lean-text">{</span><span class="lean-text">m</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">}</span> <span class="lean-text">(</span><span class="lean-text">hm</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">m</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">S</span> <span class="lean-text">:</span> <span class="lean-text">Finset</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span>
    <span class="lean-text">(</span><span class="lean-text">hS_sub</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">d</span> <span class="lean-text">∣</span> <span class="lean-text">m</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hS_lcm</span> <span class="lean-text">:</span> <span class="lean-text">S.lcm</span> <span class="lean-text">id</span> <span class="lean-text">=</span> <span class="lean-text">m</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">∀</span> <span class="lean-text">q</span> <span class="lean-text">∈</span> <span class="lean-text">m.factorization.support</span><span class="lean-text">,</span> <span class="lean-text">∃</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">q</span> <span class="lean-text">^</span> <span class="lean-text">m.factorization</span> <span class="lean-text">q</span> <span class="lean-text">∣</span> <span class="lean-text">d</span> <span class="lean-text">:=</span></code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">q</span> <span class="lean-text">hq</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hq_prime</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.prime_of_mem_primeFactors</span> <span class="lean-text">(</span><span class="lean-text">Nat.support_factorization</span> <span class="lean-text">m</span> <span class="lean-text">▸</span> <span class="lean-text">hq</span><span class="lean-text">)</span>
  <span class="lean-keyword" data-docs="`by_contra h` proves `⊢ p` by contradiction,
introducing a hypothesis `h : ¬p` and proving `False`.
* If `p` is a negation `¬q`, `h : q` will be introduced instead of `¬¬q`.
* If `p` is decidable, it uses `Decidable.byContradiction` instead of `Classical.byContradiction`.
* If `h` is omitted, the introduced variable will be called `this`.
">by_contra</span> <span class="lean-text">hall</span>
  <span class="lean-keyword" data-docs="Push negations into the conclusion or a hypothesis.
For instance, a hypothesis `h : ¬ ∀ x, ∃ y, x ≤ y` will be transformed by `push_neg at h` into
`h : ∃ x, ∀ y, y &lt; x`. Binder names are preserved.

`push_neg` is a special case of the more general `push` tactic, namely `push Not`.
The `push` tactic can be extended using the `@[push]` attribute. `push` has special-casing
built in for `push Not`, so that it can preserve binder names, and so that `¬ (p ∧ q)` can be
transformed to either `p → ¬ q` (default) or `¬ p ∨ ¬ q` (`push_neg +distrib`).

Tactics that introduce a negation usually have a version that automatically calls `push_neg` on
that negation. These include `by_cases!`, `contrapose!` and `by_contra!`.

Another example: given a hypothesis
```lean
h : ¬ ∀ ε &gt; 0, ∃ δ &gt; 0, ∀ x, |x - x₀| ≤ δ → |f x - y₀| ≤ ε
```
writing `push_neg at h` will turn `h` into
```lean
h : ∃ ε &gt; 0, ∀ δ &gt; 0, ∃ x, |x - x₀| ≤ δ ∧ ε &lt; |f x - y₀|
```
Note that binder names are preserved by this tactic, contrary to what would happen with `simp`
using the relevant lemmas. One can use this tactic at the goal using `push_neg`,
at every hypothesis and the goal using `push_neg at *` or at selected hypotheses and the goal
using say `push_neg at h h&#x27; ⊢`, as usual.
">push_neg</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> <span class="lean-text">hall</span>
  <span class="lean-comment">-- All d <span class="lean-operator">∈</span> S have q^<span class="lean-bracket">{</span>ord_q<span class="lean-bracket">(</span>m<span class="lean-bracket">)</span><span class="lean-bracket">}</span> not dividing d</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hall&#x27;</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">d.factorization</span> <span class="lean-text">q</span> <span class="lean-text">&lt;</span> <span class="lean-text">m.factorization</span> <span class="lean-text">q</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">d</span> <span class="lean-text">hd</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hndvd</span> <span class="lean-text">:=</span> <span class="lean-text">hall</span> <span class="lean-text">d</span> <span class="lean-text">hd</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hdvd</span> <span class="lean-text">:</span> <span class="lean-text">d</span> <span class="lean-text">∣</span> <span class="lean-text">m</span> <span class="lean-text">:=</span> <span class="lean-text">hS_sub</span> <span class="lean-text">d</span> <span class="lean-text">hd</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hd_pos</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">d</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.pos_of_dvd_of_pos</span> <span class="lean-text">hdvd</span> <span class="lean-text">hm</span>
    <span class="lean-keyword" data-docs="`by_contra h` proves `⊢ p` by contradiction,
introducing a hypothesis `h : ¬p` and proving `False`.
* If `p` is a negation `¬q`, `h : q` will be introduced instead of `¬¬q`.
* If `p` is decidable, it uses `Decidable.byContradiction` instead of `Classical.byContradiction`.
* If `h` is omitted, the introduced variable will be called `this`.
">by_contra</span> <span class="lean-text">hge</span>
    <span class="lean-keyword" data-docs="Push negations into the conclusion or a hypothesis.
For instance, a hypothesis `h : ¬ ∀ x, ∃ y, x ≤ y` will be transformed by `push_neg at h` into
`h : ∃ x, ∀ y, y &lt; x`. Binder names are preserved.

`push_neg` is a special case of the more general `push` tactic, namely `push Not`.
The `push` tactic can be extended using the `@[push]` attribute. `push` has special-casing
built in for `push Not`, so that it can preserve binder names, and so that `¬ (p ∧ q)` can be
transformed to either `p → ¬ q` (default) or `¬ p ∨ ¬ q` (`push_neg +distrib`).

Tactics that introduce a negation usually have a version that automatically calls `push_neg` on
that negation. These include `by_cases!`, `contrapose!` and `by_contra!`.

Another example: given a hypothesis
```lean
h : ¬ ∀ ε &gt; 0, ∃ δ &gt; 0, ∀ x, |x - x₀| ≤ δ → |f x - y₀| ≤ ε
```
writing `push_neg at h` will turn `h` into
```lean
h : ∃ ε &gt; 0, ∀ δ &gt; 0, ∃ x, |x - x₀| ≤ δ ∧ ε &lt; |f x - y₀|
```
Note that binder names are preserved by this tactic, contrary to what would happen with `simp`
using the relevant lemmas. One can use this tactic at the goal using `push_neg`,
at every hypothesis and the goal using `push_neg at *` or at selected hypotheses and the goal
using say `push_neg at h h&#x27; ⊢`, as usual.
">push_neg</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> <span class="lean-text">hge</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">:=</span> <span class="lean-text">(</span><span class="lean-text">hq_prime.pow_dvd_iff_le_factorization</span> <span class="lean-text">hd_pos.ne&#x27;</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">mpr</span> <span class="lean-text">hge</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">hndvd</span> <span class="lean-text">this</span>
  <span class="lean-comment">-- lcm<span class="lean-bracket">(</span>S<span class="lean-bracket">)</span>.factorization q = sup of d.factorization q, which is &lt; m.factorization q</span>
  <span class="lean-comment">-- This contradicts hS_lcm since lcm<span class="lean-bracket">(</span>S<span class="lean-bracket">)</span> = m requires matching factorizations.</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hne_zero</span> <span class="lean-text">:</span> <span class="lean-text">S.lcm</span> <span class="lean-text">id</span> <span class="lean-text">≠</span> <span class="lean-text">0</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">hS_lcm</span><span class="lean-text">]</span><span class="lean-text">;</span> <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">hm.ne&#x27;</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hk_pos</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">m.factorization</span> <span class="lean-text">q</span> <span class="lean-text">:=</span> <span class="lean-text">Finsupp.mem_support_iff.mp</span> <span class="lean-text">hq</span> <span class="lean-text">|&gt;</span> <span class="lean-text">Nat.pos_of_ne_zero</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hfact_q</span> <span class="lean-text">:</span> <span class="lean-text">(</span><span class="lean-text">S.lcm</span> <span class="lean-text">id</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">factorization</span> <span class="lean-text">q</span> <span class="lean-text">&lt;</span> <span class="lean-text">m.factorization</span> <span class="lean-text">q</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-comment">-- Show: <span class="lean-bracket">(</span>S.lcm id<span class="lean-bracket">)</span>.factorization q <span class="lean-operator">≤</span> S.sup <span class="lean-bracket">(</span>d.factorization q<span class="lean-bracket">)</span> &lt; m.factorization q</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hsup_lt</span> <span class="lean-text">:</span> <span class="lean-text">S.sup</span> <span class="lean-text">(</span><span class="lean-keyword">fun</span> <span class="lean-text">d</span> <span class="lean-text">=&gt;</span> <span class="lean-text">d.factorization</span> <span class="lean-text">q</span><span class="lean-text">)</span> <span class="lean-text">&lt;</span> <span class="lean-text">m.factorization</span> <span class="lean-text">q</span> <span class="lean-text">:=</span>
      <span class="lean-text">Finset.sup_lt_iff</span> <span class="lean-text">hk_pos</span> <span class="lean-text">|&gt;.</span><span class="lean-text">mpr</span> <span class="lean-text">(</span><span class="lean-keyword">fun</span> <span class="lean-text">d</span> <span class="lean-text">hd</span> <span class="lean-text">=&gt;</span> <span class="lean-text">hall&#x27;</span> <span class="lean-text">d</span> <span class="lean-text">hd</span><span class="lean-text">)</span>
    <span class="lean-comment">-- Use extracted lemma for lcm factorization bound</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hS_ne_zero</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">d</span> <span class="lean-text">≠</span> <span class="lean-text">0</span> <span class="lean-text">:=</span> <span class="lean-keyword">fun</span> <span class="lean-text">d</span> <span class="lean-text">hd</span> <span class="lean-text">=&gt;</span>
      <span class="lean-text">(</span><span class="lean-text">Nat.pos_of_dvd_of_pos</span> <span class="lean-text">(</span><span class="lean-text">hS_sub</span> <span class="lean-text">d</span> <span class="lean-text">hd</span><span class="lean-text">)</span> <span class="lean-text">hm</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">ne&#x27;</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">lt_of_le_of_lt</span> <span class="lean-text">(</span><span class="lean-text">Finset.lcm_factorization_le_sup</span> <span class="lean-text">S</span> <span class="lean-text">id</span> <span class="lean-text">q</span> <span class="lean-text">hS_ne_zero</span><span class="lean-text">)</span> <span class="lean-text">hsup_lt</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">hS_lcm</span><span class="lean-text">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> <span class="lean-text">hfact_q</span>
  <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L253-L293" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:prime-pow-achieved-of-lcm-eq');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:finset-nonempty-of-two-le-lcm">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.10</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:finset-nonempty-of-two-le-lcm">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000023"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.Finset.nonempty_of_two_le_lcm" class="lean_decl">Crystallographic.Finset.nonempty_of_two_le_lcm</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(\mathrm{lcm}(S) \geq 2\) for a finite set \(S\) of natural numbers, then \(S\) is nonempty. </p>
<p>This follows immediately from the fact that \(\mathrm{lcm}(\emptyset ) = 1\) by convention.  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000023">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>By contradiction: if \(S = \emptyset \), then \(\mathrm{lcm}(S) = 1 {\lt} 2\), contradicting the hypothesis. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> <span class="lean-text">Finset.nonempty_of_two_le_lcm</span> <span class="lean-text">{</span><span class="lean-text">S</span> <span class="lean-text">:</span> <span class="lean-text">Finset</span> <span class="lean-text">ℕ</span><span class="lean-text">}</span> <span class="lean-text">(</span><span class="lean-text">hS_lcm_ge2</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">≤</span> <span class="lean-text">S.lcm</span> <span class="lean-text">id</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">S.Nonempty</span> <span class="lean-text">:=</span></code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="`by_contra h` proves `⊢ p` by contradiction,
introducing a hypothesis `h : ¬p` and proving `False`.
* If `p` is a negation `¬q`, `h : q` will be introduced instead of `¬¬q`.
* If `p` is decidable, it uses `Decidable.byContradiction` instead of `Classical.byContradiction`.
* If `h` is omitted, the introduced variable will be called `this`.
">by_contra</span> <span class="lean-text">h</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">Finset.not_nonempty_iff_eq_empty</span><span class="lean-text">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> <span class="lean-text">h</span>
  <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">h</span><span class="lean-text">,</span> <span class="lean-text">Finset.lcm_empty</span><span class="lean-text">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> <span class="lean-text">hS_lcm_ge2</span>
  <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L418-L431" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:finset-nonempty-of-two-le-lcm');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:finset-exists-one-lt-of-two-le-lcm">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.11</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:finset-exists-one-lt-of-two-le-lcm">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000024"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#lem:finset-nonempty-of-two-le-lcm">Theorem 2.0.10</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.Finset.exists_one_lt_of_two_le_lcm" class="lean_decl">Crystallographic.Finset.exists_one_lt_of_two_le_lcm</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(S\) is a finite set of positive integers with \(\mathrm{lcm}(S) \geq 2\), then some element \(d \in S\) satisfies \(d {\gt} 1\). </p>
<p>This is because \(\mathrm{lcm}\) of a set where all elements equal \(1\) would be \(1\).  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000024">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>By contradiction: if all \(d \in S\) satisfy \(d \leq 1\), then since all \(d {\gt} 0\) we have \(d = 1\) for all \(d \in S\). Thus \(\mathrm{lcm}(S) = 1 {\lt} 2\), a contradiction. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> <span class="lean-text">Finset.exists_one_lt_of_two_le_lcm</span> <span class="lean-text">{</span><span class="lean-text">S</span> <span class="lean-text">:</span> <span class="lean-text">Finset</span> <span class="lean-text">ℕ</span><span class="lean-text">}</span> <span class="lean-text">(</span><span class="lean-text">hS_pos</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">d</span><span class="lean-text">)</span>
    <span class="lean-text">(</span><span class="lean-text">hS_lcm_ge2</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">≤</span> <span class="lean-text">S.lcm</span> <span class="lean-text">id</span><span class="lean-text">)</span> <span class="lean-text">:</span> <span class="lean-text">∃</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">1</span> <span class="lean-text">&lt;</span> <span class="lean-text">d</span> <span class="lean-text">:=</span></code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="`by_contra h` proves `⊢ p` by contradiction,
introducing a hypothesis `h : ¬p` and proving `False`.
* If `p` is a negation `¬q`, `h : q` will be introduced instead of `¬¬q`.
* If `p` is decidable, it uses `Decidable.byContradiction` instead of `Classical.byContradiction`.
* If `h` is omitted, the introduced variable will be called `this`.
">by_contra</span> <span class="lean-text">hall_le1</span>
  <span class="lean-keyword" data-docs="Push negations into the conclusion or a hypothesis.
For instance, a hypothesis `h : ¬ ∀ x, ∃ y, x ≤ y` will be transformed by `push_neg at h` into
`h : ∃ x, ∀ y, y &lt; x`. Binder names are preserved.

`push_neg` is a special case of the more general `push` tactic, namely `push Not`.
The `push` tactic can be extended using the `@[push]` attribute. `push` has special-casing
built in for `push Not`, so that it can preserve binder names, and so that `¬ (p ∧ q)` can be
transformed to either `p → ¬ q` (default) or `¬ p ∨ ¬ q` (`push_neg +distrib`).

Tactics that introduce a negation usually have a version that automatically calls `push_neg` on
that negation. These include `by_cases!`, `contrapose!` and `by_contra!`.

Another example: given a hypothesis
```lean
h : ¬ ∀ ε &gt; 0, ∃ δ &gt; 0, ∀ x, |x - x₀| ≤ δ → |f x - y₀| ≤ ε
```
writing `push_neg at h` will turn `h` into
```lean
h : ∃ ε &gt; 0, ∀ δ &gt; 0, ∃ x, |x - x₀| ≤ δ ∧ ε &lt; |f x - y₀|
```
Note that binder names are preserved by this tactic, contrary to what would happen with `simp`
using the relevant lemmas. One can use this tactic at the goal using `push_neg`,
at every hypothesis and the goal using `push_neg at *` or at selected hypotheses and the goal
using say `push_neg at h h&#x27; ⊢`, as usual.
">push_neg</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> <span class="lean-text">hall_le1</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hall_eq1</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">d</span> <span class="lean-text">=</span> <span class="lean-text">1</span> <span class="lean-text">:=</span> <span class="lean-keyword">fun</span> <span class="lean-text">d</span> <span class="lean-text">hd</span> <span class="lean-text">=&gt;</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hd_pos</span> <span class="lean-text">:=</span> <span class="lean-text">hS_pos</span> <span class="lean-text">d</span> <span class="lean-text">hd</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hd_le1</span> <span class="lean-text">:=</span> <span class="lean-text">hall_le1</span> <span class="lean-text">d</span> <span class="lean-text">hd</span>
    <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hlcm_eq1</span> <span class="lean-text">:</span> <span class="lean-text">S.lcm</span> <span class="lean-text">id</span> <span class="lean-text">=</span> <span class="lean-text">1</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> <span class="lean-text">Nat.eq_one_of_dvd_one</span>
    <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> <span class="lean-text">Finset.lcm_dvd_iff.mpr</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">d</span> <span class="lean-text">hd</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">id_eq</span><span class="lean-text">,</span> <span class="lean-text">hall_eq1</span> <span class="lean-text">d</span> <span class="lean-text">hd</span><span class="lean-text">,</span> <span class="lean-text">Nat.one_dvd</span><span class="lean-text">]</span>
  <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L433-L455" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:finset-exists-one-lt-of-two-le-lcm');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:sum-totient-ge-psi">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.12</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:sum-totient-ge-psi">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000025"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0002.html#lem:psi-le-totient">Theorem 2.0.8</a></li>
          
          <li><a href="sect0002.html#lem:finset-nonempty-of-two-le-lcm">Theorem 2.0.10</a></li>
          
          <li><a href="sect0002.html#lem:finset-exists-one-lt-of-two-le-lcm">Theorem 2.0.11</a></li>
          
          <li><a href="sect0002.html#lem:prime-pow-achieved-of-lcm-eq">Theorem 2.0.9</a></li>
          
          <li><a href="sect0002.html#lem:finset-exists-one-lt-of-two-le-lcm">Theorem 2.0.11</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0002.html#lem:psi-le-totient">Theorem 2.0.8</a></li>
          
          <li><a href="sect0002.html#lem:two-le-totient-prime-pow">Theorem 2.0.5</a></li>
          
          <li><a href="sect0002.html#lem:finset-nonempty-of-two-le-lcm">Theorem 2.0.10</a></li>
          
          <li><a href="sect0006.html#lem:sum-le-prod">Theorem A.0.1</a></li>
          
          <li><a href="sect0002.html#lem:prime-pow-achieved-of-lcm-eq">Theorem 2.0.9</a></li>
          
          <li><a href="sect0006.html#lem:primePow-mem-of-lcm-eq">Theorem A.0.3</a></li>
          
          <li><a href="sect0006.html#lem:totient-prod-coprime">Theorem A.0.6</a></li>
          
          <li><a href="sect0006.html#lem:prod-coprime-dvd">Theorem A.0.5</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.sum_totient_ge_psi_of_lcm_eq" class="lean_decl">Crystallographic.sum_totient_ge_psi_of_lcm_eq</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        For any finite set \(S\) of divisors of \(m\) with \(\mathrm{lcm}(S) = m\), we have \(\psi (m) \leq \sum _{d \in S} \varphi (d)\). </p>
<p>For a finite set \(S\) of divisors of \(m\) with \(\mathrm{lcm}(S) = m\), we have \(\sum _{d \in S} \varphi (d) \geq \psi (m)\). This follows from the prime factorization structure: each prime power \(p^k \|  m\) must appear in some \(d \in S\), contributing at least \(\psi _{\mathrm{pp}}(p, k)\). This is the combinatorial heart of the forward direction. The minimum sum is achieved when \(S\) consists of one prime power for each distinct prime in \(m\)’s prime factorization, giving exactly \(\psi (m)\).  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000025">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> For each prime power \(p^k \|  m\), some \(d \in S\) must have \(p^k \mid d\) (since \(\mathrm{lcm}(S) = m\)). The element with maximal \(p\)-valuation contributes at least \(\varphi (p^k) \geq \psi _{\mathrm{pp}}(p, k)\). Summing over distinct prime powers and using non-negativity gives the bound. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> <span class="lean-text">sum_totient_ge_psi_of_lcm_eq</span> <span class="lean-text">(</span><span class="lean-text">m</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hm</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">m</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">S</span> <span class="lean-text">:</span> <span class="lean-text">Finset</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span>
    <span class="lean-text">(</span><span class="lean-text">hS_sub</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">d</span> <span class="lean-text">∣</span> <span class="lean-text">m</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hS_lcm</span> <span class="lean-text">:</span> <span class="lean-text">S.lcm</span> <span class="lean-text">id</span> <span class="lean-text">=</span> <span class="lean-text">m</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">psi</span> <span class="lean-text">m</span> <span class="lean-text">≤</span> <span class="lean-text">∑</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">Nat.totient</span> <span class="lean-text">d</span> <span class="lean-text">:=</span></code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-comment">-- If m <span class="lean-operator">∈</span> S, apply helper lemma directly</span>
  <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> <span class="lean-text">hm_in_S</span> <span class="lean-text">:</span> <span class="lean-text">m</span> <span class="lean-text">∈</span> <span class="lean-text">S</span>
  <span class="lean-text">·</span> <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">totient_sum_ge_psi_of_mem</span> <span class="lean-text">hm</span> <span class="lean-text">S</span> <span class="lean-text">hS_sub</span> <span class="lean-text">hm_in_S</span>
  <span class="lean-comment">-- If m <span class="lean-operator">∉</span> S, we use strong induction on m</span>
  <span class="lean-text">·</span> <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
">induction</span> <span class="lean-text">m</span> <span class="lean-keyword">using</span> <span class="lean-text">Nat.strong_induction_on</span> <span class="lean-keyword">generalizing</span> <span class="lean-text">S</span> <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
">with</span>
    <span class="lean-text">|</span> <span class="lean-text">_</span> <span class="lean-text">m</span> <span class="lean-text">IH</span> <span class="lean-text">=&gt;</span>
    <span class="lean-comment">-- For m = <span class="lean-number">1</span>: psi<span class="lean-bracket">(</span><span class="lean-number">1</span><span class="lean-bracket">)</span> = <span class="lean-number">0</span> <span class="lean-operator">≤</span> any sum</span>
    <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> <span class="lean-text">hm_eq1</span> <span class="lean-text">:</span> <span class="lean-text">m</span> <span class="lean-text">=</span> <span class="lean-text">1</span>
    <span class="lean-text">·</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">hm_eq1</span><span class="lean-text">,</span> <span class="lean-text">psi_one</span><span class="lean-text">,</span> <span class="lean-text">Nat.zero_le</span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hm_ge2</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">≤</span> <span class="lean-text">m</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hS_lcm_ge2</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">≤</span> <span class="lean-text">S.lcm</span> <span class="lean-text">id</span> <span class="lean-text">:=</span> <span class="lean-text">hS_lcm</span> <span class="lean-text">▸</span> <span class="lean-text">hm_ge2</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hS_pos</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">d</span> <span class="lean-text">:=</span> <span class="lean-keyword">fun</span> <span class="lean-text">d</span> <span class="lean-text">hd</span> <span class="lean-text">=&gt;</span> <span class="lean-text">Nat.pos_of_dvd_of_pos</span> <span class="lean-text">(</span><span class="lean-text">hS_sub</span> <span class="lean-text">d</span> <span class="lean-text">hd</span><span class="lean-text">)</span> <span class="lean-text">hm</span>
    <span class="lean-comment">-- S is nonempty since lcm<span class="lean-bracket">(</span>S<span class="lean-bracket">)</span> &gt;= <span class="lean-number">2</span></span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">_hS_ne</span> <span class="lean-text">:</span> <span class="lean-text">S.Nonempty</span> <span class="lean-text">:=</span> <span class="lean-text">Finset.nonempty_of_two_le_lcm</span> <span class="lean-text">hS_lcm_ge2</span>
    <span class="lean-comment">-- Some element of S is &gt; <span class="lean-number">1</span></span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">_hS_has_gt1</span> <span class="lean-text">:</span> <span class="lean-text">∃</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">1</span> <span class="lean-text">&lt;</span> <span class="lean-text">d</span> <span class="lean-text">:=</span> <span class="lean-text">Finset.exists_one_lt_of_two_le_lcm</span> <span class="lean-text">hS_pos</span> <span class="lean-text">hS_lcm_ge2</span>
    <span class="lean-comment">-- Check if m is a prime power</span>
    <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> <span class="lean-text">hpow</span> <span class="lean-text">:</span> <span class="lean-text">IsPrimePow</span> <span class="lean-text">m</span>
    <span class="lean-text">·</span> <span class="lean-comment">-- m is a prime power p^k: contradiction since p^k must be in S</span>
      <span class="lean-keyword" data-docs="`exfalso` converts a goal `⊢ tgt` into `⊢ False` by applying `False.elim`. ">exfalso</span>
      <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">isPrimePow_nat_iff</span><span class="lean-text">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> <span class="lean-text">hpow</span>
      <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-text">⟨</span><span class="lean-text">p</span><span class="lean-text">,</span> <span class="lean-text">k</span><span class="lean-text">,</span> <span class="lean-text">hp</span><span class="lean-text">,</span> <span class="lean-text">hk</span><span class="lean-text">,</span> <span class="lean-text">hm_eq</span><span class="lean-text">⟩</span> <span class="lean-text">:=</span> <span class="lean-text">hpow</span>
      <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">hm_in_S</span> <span class="lean-text">(</span><span class="lean-text">hm_eq</span> <span class="lean-text">▸</span> <span class="lean-text">Finset.prime_pow_mem_of_lcm_eq</span> <span class="lean-text">hp</span> <span class="lean-text">hk</span> <span class="lean-text">S</span>
        <span class="lean-text">(</span><span class="lean-keyword">fun</span> <span class="lean-text">d</span> <span class="lean-text">hd</span> <span class="lean-text">=&gt;</span> <span class="lean-text">hm_eq</span> <span class="lean-text">▸</span> <span class="lean-text">hS_sub</span> <span class="lean-text">d</span> <span class="lean-text">hd</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hm_eq</span> <span class="lean-text">▸</span> <span class="lean-text">hS_lcm</span><span class="lean-text">)</span><span class="lean-text">)</span>
    <span class="lean-text">·</span> <span class="lean-comment">-- m is not a prime power: use achiever function approach</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">h_achieves</span> <span class="lean-text">:=</span> <span class="lean-text">primePow_achieved_of_lcm_eq</span> <span class="lean-text">hm</span> <span class="lean-text">S</span> <span class="lean-text">hS_sub</span> <span class="lean-text">hS_lcm</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">h_ach</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">q</span> <span class="lean-text">∈</span> <span class="lean-text">nontrivialPrimes</span> <span class="lean-text">m</span><span class="lean-text">,</span> <span class="lean-text">∃</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">q</span> <span class="lean-text">^</span> <span class="lean-text">m.factorization</span> <span class="lean-text">q</span> <span class="lean-text">∣</span> <span class="lean-text">d</span> <span class="lean-text">:=</span> <span class="lean-keyword">fun</span> <span class="lean-text">q</span> <span class="lean-text">hq</span> <span class="lean-text">=&gt;</span>
        <span class="lean-text">h_achieves</span> <span class="lean-text">q</span> <span class="lean-text">(</span><span class="lean-text">Finset.mem_of_mem_filter</span> <span class="lean-text">q</span> <span class="lean-text">hq</span><span class="lean-text">)</span>
      <span class="lean-comment">-- Construct achiever function and prove its properties</span>
      <span class="lean-keyword" data-docs="The `let` tactic is for adding definitions to the local context of the main goal.
The definition can be unfolded, unlike definitions introduced by `have`.

* `let x : t := e` adds the definition `x : t := e` if `e` is a term of type `t`.
* `let x := e` uses the type of `e` for `t`.
* `let : t := e` and `let := e` use `this` for the name of the hypothesis.
* `let pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that let only one applicable constructor.
  For example, given `p : α × β × γ`, `let ⟨x, y, z⟩ := p` produces the
  local variables `x : α`, `y : β`, and `z : γ`.
* The syntax `let (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `let` term.

## Properties and relations

* Unlike `have`, it is possible to unfold definitions introduced using `let`, using tactics
  such as `simp`, `dsimp`, `unfold`, and `subst`.
* The `clear_value` tactic turns a `let` definition into a `have` definition after the fact.
  The tactic might fail if the local context depends on the value of the variable.
* The `let` tactic is preferred for data (non-propositions).
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
">let</span> <span class="lean-text">achiever</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span> <span class="lean-text">→</span> <span class="lean-text">ℕ</span> <span class="lean-text">:=</span> <span class="lean-keyword">fun</span> <span class="lean-text">q</span> <span class="lean-text">=&gt;</span>
        <span class="lean-keyword" data-docs="&quot;Dependent&quot; if-then-else, normally written via the notation `if h : c then t(h) else e(h)`,
is sugar for `dite c (fun h =&gt; t(h)) (fun h =&gt; e(h))`, and it is the same as
`if c then t else e` except that `t` is allowed to depend on a proof `h : c`,
and `e` can depend on `h : ¬c`. (Both branches use the same name for the hypothesis,
even though it has different types in the two cases.)

We use this to be able to communicate the if-then-else condition to the branches.
For example, `Array.get arr i h` expects a proof `h : i &lt; arr.size` in order to
avoid a bounds check, so you can write `if h : i &lt; arr.size then arr.get i h else ...`
to avoid the bounds check inside the if branch. (Of course in this case we have only
lifted the check into an explicit `if`, but we could also use this proof multiple times
or derive `i &lt; arr.size` from some other proposition that we are checking in the `if`.)
">if</span> <span class="lean-text">hq</span> <span class="lean-text">:</span> <span class="lean-text">q</span> <span class="lean-text">∈</span> <span class="lean-text">nontrivialPrimes</span> <span class="lean-text">m</span> <span class="lean-keyword" data-docs="&quot;Dependent&quot; if-then-else, normally written via the notation `if h : c then t(h) else e(h)`,
is sugar for `dite c (fun h =&gt; t(h)) (fun h =&gt; e(h))`, and it is the same as
`if c then t else e` except that `t` is allowed to depend on a proof `h : c`,
and `e` can depend on `h : ¬c`. (Both branches use the same name for the hypothesis,
even though it has different types in the two cases.)

We use this to be able to communicate the if-then-else condition to the branches.
For example, `Array.get arr i h` expects a proof `h : i &lt; arr.size` in order to
avoid a bounds check, so you can write `if h : i &lt; arr.size then arr.get i h else ...`
to avoid the bounds check inside the if branch. (Of course in this case we have only
lifted the check into an explicit `if`, but we could also use this proof multiple times
or derive `i &lt; arr.size` from some other proposition that we are checking in the `if`.)
">then</span> <span class="lean-text">(</span><span class="lean-text">h_ach</span> <span class="lean-text">q</span> <span class="lean-text">hq</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">choose</span> <span class="lean-keyword" data-docs="&quot;Dependent&quot; if-then-else, normally written via the notation `if h : c then t(h) else e(h)`,
is sugar for `dite c (fun h =&gt; t(h)) (fun h =&gt; e(h))`, and it is the same as
`if c then t else e` except that `t` is allowed to depend on a proof `h : c`,
and `e` can depend on `h : ¬c`. (Both branches use the same name for the hypothesis,
even though it has different types in the two cases.)

We use this to be able to communicate the if-then-else condition to the branches.
For example, `Array.get arr i h` expects a proof `h : i &lt; arr.size` in order to
avoid a bounds check, so you can write `if h : i &lt; arr.size then arr.get i h else ...`
to avoid the bounds check inside the if branch. (Of course in this case we have only
lifted the check into an explicit `if`, but we could also use this proof multiple times
or derive `i &lt; arr.size` from some other proposition that we are checking in the `if`.)
">else</span> <span class="lean-text">0</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">h_achiever_mem</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">q</span> <span class="lean-text">∈</span> <span class="lean-text">nontrivialPrimes</span> <span class="lean-text">m</span><span class="lean-text">,</span> <span class="lean-text">achiever</span> <span class="lean-text">q</span> <span class="lean-text">∈</span> <span class="lean-text">S</span> <span class="lean-text">:=</span> <span class="lean-keyword">fun</span> <span class="lean-text">q</span> <span class="lean-text">hq</span> <span class="lean-text">=&gt;</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
        <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">achiever</span><span class="lean-text">,</span> <span class="lean-text">dif_pos</span> <span class="lean-text">hq</span><span class="lean-text">]</span><span class="lean-text">;</span> <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">(</span><span class="lean-text">h_ach</span> <span class="lean-text">q</span> <span class="lean-text">hq</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">choose_spec</span><span class="lean-text">.</span><span class="lean-text">1</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">h_achiever_dvd</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">q</span> <span class="lean-text">∈</span> <span class="lean-text">nontrivialPrimes</span> <span class="lean-text">m</span><span class="lean-text">,</span> <span class="lean-text">q</span> <span class="lean-text">^</span> <span class="lean-text">m.factorization</span> <span class="lean-text">q</span> <span class="lean-text">∣</span> <span class="lean-text">achiever</span> <span class="lean-text">q</span> <span class="lean-text">:=</span>
        <span class="lean-keyword">fun</span> <span class="lean-text">q</span> <span class="lean-text">hq</span> <span class="lean-text">=&gt;</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">achiever</span><span class="lean-text">,</span> <span class="lean-text">dif_pos</span> <span class="lean-text">hq</span><span class="lean-text">]</span><span class="lean-text">;</span> <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">(</span><span class="lean-text">h_ach</span> <span class="lean-text">q</span> <span class="lean-text">hq</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">choose_spec</span><span class="lean-text">.</span><span class="lean-text">2</span>
      <span class="lean-comment">-- Apply the fiberwise bound</span>
      <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
">calc</span> <span class="lean-text">psi</span> <span class="lean-text">m</span>
          <span class="lean-text">=</span> <span class="lean-text">∑</span> <span class="lean-text">q</span> <span class="lean-text">∈</span> <span class="lean-text">nontrivialPrimes</span> <span class="lean-text">m</span><span class="lean-text">,</span> <span class="lean-text">Nat.totient</span> <span class="lean-text">(</span><span class="lean-text">q</span> <span class="lean-text">^</span> <span class="lean-text">m.factorization</span> <span class="lean-text">q</span><span class="lean-text">)</span> <span class="lean-text">:=</span>
            <span class="lean-text">psi_eq_sum_nontrivial_totients</span> <span class="lean-text">m</span>
        <span class="lean-text">_</span> <span class="lean-text">≤</span> <span class="lean-text">∑</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">Nat.totient</span> <span class="lean-text">d</span> <span class="lean-text">:=</span>
            <span class="lean-text">sum_nontrivial_totients_le_sum_totients</span> <span class="lean-text">S</span> <span class="lean-text">hS_pos</span> <span class="lean-text">achiever</span> <span class="lean-text">h_achiever_mem</span> <span class="lean-text">h_achiever_dvd</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L457-L524" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:sum-totient-ge-psi');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>



</div> <!--main-text -->
</div> <!-- content-wrapper -->
</div> <!-- content -->
</div> <!-- wrapper -->

<nav class="prev_up_next">
  <svg  id="showmore-minus" class="icon icon-eye-minus showmore"><use xlink:href="symbol-defs.svg#icon-eye-minus"></use></svg>

  <svg  id="showmore-plus" class="icon icon-eye-plus showmore"><use xlink:href="symbol-defs.svg#icon-eye-plus"></use></svg>

  <a href="sect0001.html" title="Introduction"><svg  class="icon icon-arrow-left "><use xlink:href="symbol-defs.svg#icon-arrow-left"></use></svg>
</a>
  <a href="index.html" title="Crystallographic Restriction Theorem"><svg  class="icon icon-arrow-up "><use xlink:href="symbol-defs.svg#icon-arrow-up"></use></svg>
</a>
  <a href="sect0003.html" title="Integer Matrix Orders"><svg  class="icon icon-arrow-right "><use xlink:href="symbol-defs.svg#icon-arrow-right"></use></svg>
</a>
</nav>

<script type="text/javascript" src="js/jquery.min.js"></script>
<script type="text/javascript" src="js/plastex.js"></script>
<script type="text/javascript" src="js/svgxuse.js"></script>
<script type="text/javascript" src="js/js.cookie.min.js"></script>
<script type="text/javascript" src="js/showmore.js"></script>
</body>
</html>