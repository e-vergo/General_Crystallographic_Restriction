<!DOCTYPE html>
<html lang="en">
<head>
<script>
  MathJax = { 
    tex: {
		    inlineMath: [['$','$'], ['\\(','\\)']]
	} }
</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
<meta name="generator" content="plasTeX" />
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>The Psi Function</title>
<link rel="next" href="sect0003.html" title="Integer Matrix Orders" />
<link rel="prev" href="sect0001.html" title="Introduction" />
<link rel="up" href="index.html" title="Crystallographic Restriction Theorem" />
<link rel="stylesheet" href="styles/theme-blue.css" />
<link rel="stylesheet" href="styles/showmore.css" />
<link rel="stylesheet" href="styles/blueprint.css" />
<link rel="stylesheet" href="styles/amsthm.css" />
<link rel="stylesheet" href="styles/style.css" />
</head>

<body>
<header>
<svg  id="toc-toggle" class="icon icon-list-numbered "><use xlink:href="symbol-defs.svg#icon-list-numbered"></use></svg>
<h1 id="doc_title"><a href="index.html">Crystallographic Restriction Theorem</a></h1>
</header>

<div class="wrapper">
<nav class="toc">
<ul class="sub-toc-0">
<li class="">
  <a href="sect0001.html"><span class="toc_ref">1</span> <span class="toc_entry">Introduction</span></a>
 </li>
<li class=" active current">
  <a href="sect0002.html"><span class="toc_ref">2</span> <span class="toc_entry">The Psi Function</span></a>
 </li>
<li class="">
  <a href="sect0003.html"><span class="toc_ref">3</span> <span class="toc_entry">Integer Matrix Orders</span></a>
 </li>
<li class="">
  <a href="sect0004.html"><span class="toc_ref">4</span> <span class="toc_entry">Companion Matrices</span></a>
 </li>
<li class="">
  <a href="sect0005.html"><span class="toc_ref">5</span> <span class="toc_entry">The Crystallographic Restriction Theorem</span></a>
 </li>
<li class="">
  <a href="sect0006.html"><span class="toc_ref">A</span> <span class="toc_entry">Appendix</span></a>
 </li>
<li ><a href="dep_graph_document.html">Dependency graph</a></li>
</ul>
</nav>

<div class="content">
<div class="content-wrapper">


<div class="main-text">
<h1 id="a0000000003">2 The Psi Function</h1>
<p>The \(\psi \) function measures the “arithmetic complexity” of a positive integer \(m\). For a prime power \(p^k\), we define: </p>
<ul class="itemize">
  <li><p>\(\psi _{\mathrm{pp}}(p,k) = \varphi (p^k)\) for \(p\) odd or \(k \geq 2\) </p>
</li>
  <li><p>\(\psi _{\mathrm{pp}}(2,1) = 0\) </p>
</li>
</ul>
<p>For a general integer \(m\) with prime factorization \(m = \prod _i p_i^{k_i}\), we have: </p>
<div class="displaymath" id="a0000000011">
  \[ \psi (m) = \sum _i \psi _{\mathrm{pp}}(p_i, k_i) \]
</div>
<div class="definition_thmwrapper sbs-container theorem-style-definition" id="psiPrimePow-def">
  <div class="sbs-latex-column">
    <div class="definition_thmheading">
      <span class="definition_thmcaption">
      Definition
      </span>
      <span class="definition_thmlabel">2.0.1</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#psiPrimePow-def">#</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psiPrimePow" class="lean_decl">Crystallographic.psiPrimePow</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="definition_thmcontent">
    <p>      The function \(\psi _{\text{pp}}(p, k)\) computes the contribution of a single prime power \(p^k\) to \(\psi \). Returns \(0\) if \(k = 0\) or if \(p = 2\) and \(k = 1\), otherwise returns \(\varphi (p^k)\). </p>
<p>The special case \(\psi _{\text{pp}}(2, 1) = 0\) reflects that \(-I\) achieves order \(2\) in any dimension \(\geq 1\), so order \(2\) does not require additional dimensions. For all other prime powers \(p^k\), we need \(\varphi (p^k)\) dimensions to achieve order \(p^k\). </p>

    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">def</span> <span class="lean-const lean-def" data-name="Crystallographic.psiPrimePow" data-signature="Crystallographic.psiPrimePow (p k : ℕ) : ℕ" data-docs="Helper function that computes the contribution of a single prime power p^k to psi.
Returns 0 if k = 0, returns 0 if p = 2 and k = 1, otherwise returns phi(p^k). " title="Crystallographic.psiPrimePow (p k : ℕ) : ℕ
Helper function that computes the contribution of a single prime power p^k to psi....">psiPrimePow</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> <span class="lean-var" data-type="ℕ" title="ℕ">k</span> : ℕ<span class="lean-bracket-1">)</span> : ℕ :=
  <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
" title="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to">if</span> <span class="lean-var" data-type="ℕ" title="ℕ">k</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
" title="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to">then</span> <span class="lean-expr" data-type="ℕ" title="ℕ">0</span>
  <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
" title="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to">else</span> <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
" title="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to">if</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> <span class="lean-operator">∧</span> <span class="lean-var" data-type="ℕ" title="ℕ">k</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
" title="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to">then</span> <span class="lean-expr" data-type="ℕ" title="ℕ">0</span>
  <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
" title="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to">else</span> <span class="lean-const" data-name="Nat.totient" data-signature="Nat.totient (n : ℕ) : ℕ" data-docs="Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are
coprime with `n`. " title="Nat.totient (n : ℕ) : ℕ
Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are...">Nat.totient</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">k</span><span class="lean-bracket-1">)</span></code><code class="lean-proof-body"><span class="lean-plain">(p k : ℕ) : ℕ :=
  if k = 0 then 0
  else if p = 2 ∧ k = 1 then 0
  else Nat.totient (p ^ k)</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Basic.lean#L49-L63" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>

<div class="definition_thmwrapper sbs-container theorem-style-definition" id="psi-def">
  <div class="sbs-latex-column">
    <div class="definition_thmheading">
      <span class="definition_thmcaption">
      Definition
      </span>
      <span class="definition_thmlabel">2.0.2</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#psi-def">#</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psi" class="lean_decl">Crystallographic.psi</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="definition_thmcontent">
    <p>       The psi function \(\psi (m) = \sum _{p^k \|  m} \psi _{\text{pp}}(p, k)\), which gives the minimum dimension \(N\) such that an \(N \times N\) integer matrix can have order \(m\). </p>
<p>For \(m\) with prime factorization \(m = \prod _i p_i^{k_i}\): </p>
<div class="displaymath" id="a0000000012">
  \[ \psi (m) = \sum _i \psi _{\text{pp}}(p_i, k_i) = \sum _{\substack {p^k \|  m \\ (p,k) \neq (2,1)}} \varphi (p^k) \]
</div>
<p> This gives the minimum dimension needed to realize order \(m\).  </p>

    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">def</span> <span class="lean-const lean-def" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">m</span> : ℕ<span class="lean-bracket-1">)</span> : ℕ :=
  <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span>.<span class="lean-const" data-name="Finsupp.sum" data-signature="Finsupp.sum.{u_1, u_8, u_10} {α : Type u_1} {M : Type u_8} {N : Type u_10} [Zero M] [AddCommMonoid N] (f : α →₀ M)
  (g : α → M → N) : N" data-docs="`sum f g` is the sum of `g a (f a)` over the support of `f`. " title="Finsupp.sum.{u_1, u_8, u_10} {α : Type u_1} {M : Type u_8} {N : Type u_10} [Zero M] [AddCommMonoid N] (f : α →₀ M)
  (g : α → M → N) : N
`sum f g` is the sum of `g a (f a)` over the support of `f`. ">sum</span> <span class="lean-keyword">fun</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> <span class="lean-var" data-type="ℕ" title="ℕ">k</span> =&gt; <span class="lean-const" data-name="Crystallographic.psiPrimePow" data-signature="Crystallographic.psiPrimePow (p k : ℕ) : ℕ" data-docs="Helper function that computes the contribution of a single prime power p^k to psi.
Returns 0 if k = 0, returns 0 if p = 2 and k = 1, otherwise returns phi(p^k). " title="Crystallographic.psiPrimePow (p k : ℕ) : ℕ
Helper function that computes the contribution of a single prime power p^k to psi....">psiPrimePow</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> <span class="lean-var" data-type="ℕ" title="ℕ">k</span></code><code class="lean-proof-body"><span class="lean-plain">(m : ℕ) : ℕ :=
  m.factorization.sum fun p k =&gt; psiPrimePow p k</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Basic.lean#L70-L87" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>

<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:psi-prime-pow">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.1</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:psi-prime-pow">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000013"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psi_prime_pow" class="lean_decl">Crystallographic.psi_prime_pow</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        For prime \(p\) and \(k {\gt} 0\): \(\psi (p^k) = \varphi (p^k)\) unless \(p = 2, k = 1\). </p>
<p>For a prime power \(p^k\), the factorization has a single term, so \(\psi (p^k) = \psi _{\text{pp}}(p, k)\). This equals \(\varphi (p^k) = p^{k-1}(p-1)\) except when \(p = 2\) and \(k = 1\).  </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000013">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> For prime power \(p^k\), the factorization has a single term, so \(\psi (p^k) = \psi _{pp}(p, k)\). This equals \(\varphi (p^k)\) except when \(p = 2, k = 1\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> <span class="lean-const lean-def" data-name="Crystallographic.psi_prime_pow" data-signature="Crystallographic.psi_prime_pow (p k : ℕ) (hp : Nat.Prime p) (hk : 0 &lt; k) :
  psi (p ^ k) = if p = 2 ∧ k = 1 then 0 else φ (p ^ k)" data-docs="`psi` of a prime power p^k equals phi(p^k), except `psi 2 = 0` " title="Crystallographic.psi_prime_pow (p k : ℕ) (hp : Nat.Prime p) (hk : 0 &lt; k) :
  psi (p ^ k) = if p = 2 ∧ k = 1 then 0 else φ (p ^ k)
`psi` of a prime power p^k equals phi(p^k), except `psi 2 = 0` ">psi_prime_pow</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> <span class="lean-var" data-type="ℕ" title="ℕ">k</span> : ℕ<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hp</span> : <span class="lean-var" data-type="ℕ" title="ℕ">p</span>.<span class="lean-const" data-name="Nat.Prime" data-signature="Nat.Prime (p : ℕ) : Prop" data-docs="`Nat.Prime p` means that `p` is a prime number, that is, a natural number
at least 2 whose only divisors are `p` and `1`.
The theorem `Nat.prime_def` witnesses this description of a prime number. " title="Nat.Prime (p : ℕ) : Prop
`Nat.Prime p` means that `p` is a prime number, that is, a natural number...">Prime</span><span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="0 &lt; k" title="0 &lt; k">hk</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">k</span><span class="lean-bracket-1">)</span> :
    <span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">k</span><span class="lean-bracket-1">)</span> = <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
" title="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to">if</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> <span class="lean-operator">∧</span> <span class="lean-var" data-type="ℕ" title="ℕ">k</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
" title="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to">then</span> <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> <span class="lean-keyword" data-docs="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to
return `t` or `e` depending on whether `c` is true or false. The explicit argument
`c : Prop` does not have any actual computational content, but there is an additional
`[Decidable c]` argument synthesized by typeclass inference which actually
determines how to evaluate `c` to true or false. Write `if h : c then t else e`
instead for a &quot;dependent if-then-else&quot; `dite`, which allows `t`/`e` to use the fact
that `c` is true/false.
" title="`if c then t else e` is notation for `ite c t e`, &quot;if-then-else&quot;, which decides to">else</span> <span class="lean-const" data-name="Nat.totient" data-signature="Nat.totient (n : ℕ) : ℕ" data-docs="Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are
coprime with `n`. " title="Nat.totient (n : ℕ) : ℕ
Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are...">Nat.totient</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">k</span><span class="lean-bracket-1">)</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span></code><code class="lean-proof-body">
  <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span><span class="lean-bracket-1">]</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hp</span>.<span class="lean-const" data-name="Nat.Prime.factorization_pow" data-signature="Nat.Prime.factorization_pow {p k : ℕ} (hp : Nat.Prime p) : (p ^ k).factorization = single p k" data-docs="For prime `p` the only prime factor of `p^k` is `p` with multiplicity `k` " title="Nat.Prime.factorization_pow {p k : ℕ} (hp : Nat.Prime p) : (p ^ k).factorization = single p k
For prime `p` the only prime factor of `p^k` is `p` with multiplicity `k` ">factorization_pow</span><span class="lean-bracket-1">]</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Finsupp.sum_single_index" data-signature="Finsupp.sum_single_index.{u_1, u_8, u_10} {α : Type u_1} {M : Type u_8} {N : Type u_10} [Zero M] [AddCommMonoid N]
  {a : α} {b : M} {h : α → M → N} (h_zero : h a 0 = 0) : (single a b).sum h = h a b" title="Finsupp.sum_single_index.{u_1, u_8, u_10} {α : Type u_1} {M : Type u_8} {N : Type u_10} [Zero M] [AddCommMonoid N]
  {a : α} {b : M} {h : α → M → N} (h_zero : h a 0 = 0) : (single a b).sum h = h a b">Finsupp.sum_single_index</span> <span class="lean-bracket-2">(</span><span class="lean-const" data-name="Crystallographic.psiPrimePow_zero" data-signature="Crystallographic.psiPrimePow_zero (p : ℕ) : psiPrimePow p 0 = 0" data-docs="psiPrimePow at exponent 0 is always 0. " title="Crystallographic.psiPrimePow_zero (p : ℕ) : psiPrimePow p 0 = 0
psiPrimePow at exponent 0 is always 0. ">psiPrimePow_zero</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span><span class="lean-bracket-2">)</span><span class="lean-bracket-1">]</span>
  <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Crystallographic.psiPrimePow" data-signature="Crystallographic.psiPrimePow (p k : ℕ) : ℕ" data-docs="Helper function that computes the contribution of a single prime power p^k to psi.
Returns 0 if k = 0, returns 0 if p = 2 and k = 1, otherwise returns phi(p^k). " title="Crystallographic.psiPrimePow (p k : ℕ) : ℕ
Helper function that computes the contribution of a single prime power p^k to psi....">psiPrimePow</span>, <span class="lean-var" data-type="0 &lt; k" title="0 &lt; k">hk</span>.<span class="lean-const" data-name="LT.lt.ne&#x27;" data-signature="LT.lt.ne&#x27;.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : b &lt; a) : a ≠ b" title="LT.lt.ne&#x27;.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : b &lt; a) : a ≠ b">ne&#x27;</span>, <span class="lean-const" data-name="ite_false" data-signature="ite_false.{u_1} {α : Sort u_1} (a b : α) : (if False then a else b) = b" title="ite_false.{u_1} {α : Sort u_1} (a b : α) : (if False then a else b) = b">ite_false</span><span class="lean-bracket-1">]</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Basic.lean#L107-L122" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:psi-prime-pow');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:factorization-disjoint">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.2</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:factorization-disjoint">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000014"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.factorization_support_disjoint" class="lean_decl">Crystallographic.factorization_support_disjoint</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       Coprime numbers have disjoint prime factorization supports. </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000014">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>If \(p\) divides both \(m\) and \(n\), then \(p \mid \gcd (m,n) = 1\), contradicting \(p\) prime. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> <span class="lean-const lean-def" data-name="Crystallographic.factorization_support_disjoint" data-signature="Crystallographic.factorization_support_disjoint {m n : ℕ} (h : m.Coprime n) :
  Disjoint m.factorization.support n.factorization.support" data-docs="The supports of factorizations of coprime numbers are disjoint.

If gcd(m, n) = 1, then m and n share no common prime factors. " title="Crystallographic.factorization_support_disjoint {m n : ℕ} (h : m.Coprime n) :
  Disjoint m.factorization.support n.factorization.support
The supports of factorizations of coprime numbers are disjoint....">factorization_support_disjoint</span> <span class="lean-bracket-1">{</span><span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-var" data-type="ℕ" title="ℕ">n</span> : ℕ<span class="lean-bracket-1">}</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="m.Coprime n" title="m.Coprime n">h</span> : <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.Coprime" data-signature="Nat.Coprime (m n : ℕ) : Prop" data-docs="`m` and `n` are coprime, or relatively prime, if their `gcd` is 1. " title="Nat.Coprime (m n : ℕ) : Prop
`m` and `n` are coprime, or relatively prime, if their `gcd` is 1. ">Coprime</span> <span class="lean-var" data-type="ℕ" title="ℕ">n</span><span class="lean-bracket-1">)</span> :
    <span class="lean-const" data-name="Disjoint" data-signature="Disjoint.{u_1} {α : Type u_1} [PartialOrder α] [OrderBot α] (a b : α) : Prop" data-docs="Two elements of a lattice are disjoint if their inf is the bottom element.
  (This generalizes disjoint sets, viewed as members of the subset lattice.)

Note that we define this without reference to `⊓`, as this allows us to talk about orders where
the infimum is not unique, or where implementing `Inf` would require additional `Decidable`
arguments. " title="Disjoint.{u_1} {α : Type u_1} [PartialOrder α] [OrderBot α] (a b : α) : Prop
Two elements of a lattice are disjoint if their inf is the bottom element....">Disjoint</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span>.<span class="lean-const" data-name="Finsupp.support" data-signature="Finsupp.support.{u_9, u_10} {α : Type u_9} {M : Type u_10} [Zero M] (self : α →₀ M) : Finset α" data-docs="The support of a finitely supported function (aka `Finsupp`). " title="Finsupp.support.{u_9, u_10} {α : Type u_9} {M : Type u_10} [Zero M] (self : α →₀ M) : Finset α
The support of a finitely supported function (aka `Finsupp`). ">support</span> <span class="lean-var" data-type="ℕ" title="ℕ">n</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span>.<span class="lean-const" data-name="Finsupp.support" data-signature="Finsupp.support.{u_9, u_10} {α : Type u_9} {M : Type u_10} [Zero M] (self : α →₀ M) : Finset α" data-docs="The support of a finitely supported function (aka `Finsupp`). " title="Finsupp.support.{u_9, u_10} {α : Type u_9} {M : Type u_10} [Zero M] (self : α →₀ M) : Finset α
The support of a finitely supported function (aka `Finsupp`). ">support</span> :=</code><code class="lean-proof-body">
  <span class="lean-const" data-name="Nat.support_factorization" data-signature="Nat.support_factorization (n : ℕ) : n.factorization.support = n.primeFactors" data-docs="The support of `n.factorization` is exactly `n.primeFactors`. " title="Nat.support_factorization (n : ℕ) : n.factorization.support = n.primeFactors
The support of `n.factorization` is exactly `n.primeFactors`. ">Nat.support_factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> ▸ <span class="lean-const" data-name="Nat.support_factorization" data-signature="Nat.support_factorization (n : ℕ) : n.factorization.support = n.primeFactors" data-docs="The support of `n.factorization` is exactly `n.primeFactors`. " title="Nat.support_factorization (n : ℕ) : n.factorization.support = n.primeFactors
The support of `n.factorization` is exactly `n.primeFactors`. ">Nat.support_factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">n</span> ▸ <span class="lean-var" data-type="m.Coprime n" title="m.Coprime n">h</span>.<span class="lean-const" data-name="Nat.Coprime.disjoint_primeFactors" data-signature="Nat.Coprime.disjoint_primeFactors {a b : ℕ} (hab : a.Coprime b) : Disjoint a.primeFactors b.primeFactors" title="Nat.Coprime.disjoint_primeFactors {a b : ℕ} (hab : a.Coprime b) : Disjoint a.primeFactors b.primeFactors">disjoint_primeFactors</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Basic.lean#L161-L169" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:factorization-disjoint');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:psi-coprime-add">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.3</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:psi-coprime-add">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000015"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0002.html#lem:factorization-disjoint">Theorem 2.0.2</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0002.html#lem:factorization-disjoint">Theorem 2.0.2</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psi_coprime_add" class="lean_decl">Crystallographic.psi_coprime_add</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        \(\psi (mn) = \psi (m) + \psi (n)\) for coprime \(m, n\). </p>
<p>When \(\gcd (m, n) = 1\), the prime factorizations of \(m\) and \(n\) share no common primes, so </p>
<div class="displaymath" id="a0000000016">
  \[ \psi (mn) = \sum _{p^k \|  mn} \psi _{\text{pp}}(p, k) = \sum _{p^k \|  m} \psi _{\text{pp}}(p, k) + \sum _{p^k \|  n} \psi _{\text{pp}}(p, k) = \psi (m) + \psi (n). \]
</div>


    </div>
    <div class="proof_wrapper proof_inline" id="a0000000015">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> When \(\gcd (m, n) = 1\), the factorizations of \(m\) and \(n\) are disjoint. Each prime power in \(mn\) comes from exactly one of \(m\) or \(n\), so the \(\psi \) contributions add. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> <span class="lean-const lean-def" data-name="Crystallographic.psi_coprime_add" data-signature="Crystallographic.psi_coprime_add (m n : ℕ) (hm : 0 &lt; m) (hn : 0 &lt; n) (h : m.Coprime n) : psi (m * n) = psi m + psi n" data-docs="`psi` is additive on coprime factors.

For coprime m and n, `psi (m * n) = psi m + psi n`. This follows from the
factorization m * n = prod(p_i^{k_i}) * prod(q_j^{l_j}) where the prime
factors of m and n are disjoint. " title="Crystallographic.psi_coprime_add (m n : ℕ) (hm : 0 &lt; m) (hn : 0 &lt; n) (h : m.Coprime n) : psi (m * n) = psi m + psi n
`psi` is additive on coprime factors....">psi_coprime_add</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-var" data-type="ℕ" title="ℕ">n</span> : ℕ<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="0 &lt; m" title="0 &lt; m">hm</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span><span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="0 &lt; n" title="0 &lt; n">hn</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">n</span><span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="m.Coprime n" title="m.Coprime n">h</span> : <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.Coprime" data-signature="Nat.Coprime (m n : ℕ) : Prop" data-docs="`m` and `n` are coprime, or relatively prime, if their `gcd` is 1. " title="Nat.Coprime (m n : ℕ) : Prop
`m` and `n` are coprime, or relatively prime, if their `gcd` is 1. ">Coprime</span> <span class="lean-var" data-type="ℕ" title="ℕ">n</span><span class="lean-bracket-1">)</span> :
    <span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">m</span> * <span class="lean-var" data-type="ℕ" title="ℕ">n</span><span class="lean-bracket-1">)</span> = <span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> + <span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span> <span class="lean-var" data-type="ℕ" title="ℕ">n</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span></code><code class="lean-proof-body">
  <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span>, <span class="lean-const" data-name="Finsupp.sum" data-signature="Finsupp.sum.{u_1, u_8, u_10} {α : Type u_1} {M : Type u_8} {N : Type u_10} [Zero M] [AddCommMonoid N] (f : α →₀ M)
  (g : α → M → N) : N" data-docs="`sum f g` is the sum of `g a (f a)` over the support of `f`. " title="Finsupp.sum.{u_1, u_8, u_10} {α : Type u_1} {M : Type u_8} {N : Type u_10} [Zero M] [AddCommMonoid N] (f : α →₀ M)
  (g : α → M → N) : N
`sum f g` is the sum of `g a (f a)` over the support of `f`. ">Finsupp.sum</span><span class="lean-bracket-1">]</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Nat.factorization_mul" data-signature="Nat.factorization_mul {a b : ℕ} (ha : a ≠ 0) (hb : b ≠ 0) : (a * b).factorization = a.factorization + b.factorization" data-docs="For nonzero `a` and `b`, the power of `p` in `a * b` is the sum of the powers in `a` and `b` " title="Nat.factorization_mul {a b : ℕ} (ha : a ≠ 0) (hb : b ≠ 0) : (a * b).factorization = a.factorization + b.factorization
For nonzero `a` and `b`, the power of `p` in `a * b` is the sum of the powers in `a` and `b` ">Nat.factorization_mul</span> <span class="lean-bracket-2">(</span><span class="lean-const" data-name="Nat.pos_iff_ne_zero" data-signature="Nat.pos_iff_ne_zero {n : ℕ} : 0 &lt; n ↔ n ≠ 0" title="Nat.pos_iff_ne_zero {n : ℕ} : 0 &lt; n ↔ n ≠ 0">Nat.pos_iff_ne_zero</span>.<span class="lean-const" data-name="Iff.mp" data-signature="Iff.mp {a b : Prop} (self : a ↔ b) : a → b" data-docs="Modus ponens for if and only if. If `a ↔ b` and `a`, then `b`. " title="Iff.mp {a b : Prop} (self : a ↔ b) : a → b
Modus ponens for if and only if. If `a ↔ b` and `a`, then `b`. ">mp</span> <span class="lean-var" data-type="0 &lt; m" title="0 &lt; m">hm</span><span class="lean-bracket-2">)</span> <span class="lean-bracket-2">(</span><span class="lean-const" data-name="Nat.pos_iff_ne_zero" data-signature="Nat.pos_iff_ne_zero {n : ℕ} : 0 &lt; n ↔ n ≠ 0" title="Nat.pos_iff_ne_zero {n : ℕ} : 0 &lt; n ↔ n ≠ 0">Nat.pos_iff_ne_zero</span>.<span class="lean-const" data-name="Iff.mp" data-signature="Iff.mp {a b : Prop} (self : a ↔ b) : a → b" data-docs="Modus ponens for if and only if. If `a ↔ b` and `a`, then `b`. " title="Iff.mp {a b : Prop} (self : a ↔ b) : a → b
Modus ponens for if and only if. If `a ↔ b` and `a`, then `b`. ">mp</span> <span class="lean-var" data-type="0 &lt; n" title="0 &lt; n">hn</span><span class="lean-bracket-2">)</span><span class="lean-bracket-1">]</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="Disjoint m.factorization.support n.factorization.support" title="Disjoint m.factorization.support n.factorization.support">hdisj</span> := <span class="lean-const" data-name="Crystallographic.factorization_support_disjoint" data-signature="Crystallographic.factorization_support_disjoint {m n : ℕ} (h : m.Coprime n) :
  Disjoint m.factorization.support n.factorization.support" data-docs="The supports of factorizations of coprime numbers are disjoint.

If gcd(m, n) = 1, then m and n share no common prime factors. " title="Crystallographic.factorization_support_disjoint {m n : ℕ} (h : m.Coprime n) :
  Disjoint m.factorization.support n.factorization.support
The supports of factorizations of coprime numbers are disjoint....">factorization_support_disjoint</span> <span class="lean-var" data-type="m.Coprime n" title="m.Coprime n">h</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Finsupp.support_add_eq" data-signature="Finsupp.support_add_eq.{u_1, u_3} {ι : Type u_1} {M : Type u_3} [AddZeroClass M] {g₁ g₂ : ι →₀ M} [DecidableEq ι]
  (h : Disjoint g₁.support g₂.support) : (g₁ + g₂).support = g₁.support ∪ g₂.support" title="Finsupp.support_add_eq.{u_1, u_3} {ι : Type u_1} {M : Type u_3} [AddZeroClass M] {g₁ g₂ : ι →₀ M} [DecidableEq ι]
  (h : Disjoint g₁.support g₂.support) : (g₁ + g₂).support = g₁.support ∪ g₂.support">Finsupp.support_add_eq</span> <span class="lean-var" data-type="Disjoint m.factorization.support n.factorization.support" title="Disjoint m.factorization.support n.factorization.support">hdisj</span><span class="lean-bracket-1">]</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Finset.sum_union" data-signature="Finset.sum_union.{u_1, u_4} {ι : Type u_1} {M : Type u_4} {s₁ s₂ : Finset ι} [AddCommMonoid M] {f : ι → M}
  [DecidableEq ι] (h : Disjoint s₁ s₂) : ∑ x ∈ s₁ ∪ s₂, f x = ∑ x ∈ s₁, f x + ∑ x ∈ s₂, f x" title="Finset.sum_union.{u_1, u_4} {ι : Type u_1} {M : Type u_4} {s₁ s₂ : Finset ι} [AddCommMonoid M] {f : ι → M}
  [DecidableEq ι] (h : Disjoint s₁ s₂) : ∑ x ∈ s₁ ∪ s₂, f x = ∑ x ∈ s₁, f x + ∑ x ∈ s₂, f x">Finset.sum_union</span> <span class="lean-var" data-type="Disjoint m.factorization.support n.factorization.support" title="Disjoint m.factorization.support n.factorization.support">hdisj</span><span class="lean-bracket-1">]</span>
  <span class="lean-keyword" data-docs="Apply congruence (recursively) to goals of the form `⊢ f as = f bs` and `⊢ f as ≍ f bs`.
The optional parameter is the depth of the recursive applications.
This is useful when `congr` is too aggressive in breaking down the goal.
For example, given `⊢ f (g (x + y)) = f (g (y + x))`,
`congr` produces the goals `⊢ x = y` and `⊢ y = x`,
while `congr 2` produces the intended `⊢ x + y = y + x`.
" title="Apply congruence (recursively) to goals of the form `⊢ f as = f bs` and `⊢ f as ≍ f bs`.">congr</span> <span class="lean-number">1</span>
  <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
" title="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.">apply</span> <span class="lean-const" data-name="Finset.sum_congr" data-signature="Finset.sum_congr.{u_1, u_4} {ι : Type u_1} {M : Type u_4} {s₁ s₂ : Finset ι} [AddCommMonoid M] {f g : ι → M}
  (h : s₁ = s₂) : (∀ x ∈ s₂, f x = g x) → s₁.sum f = s₂.sum g" title="Finset.sum_congr.{u_1, u_4} {ι : Type u_1} {M : Type u_4} {s₁ s₂ : Finset ι} [AddCommMonoid M] {f g : ι → M}
  (h : s₁ = s₂) : (∀ x ∈ s₂, f x = g x) → s₁.sum f = s₂.sum g">Finset.sum_congr</span> <span class="lean-const" data-name="rfl" data-signature="rfl.{u} {α : Sort u} {a : α} : a = a" data-docs="`rfl : a = a` is the unique constructor of the equality type. This is the
same as `Eq.refl` except that it takes `a` implicitly instead of explicitly.

This is a more powerful theorem than it may appear at first, because although
the statement of the theorem is `a = a`, Lean will allow anything that is
definitionally equal to that type. So, for instance, `2 + 2 = 4` is proven in
Lean by `rfl`, because both sides are the same up to definitional equality.
" title="rfl.{u} {α : Sort u} {a : α} : a = a
`rfl : a = a` is the unique constructor of the equality type. This is the...">rfl</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
" title="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.">intro</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> <span class="lean-var" data-type="p ∈ m.factorization.support" title="p ∈ m.factorization.support">hp</span>
    <span class="lean-keyword" data-docs="Apply congruence (recursively) to goals of the form `⊢ f as = f bs` and `⊢ f as ≍ f bs`.
The optional parameter is the depth of the recursive applications.
This is useful when `congr` is too aggressive in breaking down the goal.
For example, given `⊢ f (g (x + y)) = f (g (y + x))`,
`congr` produces the goals `⊢ x = y` and `⊢ y = x`,
while `congr 2` produces the intended `⊢ x + y = y + x`.
" title="Apply congruence (recursively) to goals of the form `⊢ f as = f bs` and `⊢ f as ≍ f bs`.">congr</span> <span class="lean-number">1</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Finsupp.add_apply" data-signature="Finsupp.add_apply.{u_1, u_3} {ι : Type u_1} {M : Type u_3} [AddZeroClass M] (g₁ g₂ : ι →₀ M) (a : ι) :
  (g₁ + g₂) a = g₁ a + g₂ a" title="Finsupp.add_apply.{u_1, u_3} {ι : Type u_1} {M : Type u_3} [AddZeroClass M] (g₁ g₂ : ι →₀ M) (a : ι) :
  (g₁ + g₂) a = g₁ a + g₂ a">Finsupp.add_apply</span>, <span class="lean-const" data-name="_private.0.Crystallographic.factorization_eq_zero_of_disjoint_support" data-signature="Crystallographic.factorization_eq_zero_of_disjoint_support {m n p : ℕ}
  (hdisj : Disjoint m.factorization.support n.factorization.support) (hp : p ∈ m.factorization.support) :
  n.factorization p = 0" title="Crystallographic.factorization_eq_zero_of_disjoint_support {m n p : ℕ}
  (hdisj : Disjoint m.factorization.support n.factorization.support) (hp : p ∈ m.factorization.support) :
  n.factorization p = 0">factorization_eq_zero_of_disjoint_support</span> <span class="lean-var" data-type="Disjoint m.factorization.support n.factorization.support" title="Disjoint m.factorization.support n.factorization.support">hdisj</span> <span class="lean-var" data-type="p ∈ m.factorization.support" title="p ∈ m.factorization.support">hp</span>, <span class="lean-const" data-name="add_zero" data-signature="add_zero.{u} {M : Type u} [AddZeroClass M] (a : M) : a + 0 = a" title="add_zero.{u} {M : Type u} [AddZeroClass M] (a : M) : a + 0 = a">add_zero</span><span class="lean-bracket-1">]</span>
  <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
" title="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.">apply</span> <span class="lean-const" data-name="Finset.sum_congr" data-signature="Finset.sum_congr.{u_1, u_4} {ι : Type u_1} {M : Type u_4} {s₁ s₂ : Finset ι} [AddCommMonoid M] {f g : ι → M}
  (h : s₁ = s₂) : (∀ x ∈ s₂, f x = g x) → s₁.sum f = s₂.sum g" title="Finset.sum_congr.{u_1, u_4} {ι : Type u_1} {M : Type u_4} {s₁ s₂ : Finset ι} [AddCommMonoid M] {f g : ι → M}
  (h : s₁ = s₂) : (∀ x ∈ s₂, f x = g x) → s₁.sum f = s₂.sum g">Finset.sum_congr</span> <span class="lean-const" data-name="rfl" data-signature="rfl.{u} {α : Sort u} {a : α} : a = a" data-docs="`rfl : a = a` is the unique constructor of the equality type. This is the
same as `Eq.refl` except that it takes `a` implicitly instead of explicitly.

This is a more powerful theorem than it may appear at first, because although
the statement of the theorem is `a = a`, Lean will allow anything that is
definitionally equal to that type. So, for instance, `2 + 2 = 4` is proven in
Lean by `rfl`, because both sides are the same up to definitional equality.
" title="rfl.{u} {α : Sort u} {a : α} : a = a
`rfl : a = a` is the unique constructor of the equality type. This is the...">rfl</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
" title="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.">intro</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> <span class="lean-var" data-type="p ∈ n.factorization.support" title="p ∈ n.factorization.support">hp</span>
    <span class="lean-keyword" data-docs="Apply congruence (recursively) to goals of the form `⊢ f as = f bs` and `⊢ f as ≍ f bs`.
The optional parameter is the depth of the recursive applications.
This is useful when `congr` is too aggressive in breaking down the goal.
For example, given `⊢ f (g (x + y)) = f (g (y + x))`,
`congr` produces the goals `⊢ x = y` and `⊢ y = x`,
while `congr 2` produces the intended `⊢ x + y = y + x`.
" title="Apply congruence (recursively) to goals of the form `⊢ f as = f bs` and `⊢ f as ≍ f bs`.">congr</span> <span class="lean-number">1</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Finsupp.add_apply" data-signature="Finsupp.add_apply.{u_1, u_3} {ι : Type u_1} {M : Type u_3} [AddZeroClass M] (g₁ g₂ : ι →₀ M) (a : ι) :
  (g₁ + g₂) a = g₁ a + g₂ a" title="Finsupp.add_apply.{u_1, u_3} {ι : Type u_1} {M : Type u_3} [AddZeroClass M] (g₁ g₂ : ι →₀ M) (a : ι) :
  (g₁ + g₂) a = g₁ a + g₂ a">Finsupp.add_apply</span>, <span class="lean-const" data-name="_private.0.Crystallographic.factorization_eq_zero_of_disjoint_support" data-signature="Crystallographic.factorization_eq_zero_of_disjoint_support {m n p : ℕ}
  (hdisj : Disjoint m.factorization.support n.factorization.support) (hp : p ∈ m.factorization.support) :
  n.factorization p = 0" title="Crystallographic.factorization_eq_zero_of_disjoint_support {m n p : ℕ}
  (hdisj : Disjoint m.factorization.support n.factorization.support) (hp : p ∈ m.factorization.support) :
  n.factorization p = 0">factorization_eq_zero_of_disjoint_support</span> <span class="lean-var" data-type="Disjoint m.factorization.support n.factorization.support" title="Disjoint m.factorization.support n.factorization.support">hdisj</span>.<span class="lean-const" data-name="Disjoint.symm" data-signature="Disjoint.symm.{u_1} {α : Type u_1} [PartialOrder α] [OrderBot α] ⦃a b : α⦄ : Disjoint a b → Disjoint b a" title="Disjoint.symm.{u_1} {α : Type u_1} [PartialOrder α] [OrderBot α] ⦃a b : α⦄ : Disjoint a b → Disjoint b a">symm</span> <span class="lean-var" data-type="p ∈ n.factorization.support" title="p ∈ n.factorization.support">hp</span>, <span class="lean-const" data-name="zero_add" data-signature="zero_add.{u} {M : Type u} [AddZeroClass M] (a : M) : 0 + a = a" title="zero_add.{u} {M : Type u} [AddZeroClass M] (a : M) : 0 + a = a">zero_add</span><span class="lean-bracket-1">]</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Basic.lean#L177-L208" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:psi-coprime-add');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:psi-ge-psiPrimePow">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.4</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:psi-ge-psiPrimePow">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000017"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psi_ge_psiPrimePow_of_mem_support" class="lean_decl">Crystallographic.psi_ge_psiPrimePow_of_mem_support</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        \(\psi (m) \geq \psi _{\mathrm{pp}}(p, v_p(m))\) for each prime \(p \mid m\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000017">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>The sum \(\psi (m)\) includes the term \(\psi _{\mathrm{pp}}(p, v_p(m))\), and all terms are non-negative. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> <span class="lean-const lean-def" data-name="Crystallographic.psi_ge_psiPrimePow_of_mem_support" data-signature="Crystallographic.psi_ge_psiPrimePow_of_mem_support {m p : ℕ} (hp : p ∈ m.factorization.support) :
  psiPrimePow p (m.factorization p) ≤ psi m" data-docs="`psi m` is at least the contribution from any single prime power factor.

If p^k divides m exactly, then `psi m ≥ psiPrimePow p k`. " title="Crystallographic.psi_ge_psiPrimePow_of_mem_support {m p : ℕ} (hp : p ∈ m.factorization.support) :
  psiPrimePow p (m.factorization p) ≤ psi m
`psi m` is at least the contribution from any single prime power factor....">psi_ge_psiPrimePow_of_mem_support</span> <span class="lean-bracket-1">{</span><span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> : ℕ<span class="lean-bracket-1">}</span>
    <span class="lean-bracket-1">(</span><span class="lean-var" data-type="p ∈ m.factorization.support" title="p ∈ m.factorization.support">hp</span> : <span class="lean-var" data-type="ℕ" title="ℕ">p</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span>.<span class="lean-const" data-name="Finsupp.support" data-signature="Finsupp.support.{u_9, u_10} {α : Type u_9} {M : Type u_10} [Zero M] (self : α →₀ M) : Finset α" data-docs="The support of a finitely supported function (aka `Finsupp`). " title="Finsupp.support.{u_9, u_10} {α : Type u_9} {M : Type u_10} [Zero M] (self : α →₀ M) : Finset α
The support of a finitely supported function (aka `Finsupp`). ">support</span><span class="lean-bracket-1">)</span> :
    <span class="lean-const" data-name="Crystallographic.psiPrimePow" data-signature="Crystallographic.psiPrimePow (p k : ℕ) : ℕ" data-docs="Helper function that computes the contribution of a single prime power p^k to psi.
Returns 0 if k = 0, returns 0 if p = 2 and k = 1, otherwise returns phi(p^k). " title="Crystallographic.psiPrimePow (p k : ℕ) : ℕ
Helper function that computes the contribution of a single prime power p^k to psi....">psiPrimePow</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span><span class="lean-bracket-1">)</span> <span class="lean-operator">≤</span> <span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span></code><code class="lean-proof-body">
  <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span>, <span class="lean-const" data-name="Finsupp.sum" data-signature="Finsupp.sum.{u_1, u_8, u_10} {α : Type u_1} {M : Type u_8} {N : Type u_10} [Zero M] [AddCommMonoid N] (f : α →₀ M)
  (g : α → M → N) : N" data-docs="`sum f g` is the sum of `g a (f a)` over the support of `f`. " title="Finsupp.sum.{u_1, u_8, u_10} {α : Type u_1} {M : Type u_8} {N : Type u_10} [Zero M] [AddCommMonoid N] (f : α →₀ M)
  (g : α → M → N) : N
`sum f g` is the sum of `g a (f a)` over the support of `f`. ">Finsupp.sum</span><span class="lean-bracket-1">]</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="∀ i ∈ m.factorization.support, 0 ≤ psiPrimePow i (m.factorization i)" title="∀ i ∈ m.factorization.support, 0 ≤ psiPrimePow i (m.factorization i)">hnonneg</span> : <span class="lean-operator">∀</span> <span class="lean-var" data-type="ℕ" title="ℕ">i</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span>.<span class="lean-const" data-name="Finsupp.support" data-signature="Finsupp.support.{u_9, u_10} {α : Type u_9} {M : Type u_10} [Zero M] (self : α →₀ M) : Finset α" data-docs="The support of a finitely supported function (aka `Finsupp`). " title="Finsupp.support.{u_9, u_10} {α : Type u_9} {M : Type u_10} [Zero M] (self : α →₀ M) : Finset α
The support of a finitely supported function (aka `Finsupp`). ">support</span>, <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> <span class="lean-operator">≤</span> <span class="lean-const" data-name="Crystallographic.psiPrimePow" data-signature="Crystallographic.psiPrimePow (p k : ℕ) : ℕ" data-docs="Helper function that computes the contribution of a single prime power p^k to psi.
Returns 0 if k = 0, returns 0 if p = 2 and k = 1, otherwise returns phi(p^k). " title="Crystallographic.psiPrimePow (p k : ℕ) : ℕ
Helper function that computes the contribution of a single prime power p^k to psi....">psiPrimePow</span> <span class="lean-var" data-type="ℕ" title="ℕ">i</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">i</span><span class="lean-bracket-1">)</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
" title="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.">intro</span> <span class="lean-var" data-type="ℕ" title="ℕ">i</span> _
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Crystallographic.psiPrimePow" data-signature="Crystallographic.psiPrimePow (p k : ℕ) : ℕ" data-docs="Helper function that computes the contribution of a single prime power p^k to psi.
Returns 0 if k = 0, returns 0 if p = 2 and k = 1, otherwise returns phi(p^k). " title="Crystallographic.psiPrimePow (p k : ℕ) : ℕ
Helper function that computes the contribution of a single prime power p^k to psi....">psiPrimePow</span><span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="Splits all if-then-else-expressions into multiple goals.
Given a goal of the form `g (if p then x else y)`, `split_ifs` will produce
two goals: `p ⊢ g x` and `¬p ⊢ g y`.
If there are multiple ite-expressions, then `split_ifs` will split them all,
starting with a top-most one whose condition does not contain another
ite-expression.
`split_ifs at *` splits all ite-expressions in all hypotheses as well as the goal.
`split_ifs with h₁ h₂ h₃` overrides the default names for the hypotheses.
" title="Splits all if-then-else-expressions into multiple goals.">split_ifs</span> &lt;;&gt; <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span>
  <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-const" data-name="Finset.single_le_sum" data-signature="Finset.single_le_sum.{u_1, u_5} {ι : Type u_1} {N : Type u_5} [AddCommMonoid N] [PartialOrder N] {f : ι → N}
  {s : Finset ι} [AddLeftMono N] (hf : ∀ i ∈ s, 0 ≤ f i) {a : ι} (h : a ∈ s) : f a ≤ ∑ x ∈ s, f x" title="Finset.single_le_sum.{u_1, u_5} {ι : Type u_1} {N : Type u_5} [AddCommMonoid N] [PartialOrder N] {f : ι → N}
  {s : Finset ι} [AddLeftMono N] (hf : ∀ i ∈ s, 0 ≤ f i) {a : ι} (h : a ∈ s) : f a ≤ ∑ x ∈ s, f x">Finset.single_le_sum</span> <span class="lean-var" data-type="∀ i ∈ m.factorization.support, 0 ≤ psiPrimePow i (m.factorization i)" title="∀ i ∈ m.factorization.support, 0 ≤ psiPrimePow i (m.factorization i)">hnonneg</span> <span class="lean-var" data-type="p ∈ m.factorization.support" title="p ∈ m.factorization.support">hp</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Basic.lean#L230-L244" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:psi-ge-psiPrimePow');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:two-le-totient-prime-pow">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.5</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:two-le-totient-prime-pow">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000018"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.two_le_totient_primePow" class="lean_decl">Crystallographic.two_le_totient_primePow</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       For any prime power \(p^k {\gt} 2\), we have \(2 \leq \varphi (p^k)\). </p>
<p>Specifically, \(\varphi (p^k) = p^{k-1}(p-1) \geq 2\) unless \((p, k) = (2, 1)\), in which case \(\varphi (2) = 1\). This bound is essential for showing that sums of totients are bounded by products when factors are coprime.  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000018">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>By cases on \(p = 2\): if \(p \neq 2\), then \(p \geq 3\) so \(\varphi (p^k) = p^{k-1}(p-1) \geq 1 \cdot 2 = 2\). If \(p = 2\) and \(k \geq 2\), then \(\varphi (2^k) = 2^{k-1} \geq 2\). The case \((2, 1)\) is excluded by hypothesis. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> <span class="lean-const lean-def" data-name="Crystallographic.two_le_totient_primePow" data-signature="Crystallographic.two_le_totient_primePow {p k : ℕ} (hp : Nat.Prime p) (hk : 0 &lt; k) (h : ¬(p = 2 ∧ k = 1)) :
  2 ≤ (p ^ k).totient" title="Crystallographic.two_le_totient_primePow {p k : ℕ} (hp : Nat.Prime p) (hk : 0 &lt; k) (h : ¬(p = 2 ∧ k = 1)) :
  2 ≤ (p ^ k).totient">two_le_totient_primePow</span> <span class="lean-bracket-1">{</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> <span class="lean-var" data-type="ℕ" title="ℕ">k</span> : ℕ<span class="lean-bracket-1">}</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hp</span> : <span class="lean-var" data-type="ℕ" title="ℕ">p</span>.<span class="lean-const" data-name="Nat.Prime" data-signature="Nat.Prime (p : ℕ) : Prop" data-docs="`Nat.Prime p` means that `p` is a prime number, that is, a natural number
at least 2 whose only divisors are `p` and `1`.
The theorem `Nat.prime_def` witnesses this description of a prime number. " title="Nat.Prime (p : ℕ) : Prop
`Nat.Prime p` means that `p` is a prime number, that is, a natural number...">Prime</span><span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="0 &lt; k" title="0 &lt; k">hk</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">k</span><span class="lean-bracket-1">)</span>
    <span class="lean-bracket-1">(</span><span class="lean-var" data-type="¬(p = 2 ∧ k = 1)" title="¬(p = 2 ∧ k = 1)">h</span> : <span class="lean-operator">¬</span><span class="lean-bracket-2">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> <span class="lean-operator">∧</span> <span class="lean-var" data-type="ℕ" title="ℕ">k</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">1</span><span class="lean-bracket-2">)</span><span class="lean-bracket-1">)</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> <span class="lean-operator">≤</span> <span class="lean-const" data-name="Nat.totient" data-signature="Nat.totient (n : ℕ) : ℕ" data-docs="Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are
coprime with `n`. " title="Nat.totient (n : ℕ) : ℕ
Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are...">Nat.totient</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">k</span><span class="lean-bracket-1">)</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span></code><code class="lean-proof-body">
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Nat.totient_prime_pow" data-signature="Nat.totient_prime_pow {p : ℕ} (hp : Nat.Prime p) {n : ℕ} (hn : 0 &lt; n) : (p ^ n).totient = p ^ (n - 1) * (p - 1)" data-docs="When `p` is prime, then the totient of `p ^ n` is `p ^ (n - 1) * (p - 1)` " title="Nat.totient_prime_pow {p : ℕ} (hp : Nat.Prime p) {n : ℕ} (hn : 0 &lt; n) : (p ^ n).totient = p ^ (n - 1) * (p - 1)
When `p` is prime, then the totient of `p ^ n` is `p ^ (n - 1) * (p - 1)` ">Nat.totient_prime_pow</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hp</span> <span class="lean-var" data-type="0 &lt; k" title="0 &lt; k">hk</span><span class="lean-bracket-1">]</span>
  <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
" title="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `">by_cases</span> <span class="lean-var" data-type="p = 2" title="p = 2">hp2</span> : <span class="lean-var" data-type="ℕ" title="ℕ">p</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">2</span>
  <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="This is a &quot;finishing&quot; tactic modification of `simp`. It has two forms.

* `simpa [rules, ⋯] using e` will simplify the goal and the type of
`e` using `rules`, then try to close the goal using `e`.

Simplifying the type of `e` makes it more likely to match the goal
(which has also been simplified). This construction also tends to be
more robust under changes to the simp lemma set.

* `simpa [rules, ⋯]` will simplify the goal and the type of a
hypothesis `this` if present in the context, then try to close the goal using
the `assumption` tactic.
" title="This is a &quot;finishing&quot; tactic modification of `simp`. It has two forms.">simpa</span> <span class="lean-bracket-1">[</span><span class="lean-var" data-type="p = 2" title="p = 2">hp2</span><span class="lean-bracket-1">]</span> <span class="lean-keyword">using</span> <span class="lean-const" data-name="Nat.pow_le_pow_right" data-signature="Nat.pow_le_pow_right {n : ℕ} (hx : n &gt; 0) {i j : ℕ} : i ≤ j → n ^ i ≤ n ^ j" title="Nat.pow_le_pow_right {n : ℕ} (hx : n &gt; 0) {i j : ℕ} : i ≤ j → n ^ i ≤ n ^ j">Nat.pow_le_pow_right</span> <span class="lean-bracket-1">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span><span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span> : <span class="lean-number">1</span> <span class="lean-operator">≤</span> k - <span class="lean-number">1</span><span class="lean-bracket-1">)</span>
  <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="3 ≤ p" title="3 ≤ p">hp3</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">3</span> <span class="lean-operator">≤</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> := <span class="lean-const" data-name="Nat.lt_of_le_of_ne" data-signature="Nat.lt_of_le_of_ne {n m : ℕ} (h₁ : n ≤ m) (h₂ : ¬n = m) : n &lt; m" title="Nat.lt_of_le_of_ne {n m : ℕ} (h₁ : n ≤ m) (h₂ : ¬n = m) : n &lt; m">Nat.lt_of_le_of_ne</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hp</span>.<span class="lean-const" data-name="Nat.Prime.two_le" data-signature="Nat.Prime.two_le {p : ℕ} : Nat.Prime p → 2 ≤ p" title="Nat.Prime.two_le {p : ℕ} : Nat.Prime p → 2 ≤ p">two_le</span> <span class="lean-bracket-1">(</span><span class="lean-const" data-name="Ne.symm" data-signature="Ne.symm.{u} {α : Sort u} {a b : α} (h : a ≠ b) : b ≠ a" title="Ne.symm.{u} {α : Sort u} {a b : α} (h : a ≠ b) : b ≠ a">Ne.symm</span> <span class="lean-var" data-type="¬p = 2" title="¬p = 2">hp2</span><span class="lean-bracket-1">)</span>
    <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
" title="Step-wise reasoning over transitive relations.">calc</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">k</span> - <span class="lean-expr" data-type="ℕ" title="ℕ">1</span><span class="lean-bracket-1">)</span> * <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> - <span class="lean-expr" data-type="ℕ" title="ℕ">1</span><span class="lean-bracket-1">)</span> <span class="lean-operator">≥</span> <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> * <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> - <span class="lean-expr" data-type="ℕ" title="ℕ">1</span><span class="lean-bracket-1">)</span> := <span class="lean-const" data-name="Nat.mul_le_mul_right" data-signature="Nat.mul_le_mul_right {n m : ℕ} (k : ℕ) (h : n ≤ m) : n * k ≤ m * k" title="Nat.mul_le_mul_right {n m : ℕ} (k : ℕ) (h : n ≤ m) : n * k ≤ m * k">Nat.mul_le_mul_right</span> _ <span class="lean-bracket-1">(</span><span class="lean-const" data-name="Nat.one_le_pow" data-signature="Nat.one_le_pow (n m : ℕ) (h : 0 &lt; m) : 1 ≤ m ^ n" title="Nat.one_le_pow (n m : ℕ) (h : 0 &lt; m) : 1 ≤ m ^ n">Nat.one_le_pow</span> _ _ <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hp</span>.<span class="lean-const" data-name="Nat.Prime.pos" data-signature="Nat.Prime.pos {p : ℕ} (pp : Nat.Prime p) : 0 &lt; p" title="Nat.Prime.pos {p : ℕ} (pp : Nat.Prime p) : 0 &lt; p">pos</span><span class="lean-bracket-1">)</span>
      _ <span class="lean-operator">≥</span> <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L39-L56" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:two-le-totient-prime-pow');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:factorization-split-lt">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.6</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:factorization-split-lt">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000019"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.factorization_split_lt" class="lean_decl">Crystallographic.factorization_split_lt</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       A composite number \(m {\gt} 2\) that is not a prime power can be written as \(m = p^e \cdot m'\) where \(p\) is prime, \(e {\gt} 0\), \(\gcd (p^e, m') = 1\), and both \(p^e {\lt} m\) and \(1 {\lt} m' {\lt} m\). </p>
<p>This decomposition is essential for strong induction proofs on composite numbers: it provides strictly smaller coprime factors to which the inductive hypothesis applies.  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000019">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>Take \(p = \mathrm{minFac}(m)\) and \(e = \nu _p(m)\), the \(p\)-adic valuation. Then \(m' = m / p^e\) is coprime to \(p^e\) (disjoint prime support). Since \(m\) is not a prime power, \(m' \neq 1\). The bounds \(p^e {\lt} m\) and \(m' {\lt} m\) follow from \(m' {\gt} 1\) and \(p^e \geq 2\) respectively. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> <span class="lean-const lean-def" data-name="Crystallographic.factorization_split_lt" data-signature="Crystallographic.factorization_split_lt {m : ℕ} (hm : 2 &lt; m) (h_not_pp : ¬IsPrimePow m) :
  ∃ p e m&#x27;, Nat.Prime p ∧ 0 &lt; e ∧ p ^ e * m&#x27; = m ∧ (p ^ e).Coprime m&#x27; ∧ 1 &lt; m&#x27; ∧ m&#x27; &lt; m ∧ p ^ e &lt; m" title="Crystallographic.factorization_split_lt {m : ℕ} (hm : 2 &lt; m) (h_not_pp : ¬IsPrimePow m) :
  ∃ p e m&#x27;, Nat.Prime p ∧ 0 &lt; e ∧ p ^ e * m&#x27; = m ∧ (p ^ e).Coprime m&#x27; ∧ 1 &lt; m&#x27; ∧ m&#x27; &lt; m ∧ p ^ e &lt; m">factorization_split_lt</span> <span class="lean-bracket-1">{</span><span class="lean-var" data-type="ℕ" title="ℕ">m</span> : ℕ<span class="lean-bracket-1">}</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="2 &lt; m" title="2 &lt; m">hm</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span><span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="¬IsPrimePow m" title="¬IsPrimePow m">h_not_pp</span> : <span class="lean-operator">¬</span><span class="lean-const" data-name="IsPrimePow" data-signature="IsPrimePow.{u_1} {R : Type u_1} [CommMonoidWithZero R] (n : R) : Prop" data-docs="`n` is a prime power if there is a prime `p` and a positive natural `k` such that `n` can be
written as `p^k`. " title="IsPrimePow.{u_1} {R : Type u_1} [CommMonoidWithZero R] (n : R) : Prop
`n` is a prime power if there is a prime `p` and a positive natural `k` such that `n` can be...">IsPrimePow</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span><span class="lean-bracket-1">)</span> :
    <span class="lean-operator">∃</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> <span class="lean-var" data-type="ℕ" title="ℕ">e</span> <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> : ℕ<span class="lean-bracket-1">)</span>, <span class="lean-var" data-type="ℕ" title="ℕ">p</span>.<span class="lean-const" data-name="Nat.Prime" data-signature="Nat.Prime (p : ℕ) : Prop" data-docs="`Nat.Prime p` means that `p` is a prime number, that is, a natural number
at least 2 whose only divisors are `p` and `1`.
The theorem `Nat.prime_def` witnesses this description of a prime number. " title="Nat.Prime (p : ℕ) : Prop
`Nat.Prime p` means that `p` is a prime number, that is, a natural number...">Prime</span> <span class="lean-operator">∧</span> <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">e</span> <span class="lean-operator">∧</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span> * <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> = <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-operator">∧</span>
    <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span><span class="lean-bracket-1">)</span>.<span class="lean-const" data-name="Nat.Coprime" data-signature="Nat.Coprime (m n : ℕ) : Prop" data-docs="`m` and `n` are coprime, or relatively prime, if their `gcd` is 1. " title="Nat.Coprime (m n : ℕ) : Prop
`m` and `n` are coprime, or relatively prime, if their `gcd` is 1. ">Coprime</span> <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> <span class="lean-operator">∧</span> <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> <span class="lean-operator">∧</span> <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-operator">∧</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span></code><code class="lean-proof-body">
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="m ≠ 0" title="m ≠ 0">hm_ne_zero</span> : <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-operator">≠</span> <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="m ≠ 1" title="m ≠ 1">hm_ne_one</span> : <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-operator">≠</span> <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="0 &lt; m" title="0 &lt; m">hm_pos</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="Nat.Prime m.minFac" title="Nat.Prime m.minFac">hminFac_prime</span> : <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.minFac" data-signature="Nat.minFac (n : ℕ) : ℕ" data-docs="Returns the smallest prime factor of `n ≠ 1`. " title="Nat.minFac (n : ℕ) : ℕ
Returns the smallest prime factor of `n ≠ 1`. ">minFac</span>.<span class="lean-const" data-name="Nat.Prime" data-signature="Nat.Prime (p : ℕ) : Prop" data-docs="`Nat.Prime p` means that `p` is a prime number, that is, a natural number
at least 2 whose only divisors are `p` and `1`.
The theorem `Nat.prime_def` witnesses this description of a prime number. " title="Nat.Prime (p : ℕ) : Prop
`Nat.Prime p` means that `p` is a prime number, that is, a natural number...">Prime</span> := <span class="lean-const" data-name="Nat.minFac_prime" data-signature="Nat.minFac_prime {n : ℕ} (n1 : n ≠ 1) : Nat.Prime n.minFac" title="Nat.minFac_prime {n : ℕ} (n1 : n ≠ 1) : Nat.Prime n.minFac">Nat.minFac_prime</span> <span class="lean-var" data-type="m ≠ 1" title="m ≠ 1">hm_ne_one</span>
  <span class="lean-keyword" data-docs="`set a := t with h` is a variant of `let a := t`. It adds the hypothesis `h : a = t` to
the local context and replaces `t` with `a` everywhere it can.

`set a := t with ← h` will add `h : t = a` instead.

`set! a := t with h` does not do any replacing.

```lean
example (x : Nat) (h : x + x - x = 3) : x + x - x = 3 := by
  set y := x with ← h2
  sorry
/-
x : Nat
y : Nat := x
h : y + y - y = 3
h2 : x = y
⊢ y + y - y = 3
-/
```
" title="`set a := t with h` is a variant of `let a := t`. It adds the hypothesis `h : a = t` to">set</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> := <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.minFac" data-signature="Nat.minFac (n : ℕ) : ℕ" data-docs="Returns the smallest prime factor of `n ≠ 1`. " title="Nat.minFac (n : ℕ) : ℕ
Returns the smallest prime factor of `n ≠ 1`. ">minFac</span>
  <span class="lean-keyword" data-docs="`set a := t with h` is a variant of `let a := t`. It adds the hypothesis `h : a = t` to
the local context and replaces `t` with `a` everywhere it can.

`set a := t with ← h` will add `h : t = a` instead.

`set! a := t with h` does not do any replacing.

```lean
example (x : Nat) (h : x + x - x = 3) : x + x - x = 3 := by
  set y := x with ← h2
  sorry
/-
x : Nat
y : Nat := x
h : y + y - y = 3
h2 : x = y
⊢ y + y - y = 3
-/
```
" title="`set a := t with h` is a variant of `let a := t`. It adds the hypothesis `h : a = t` to">set</span> <span class="lean-var" data-type="ℕ" title="ℕ">e</span> := <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="0 &lt; e" title="0 &lt; e">he_pos</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">e</span> :=
    <span class="lean-const" data-name="Nat.Prime.factorization_pos_of_dvd" data-signature="Nat.Prime.factorization_pos_of_dvd {n p : ℕ} (hp : Nat.Prime p) (hn : n ≠ 0) (h : p ∣ n) : 0 &lt; n.factorization p" title="Nat.Prime.factorization_pos_of_dvd {n p : ℕ} (hp : Nat.Prime p) (hn : n ≠ 0) (h : p ∣ n) : 0 &lt; n.factorization p">Nat.Prime.factorization_pos_of_dvd</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hminFac_prime</span> <span class="lean-var" data-type="m ≠ 0" title="m ≠ 0">hm_ne_zero</span> <span class="lean-bracket-1">(</span><span class="lean-const" data-name="Nat.minFac_dvd" data-signature="Nat.minFac_dvd (n : ℕ) : n.minFac ∣ n" title="Nat.minFac_dvd (n : ℕ) : n.minFac ∣ n">Nat.minFac_dvd</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span><span class="lean-bracket-1">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="p ^ e ∣ m" title="p ^ e ∣ m">hdvd</span> : <span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span> ∣ <span class="lean-var" data-type="ℕ" title="ℕ">m</span> := <span class="lean-const" data-name="Nat.ordProj_dvd" data-signature="Nat.ordProj_dvd (n p : ℕ) : p ^ n.factorization p ∣ n" title="Nat.ordProj_dvd (n p : ℕ) : p ^ n.factorization p ∣ n">Nat.ordProj_dvd</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span>
  <span class="lean-keyword" data-docs="`set a := t with h` is a variant of `let a := t`. It adds the hypothesis `h : a = t` to
the local context and replaces `t` with `a` everywhere it can.

`set a := t with ← h` will add `h : t = a` instead.

`set! a := t with h` does not do any replacing.

```lean
example (x : Nat) (h : x + x - x = 3) : x + x - x = 3 := by
  set y := x with ← h2
  sorry
/-
x : Nat
y : Nat := x
h : y + y - y = 3
h2 : x = y
⊢ y + y - y = 3
-/
```
" title="`set a := t with h` is a variant of `let a := t`. It adds the hypothesis `h : a = t` to">set</span> <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> := <span class="lean-var" data-type="ℕ" title="ℕ">m</span> / <span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="0 &lt; m&#x27;" title="0 &lt; m&#x27;">hm&#x27;_pos</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> := <span class="lean-const" data-name="Nat.div_pos" data-signature="Nat.div_pos {b a : ℕ} (hba : b ≤ a) (hb : 0 &lt; b) : 0 &lt; a / b" title="Nat.div_pos {b a : ℕ} (hba : b ≤ a) (hb : 0 &lt; b) : 0 &lt; a / b">Nat.div_pos</span> <span class="lean-bracket-1">(</span><span class="lean-const" data-name="Nat.le_of_dvd" data-signature="Nat.le_of_dvd {m n : ℕ} (h : 0 &lt; n) : m ∣ n → m ≤ n" title="Nat.le_of_dvd {m n : ℕ} (h : 0 &lt; n) : m ∣ n → m ≤ n">Nat.le_of_dvd</span> <span class="lean-var" data-type="0 &lt; m" title="0 &lt; m">hm_pos</span> <span class="lean-var" data-type="p ^ e ∣ m" title="p ^ e ∣ m">hdvd</span><span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-const" data-name="Nat.pow_pos" data-signature="Nat.pow_pos {a n : ℕ} (h : 0 &lt; a) : 0 &lt; a ^ n" title="Nat.pow_pos {a n : ℕ} (h : 0 &lt; a) : 0 &lt; a ^ n">Nat.pow_pos</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hminFac_prime</span>.<span class="lean-const" data-name="Nat.Prime.pos" data-signature="Nat.Prime.pos {p : ℕ} (pp : Nat.Prime p) : 0 &lt; p" title="Nat.Prime.pos {p : ℕ} (pp : Nat.Prime p) : 0 &lt; p">pos</span><span class="lean-bracket-1">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="m = p ^ e * m&#x27;" title="m = p ^ e * m&#x27;">hm_eq</span> : <span class="lean-var" data-type="ℕ" title="ℕ">m</span> = <span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span> * <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> := <span class="lean-bracket-1">(</span><span class="lean-const" data-name="Nat.mul_div_cancel&#x27;" data-signature="Nat.mul_div_cancel&#x27; {n m : ℕ} (H : n ∣ m) : n * (m / n) = m" title="Nat.mul_div_cancel&#x27; {n m : ℕ} (H : n ∣ m) : n * (m / n) = m">Nat.mul_div_cancel&#x27;</span> <span class="lean-var" data-type="p ^ e ∣ m" title="p ^ e ∣ m">hdvd</span><span class="lean-bracket-1">)</span>.<span class="lean-const" data-name="Eq.symm" data-signature="Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a" data-docs="Equality is symmetric: if `a = b` then `b = a`.

Because this is in the `Eq` namespace, if you have a variable `h : a = b`,
`h.symm` can be used as shorthand for `Eq.symm h` as a proof of `b = a`.

For more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)
" title="Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a
Equality is symmetric: if `a = b` then `b = a`....">symm</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="(p ^ e).Coprime m&#x27;" title="(p ^ e).Coprime m&#x27;">hcop</span> : <span class="lean-const" data-name="Nat.Coprime" data-signature="Nat.Coprime (m n : ℕ) : Prop" data-docs="`m` and `n` are coprime, or relatively prime, if their `gcd` is 1. " title="Nat.Coprime (m n : ℕ) : Prop
`m` and `n` are coprime, or relatively prime, if their `gcd` is 1. ">Nat.Coprime</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span><span class="lean-bracket-1">)</span> <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> := <span class="lean-const" data-name="Nat.coprime_ordCompl" data-signature="Nat.coprime_ordCompl {n p : ℕ} (hp : Nat.Prime p) (hn : n ≠ 0) : p.Coprime (n / p ^ n.factorization p)" title="Nat.coprime_ordCompl {n p : ℕ} (hp : Nat.Prime p) (hn : n ≠ 0) : p.Coprime (n / p ^ n.factorization p)">Nat.coprime_ordCompl</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hminFac_prime</span> <span class="lean-var" data-type="m ≠ 0" title="m ≠ 0">hm_ne_zero</span> |&gt;.<span class="lean-const" data-name="Nat.Coprime.pow_left" data-signature="Nat.Coprime.pow_left {m k : ℕ} (n : ℕ) (H1 : m.Coprime k) : (m ^ n).Coprime k" title="Nat.Coprime.pow_left {m k : ℕ} (n : ℕ) (H1 : m.Coprime k) : (m ^ n).Coprime k">pow_left</span> <span class="lean-var" data-type="ℕ" title="ℕ">e</span>
  <span class="lean-comment">-- m&#x27; <span class="lean-operator">≠</span> <span class="lean-number">1</span> because m is not a prime power</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="m&#x27; ≠ 1" title="m&#x27; ≠ 1">hm&#x27;_ne_one</span> : <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> <span class="lean-operator">≠</span> <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
" title="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.">intro</span> <span class="lean-var" data-type="m&#x27; = 1" title="m&#x27; = 1">hm&#x27;_one</span>
    <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
" title="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.">apply</span> <span class="lean-var" data-type="¬IsPrimePow m" title="¬IsPrimePow m">h_not_pp</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="isPrimePow_nat_iff" data-signature="isPrimePow_nat_iff (n : ℕ) : IsPrimePow n ↔ ∃ p k, Nat.Prime p ∧ 0 &lt; k ∧ p ^ k = n" title="isPrimePow_nat_iff (n : ℕ) : IsPrimePow n ↔ ∃ p k, Nat.Prime p ∧ 0 &lt; k ∧ p ^ k = n">isPrimePow_nat_iff</span><span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">⟨</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">,</span> <span class="lean-var" data-type="ℕ" title="ℕ">e</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">,</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hminFac_prime</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">,</span> <span class="lean-var" data-type="0 &lt; e" title="0 &lt; e">he_pos</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">,</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-var" data-type="m = p ^ e * m&#x27;" title="m = p ^ e * m&#x27;">hm_eq</span>, <span class="lean-var" data-type="m&#x27; = 1" title="m&#x27; = 1">hm&#x27;_one</span>, <span class="lean-const" data-name="mul_one" data-signature="mul_one.{u} {M : Type u} [MulOneClass M] (a : M) : a * 1 = a" title="mul_one.{u} {M : Type u} [MulOneClass M] (a : M) : a * 1 = a">mul_one</span><span class="lean-bracket-1">]</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">⟩</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="1 &lt; m&#x27;" title="1 &lt; m&#x27;">hm&#x27;_gt_one</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="m&#x27; &lt; m" title="m&#x27; &lt; m">hm&#x27;_lt</span> : <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="2 ≤ p ^ e" title="2 ≤ p ^ e">hpe_ge2</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> <span class="lean-operator">≤</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
      <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
" title="Step-wise reasoning over transitive relations.">calc</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span> <span class="lean-operator">≥</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> := <span class="lean-const" data-name="Nat.pow_le_pow_right" data-signature="Nat.pow_le_pow_right {n : ℕ} (hx : n &gt; 0) {i j : ℕ} : i ≤ j → n ^ i ≤ n ^ j" title="Nat.pow_le_pow_right {n : ℕ} (hx : n &gt; 0) {i j : ℕ} : i ≤ j → n ^ i ≤ n ^ j">Nat.pow_le_pow_right</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hminFac_prime</span>.<span class="lean-const" data-name="Nat.Prime.one_lt" data-signature="Nat.Prime.one_lt {p : ℕ} : Nat.Prime p → 1 &lt; p" title="Nat.Prime.one_lt {p : ℕ} : Nat.Prime p → 1 &lt; p">one_lt</span>.<span class="lean-const" data-name="LT.lt.le" data-signature="LT.lt.le.{u_1} {α : Type u_1} [Preorder α] {a b : α} (hab : a &lt; b) : a ≤ b" data-docs="**Alias** of `le_of_lt`." title="LT.lt.le.{u_1} {α : Type u_1} [Preorder α] {a b : α} (hab : a &lt; b) : a ≤ b
**Alias** of `le_of_lt`.">le</span> <span class="lean-var" data-type="0 &lt; e" title="0 &lt; e">he_pos</span>
        _ = <span class="lean-var" data-type="ℕ" title="ℕ">p</span> := <span class="lean-const" data-name="pow_one" data-signature="pow_one.{u_2} {M : Type u_2} [Monoid M] (a : M) : a ^ 1 = a" title="pow_one.{u_2} {M : Type u_2} [Monoid M] (a : M) : a ^ 1 = a">pow_one</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span>
        _ <span class="lean-operator">≥</span> <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> := <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hminFac_prime</span>.<span class="lean-const" data-name="Nat.Prime.two_le" data-signature="Nat.Prime.two_le {p : ℕ} : Nat.Prime p → 2 ≤ p" title="Nat.Prime.two_le {p : ℕ} : Nat.Prime p → 2 ≤ p">two_le</span>
    <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
" title="Step-wise reasoning over transitive relations.">calc</span> <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> * <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> := <span class="lean-bracket-1">(</span><span class="lean-const" data-name="one_mul" data-signature="one_mul.{u} {M : Type u} [MulOneClass M] (a : M) : 1 * a = a" title="one_mul.{u} {M : Type u} [MulOneClass M] (a : M) : 1 * a = a">one_mul</span> _<span class="lean-bracket-1">)</span>.<span class="lean-const" data-name="Eq.symm" data-signature="Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a" data-docs="Equality is symmetric: if `a = b` then `b = a`.

Because this is in the `Eq` namespace, if you have a variable `h : a = b`,
`h.symm` can be used as shorthand for `Eq.symm h` as a proof of `b = a`.

For more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)
" title="Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a
Equality is symmetric: if `a = b` then `b = a`....">symm</span>
      _ &lt; <span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span> * <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> := <span class="lean-const" data-name="Nat.mul_lt_mul_of_pos_right" data-signature="Nat.mul_lt_mul_of_pos_right {n m k : ℕ} (h : n &lt; m) (hk : k &gt; 0) : n * k &lt; m * k" title="Nat.mul_lt_mul_of_pos_right {n m k : ℕ} (h : n &lt; m) (hk : k &gt; 0) : n * k &lt; m * k">Nat.mul_lt_mul_of_pos_right</span>
          <span class="lean-bracket-1">(</span><span class="lean-const" data-name="Nat.one_lt_pow" data-signature="Nat.one_lt_pow {n a : ℕ} (hn : n ≠ 0) (ha : 1 &lt; a) : 1 &lt; a ^ n" title="Nat.one_lt_pow {n a : ℕ} (hn : n ≠ 0) (ha : 1 &lt; a) : 1 &lt; a ^ n">Nat.one_lt_pow</span> <span class="lean-var" data-type="0 &lt; e" title="0 &lt; e">he_pos</span>.<span class="lean-const" data-name="LT.lt.ne&#x27;" data-signature="LT.lt.ne&#x27;.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : b &lt; a) : a ≠ b" title="LT.lt.ne&#x27;.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : b &lt; a) : a ≠ b">ne&#x27;</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hminFac_prime</span>.<span class="lean-const" data-name="Nat.Prime.one_lt" data-signature="Nat.Prime.one_lt {p : ℕ} : Nat.Prime p → 1 &lt; p" title="Nat.Prime.one_lt {p : ℕ} : Nat.Prime p → 1 &lt; p">one_lt</span><span class="lean-bracket-1">)</span> <span class="lean-var" data-type="0 &lt; m&#x27;" title="0 &lt; m&#x27;">hm&#x27;_pos</span>
      _ = <span class="lean-var" data-type="ℕ" title="ℕ">m</span> := <span class="lean-var" data-type="m = p ^ e * m&#x27;" title="m = p ^ e * m&#x27;">hm_eq</span>.<span class="lean-const" data-name="Eq.symm" data-signature="Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a" data-docs="Equality is symmetric: if `a = b` then `b = a`.

Because this is in the `Eq` namespace, if you have a variable `h : a = b`,
`h.symm` can be used as shorthand for `Eq.symm h` as a proof of `b = a`.

For more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)
" title="Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a
Equality is symmetric: if `a = b` then `b = a`....">symm</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="p ^ e &lt; m" title="p ^ e &lt; m">hpe_lt</span> : <span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
" title="Step-wise reasoning over transitive relations.">calc</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span> = <span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span> * <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> := <span class="lean-bracket-1">(</span><span class="lean-const" data-name="mul_one" data-signature="mul_one.{u} {M : Type u} [MulOneClass M] (a : M) : a * 1 = a" title="mul_one.{u} {M : Type u} [MulOneClass M] (a : M) : a * 1 = a">mul_one</span> _<span class="lean-bracket-1">)</span>.<span class="lean-const" data-name="Eq.symm" data-signature="Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a" data-docs="Equality is symmetric: if `a = b` then `b = a`.

Because this is in the `Eq` namespace, if you have a variable `h : a = b`,
`h.symm` can be used as shorthand for `Eq.symm h` as a proof of `b = a`.

For more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)
" title="Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a
Equality is symmetric: if `a = b` then `b = a`....">symm</span>
      _ &lt; <span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span> * <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> := <span class="lean-const" data-name="Nat.mul_lt_mul_of_pos_left" data-signature="Nat.mul_lt_mul_of_pos_left {n m k : ℕ} (h : n &lt; m) (hk : k &gt; 0) : k * n &lt; k * m" title="Nat.mul_lt_mul_of_pos_left {n m k : ℕ} (h : n &lt; m) (hk : k &gt; 0) : k * n &lt; k * m">Nat.mul_lt_mul_of_pos_left</span> <span class="lean-var" data-type="1 &lt; m&#x27;" title="1 &lt; m&#x27;">hm&#x27;_gt_one</span> <span class="lean-bracket-1">(</span><span class="lean-const" data-name="Nat.pow_pos" data-signature="Nat.pow_pos {a n : ℕ} (h : 0 &lt; a) : 0 &lt; a ^ n" title="Nat.pow_pos {a n : ℕ} (h : 0 &lt; a) : 0 &lt; a ^ n">Nat.pow_pos</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hminFac_prime</span>.<span class="lean-const" data-name="Nat.Prime.pos" data-signature="Nat.Prime.pos {p : ℕ} (pp : Nat.Prime p) : 0 &lt; p" title="Nat.Prime.pos {p : ℕ} (pp : Nat.Prime p) : 0 &lt; p">pos</span><span class="lean-bracket-1">)</span>
      _ = <span class="lean-var" data-type="ℕ" title="ℕ">m</span> := <span class="lean-var" data-type="m = p ^ e * m&#x27;" title="m = p ^ e * m&#x27;">hm_eq</span>.<span class="lean-const" data-name="Eq.symm" data-signature="Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a" data-docs="Equality is symmetric: if `a = b` then `b = a`.

Because this is in the `Eq` namespace, if you have a variable `h : a = b`,
`h.symm` can be used as shorthand for `Eq.symm h` as a proof of `b = a`.

For more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)
" title="Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a
Equality is symmetric: if `a = b` then `b = a`....">symm</span>
  <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">⟨</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">,</span> <span class="lean-var" data-type="ℕ" title="ℕ">e</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">,</span> <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">,</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hminFac_prime</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">,</span> <span class="lean-var" data-type="0 &lt; e" title="0 &lt; e">he_pos</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">,</span> <span class="lean-var" data-type="m = p ^ e * m&#x27;" title="m = p ^ e * m&#x27;">hm_eq</span>.<span class="lean-const" data-name="Eq.symm" data-signature="Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a" data-docs="Equality is symmetric: if `a = b` then `b = a`.

Because this is in the `Eq` namespace, if you have a variable `h : a = b`,
`h.symm` can be used as shorthand for `Eq.symm h` as a proof of `b = a`.

For more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)
" title="Eq.symm.{u} {α : Sort u} {a b : α} (h : a = b) : b = a
Equality is symmetric: if `a = b` then `b = a`....">symm</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">,</span> <span class="lean-var" data-type="(p ^ e).Coprime m&#x27;" title="(p ^ e).Coprime m&#x27;">hcop</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">,</span> <span class="lean-var" data-type="1 &lt; m&#x27;" title="1 &lt; m&#x27;">hm&#x27;_gt_one</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">,</span> <span class="lean-var" data-type="m&#x27; &lt; m" title="m&#x27; &lt; m">hm&#x27;_lt</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">,</span> <span class="lean-var" data-type="p ^ e &lt; m" title="p ^ e &lt; m">hpe_lt</span><span class="lean-const" data-signature="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p" data-docs="Existential introduction. If `a : α` and `h : p a`,
then `⟨a, h⟩` is a proof that `∃ x : α, p x`. " title="Exists.intro.{u} {α : Sort u} {p : α → Prop} (w : α) (h : p w) : Exists p">⟩</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L71-L119" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:factorization-split-lt');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:psi-pos-of-odd">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.7</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:psi-pos-of-odd">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000020"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0002.html#lem:psi-ge-psiPrimePow">Theorem 2.0.4</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psi_pos_of_odd_ge_three" class="lean_decl">Crystallographic.psi_pos_of_odd_ge_three</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        For odd \(m \geq 3\), we have \(\psi (m) {\gt} 0\). </p>
<p>Since \(m \geq 3\) and \(m\) is odd, \(m\) has a prime factor \(q \geq 3\) (specifically, \(q = \mathrm{minFac}(m)\)). The prime power \(q^{\nu _q(m)}\) contributes \(\psi _{\mathrm{pp}}(q, \nu _q(m)) = \varphi (q^{\nu _q(m)}) {\gt} 0\) to \(\psi (m)\), since \((q, \nu _q(m)) \neq (2, 1)\).  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000020">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> The minimal prime factor \(q = \mathrm{minFac}(m)\) satisfies \(q \geq 3\) (since \(2 \nmid m\)). Thus \((q, \nu _q(m))\) is a nontrivial pair, and \(\psi (m) \geq \psi _{\mathrm{pp}}(q, \nu _q(m)) = \varphi (q^{\nu _q(m)}) {\gt} 0\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> <span class="lean-const lean-def" data-name="Crystallographic.psi_pos_of_odd_ge_three" data-signature="Crystallographic.psi_pos_of_odd_ge_three {m : ℕ} (hm : 3 ≤ m) (hm_odd : Odd m) : 0 &lt; psi m" title="Crystallographic.psi_pos_of_odd_ge_three {m : ℕ} (hm : 3 ≤ m) (hm_odd : Odd m) : 0 &lt; psi m">psi_pos_of_odd_ge_three</span> <span class="lean-bracket-1">{</span><span class="lean-var" data-type="ℕ" title="ℕ">m</span> : ℕ<span class="lean-bracket-1">}</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="3 ≤ m" title="3 ≤ m">hm</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">3</span> <span class="lean-operator">≤</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span><span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="Odd m" title="Odd m">hm_odd</span> : <span class="lean-const" data-name="Odd" data-signature="Odd.{u_2} {α : Type u_2} [Semiring α] (a : α) : Prop" data-docs="An element `a` of a semiring is odd if there exists `k` such `a = 2*k + 1`. " title="Odd.{u_2} {α : Type u_2} [Semiring α] (a : α) : Prop
An element `a` of a semiring is odd if there exists `k` such `a = 2*k + 1`. ">Odd</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span><span class="lean-bracket-1">)</span> :
    <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span></code><code class="lean-proof-body">
  <span class="lean-comment">-- m &gt;= <span class="lean-number">3</span> implies m != <span class="lean-number">1</span>, so minFac</span><span class="lean-bracket-1">(</span>m<span class="lean-bracket-1">)</span> is prime
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="m ≠ 1" title="m ≠ 1">hm_ne_one</span> : <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-operator">≠</span> <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="m ≠ 0" title="m ≠ 0">hm_ne_zero</span> : <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-operator">≠</span> <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span>
  <span class="lean-keyword" data-docs="`set a := t with h` is a variant of `let a := t`. It adds the hypothesis `h : a = t` to
the local context and replaces `t` with `a` everywhere it can.

`set a := t with ← h` will add `h : t = a` instead.

`set! a := t with h` does not do any replacing.

```lean
example (x : Nat) (h : x + x - x = 3) : x + x - x = 3 := by
  set y := x with ← h2
  sorry
/-
x : Nat
y : Nat := x
h : y + y - y = 3
h2 : x = y
⊢ y + y - y = 3
-/
```
" title="`set a := t with h` is a variant of `let a := t`. It adds the hypothesis `h : a = t` to">set</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> := <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.minFac" data-signature="Nat.minFac (n : ℕ) : ℕ" data-docs="Returns the smallest prime factor of `n ≠ 1`. " title="Nat.minFac (n : ℕ) : ℕ
Returns the smallest prime factor of `n ≠ 1`. ">minFac</span> <span class="lean-keyword">with</span> <span class="lean-var" data-type="q = m.minFac" title="q = m.minFac">hq_def</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="Nat.Prime q" title="Nat.Prime q">hq_prime</span> : <span class="lean-var" data-type="ℕ" title="ℕ">q</span>.<span class="lean-const" data-name="Nat.Prime" data-signature="Nat.Prime (p : ℕ) : Prop" data-docs="`Nat.Prime p` means that `p` is a prime number, that is, a natural number
at least 2 whose only divisors are `p` and `1`.
The theorem `Nat.prime_def` witnesses this description of a prime number. " title="Nat.Prime (p : ℕ) : Prop
`Nat.Prime p` means that `p` is a prime number, that is, a natural number...">Prime</span> := <span class="lean-const" data-name="Nat.minFac_prime" data-signature="Nat.minFac_prime {n : ℕ} (n1 : n ≠ 1) : Nat.Prime n.minFac" title="Nat.minFac_prime {n : ℕ} (n1 : n ≠ 1) : Nat.Prime n.minFac">Nat.minFac_prime</span> <span class="lean-var" data-type="m ≠ 1" title="m ≠ 1">hm_ne_one</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="q ∣ m" title="q ∣ m">hq_dvd</span> : <span class="lean-var" data-type="ℕ" title="ℕ">q</span> ∣ <span class="lean-var" data-type="ℕ" title="ℕ">m</span> := <span class="lean-const" data-name="Nat.minFac_dvd" data-signature="Nat.minFac_dvd (n : ℕ) : n.minFac ∣ n" title="Nat.minFac_dvd (n : ℕ) : n.minFac ∣ n">Nat.minFac_dvd</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span>
  <span class="lean-comment">-- m is odd, so minFac</span><span class="lean-bracket-1">(</span>m<span class="lean-bracket-1">)</span> != <span class="lean-number">2</span> <span class="lean-bracket-1">(</span>otherwise <span class="lean-number">2</span> would divide m<span class="lean-bracket-1">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="q ≠ 2" title="q ≠ 2">hq_ne2</span> : <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-operator">≠</span> <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
" title="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.">intro</span> <span class="lean-var" data-type="q = 2" title="q = 2">hq2eq</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-var" data-type="q = 2" title="q = 2">hq2eq</span><span class="lean-bracket-1">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
" title="Location specifications are used by many tactics that can operate on either the">at</span> <span class="lean-var" data-type="q ∣ m" title="q ∣ m">hq_dvd</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-var" data-type="Odd m" title="Odd m">hm_odd</span>.<span class="lean-const" data-name="Odd.not_two_dvd_nat" data-signature="Odd.not_two_dvd_nat {n : ℕ} (h : Odd n) : ¬2 ∣ n" title="Odd.not_two_dvd_nat {n : ℕ} (h : Odd n) : ¬2 ∣ n">not_two_dvd_nat</span> <span class="lean-var" data-type="2 ∣ m" title="2 ∣ m">hq_dvd</span>
  <span class="lean-comment">-- Therefore minFac</span><span class="lean-bracket-1">(</span>m<span class="lean-bracket-1">)</span> &gt;= <span class="lean-number">3</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="3 ≤ q" title="3 ≤ q">hq_ge3</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">3</span> <span class="lean-operator">≤</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="2 ≤ q" title="2 ≤ q">hq2</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> <span class="lean-operator">≤</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> := <span class="lean-var" data-type="Nat.Prime q" title="Nat.Prime q">hq_prime</span>.<span class="lean-const" data-name="Nat.Prime.two_le" data-signature="Nat.Prime.two_le {p : ℕ} : Nat.Prime p → 2 ≤ p" title="Nat.Prime.two_le {p : ℕ} : Nat.Prime p → 2 ≤ p">two_le</span>
    <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span>
  <span class="lean-comment">-- q is in the factorization support</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="q ∈ m.factorization.support" title="q ∈ m.factorization.support">hq_in_support</span> : <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span>.<span class="lean-const" data-name="Finsupp.support" data-signature="Finsupp.support.{u_9, u_10} {α : Type u_9} {M : Type u_10} [Zero M] (self : α →₀ M) : Finset α" data-docs="The support of a finitely supported function (aka `Finsupp`). " title="Finsupp.support.{u_9, u_10} {α : Type u_9} {M : Type u_10} [Zero M] (self : α →₀ M) : Finset α
The support of a finitely supported function (aka `Finsupp`). ">support</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Finsupp.mem_support_iff" data-signature="Finsupp.mem_support_iff.{u_1, u_4} {α : Type u_1} {M : Type u_4} [Zero M] {f : α →₀ M} {a : α} : a ∈ f.support ↔ f a ≠ 0" title="Finsupp.mem_support_iff.{u_1, u_4} {α : Type u_1} {M : Type u_4} [Zero M] {f : α →₀ M} {a : α} : a ∈ f.support ↔ f a ≠ 0">Finsupp.mem_support_iff</span><span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-bracket-1">(</span><span class="lean-const" data-name="Nat.Prime.factorization_pos_of_dvd" data-signature="Nat.Prime.factorization_pos_of_dvd {n p : ℕ} (hp : Nat.Prime p) (hn : n ≠ 0) (h : p ∣ n) : 0 &lt; n.factorization p" title="Nat.Prime.factorization_pos_of_dvd {n p : ℕ} (hp : Nat.Prime p) (hn : n ≠ 0) (h : p ∣ n) : 0 &lt; n.factorization p">Nat.Prime.factorization_pos_of_dvd</span> <span class="lean-var" data-type="Nat.Prime q" title="Nat.Prime q">hq_prime</span> <span class="lean-var" data-type="m ≠ 0" title="m ≠ 0">hm_ne_zero</span> <span class="lean-var" data-type="q ∣ m" title="q ∣ m">hq_dvd</span><span class="lean-bracket-1">)</span>.<span class="lean-const" data-name="LT.lt.ne&#x27;" data-signature="LT.lt.ne&#x27;.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : b &lt; a) : a ≠ b" title="LT.lt.ne&#x27;.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : b &lt; a) : a ≠ b">ne&#x27;</span>
  <span class="lean-comment">-- psi</span><span class="lean-bracket-1">(</span>m<span class="lean-bracket-1">)</span> &gt;= psiPrimePow<span class="lean-bracket-1">(</span>q, ord_q<span class="lean-bracket-2">(</span>m<span class="lean-bracket-2">)</span><span class="lean-bracket-1">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="psiPrimePow q (m.factorization q) ≤ psi m" title="psiPrimePow q (m.factorization q) ≤ psi m">hcontrib</span> : <span class="lean-const" data-name="Crystallographic.psiPrimePow" data-signature="Crystallographic.psiPrimePow (p k : ℕ) : ℕ" data-docs="Helper function that computes the contribution of a single prime power p^k to psi.
Returns 0 if k = 0, returns 0 if p = 2 and k = 1, otherwise returns phi(p^k). " title="Crystallographic.psiPrimePow (p k : ℕ) : ℕ
Helper function that computes the contribution of a single prime power p^k to psi....">psiPrimePow</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span><span class="lean-bracket-1">)</span> <span class="lean-operator">≤</span> <span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> :=
    <span class="lean-const" data-name="Crystallographic.psi_ge_psiPrimePow_of_mem_support" data-signature="Crystallographic.psi_ge_psiPrimePow_of_mem_support {m p : ℕ} (hp : p ∈ m.factorization.support) :
  psiPrimePow p (m.factorization p) ≤ psi m" data-docs="`psi m` is at least the contribution from any single prime power factor.

If p^k divides m exactly, then `psi m ≥ psiPrimePow p k`. " title="Crystallographic.psi_ge_psiPrimePow_of_mem_support {m p : ℕ} (hp : p ∈ m.factorization.support) :
  psiPrimePow p (m.factorization p) ≤ psi m
`psi m` is at least the contribution from any single prime power factor....">psi_ge_psiPrimePow_of_mem_support</span> <span class="lean-var" data-type="q ∈ m.factorization.support" title="q ∈ m.factorization.support">hq_in_support</span>
  <span class="lean-comment">-- psiPrimePow</span><span class="lean-bracket-1">(</span>q, k<span class="lean-bracket-1">)</span> = totient<span class="lean-bracket-1">(</span>q^k<span class="lean-bracket-1">)</span> &gt; <span class="lean-number">0</span> for q &gt;= <span class="lean-number">3</span> <span class="lean-bracket-1">(</span>since q != <span class="lean-number">2</span> means <span class="lean-bracket-2">(</span>q, k<span class="lean-bracket-2">)</span> != <span class="lean-bracket-2">(</span><span class="lean-number">2</span>, <span class="lean-number">1</span><span class="lean-bracket-2">)</span><span class="lean-bracket-1">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="0 &lt; psiPrimePow q (m.factorization q)" title="0 &lt; psiPrimePow q (m.factorization q)">hcontrib_pos</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-const" data-name="Crystallographic.psiPrimePow" data-signature="Crystallographic.psiPrimePow (p k : ℕ) : ℕ" data-docs="Helper function that computes the contribution of a single prime power p^k to psi.
Returns 0 if k = 0, returns 0 if p = 2 and k = 1, otherwise returns phi(p^k). " title="Crystallographic.psiPrimePow (p k : ℕ) : ℕ
Helper function that computes the contribution of a single prime power p^k to psi....">psiPrimePow</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span><span class="lean-bracket-1">)</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Crystallographic.psiPrimePow" data-signature="Crystallographic.psiPrimePow (p k : ℕ) : ℕ" data-docs="Helper function that computes the contribution of a single prime power p^k to psi.
Returns 0 if k = 0, returns 0 if p = 2 and k = 1, otherwise returns phi(p^k). " title="Crystallographic.psiPrimePow (p k : ℕ) : ℕ
Helper function that computes the contribution of a single prime power p^k to psi....">psiPrimePow</span><span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="0 &lt; m.factorization q" title="0 &lt; m.factorization q">hk_pos</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> :=
      <span class="lean-const" data-name="Nat.Prime.factorization_pos_of_dvd" data-signature="Nat.Prime.factorization_pos_of_dvd {n p : ℕ} (hp : Nat.Prime p) (hn : n ≠ 0) (h : p ∣ n) : 0 &lt; n.factorization p" title="Nat.Prime.factorization_pos_of_dvd {n p : ℕ} (hp : Nat.Prime p) (hn : n ≠ 0) (h : p ∣ n) : 0 &lt; n.factorization p">Nat.Prime.factorization_pos_of_dvd</span> <span class="lean-var" data-type="Nat.Prime q" title="Nat.Prime q">hq_prime</span> <span class="lean-var" data-type="m ≠ 0" title="m ≠ 0">hm_ne_zero</span> <span class="lean-var" data-type="q ∣ m" title="q ∣ m">hq_dvd</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-var" data-type="0 &lt; m.factorization q" title="0 &lt; m.factorization q">hk_pos</span>.<span class="lean-const" data-name="LT.lt.ne&#x27;" data-signature="LT.lt.ne&#x27;.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : b &lt; a) : a ≠ b" title="LT.lt.ne&#x27;.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : b &lt; a) : a ≠ b">ne&#x27;</span>, <span class="lean-const" data-name="ite_false" data-signature="ite_false.{u_1} {α : Sort u_1} (a b : α) : (if False then a else b) = b" title="ite_false.{u_1} {α : Sort u_1} (a b : α) : (if False then a else b) = b">ite_false</span><span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-var" data-type="q ≠ 2" title="q ≠ 2">hq_ne2</span>, <span class="lean-const" data-name="false_and" data-signature="false_and (p : Prop) : (False ∧ p) = False" title="false_and (p : Prop) : (False ∧ p) = False">false_and</span>, <span class="lean-const" data-name="ite_false" data-signature="ite_false.{u_1} {α : Sort u_1} (a b : α) : (if False then a else b) = b" title="ite_false.{u_1} {α : Sort u_1} (a b : α) : (if False then a else b) = b">ite_false</span><span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-const" data-name="Nat.totient_pos" data-signature="Nat.totient_pos {n : ℕ} : 0 &lt; n.totient ↔ 0 &lt; n" title="Nat.totient_pos {n : ℕ} : 0 &lt; n.totient ↔ 0 &lt; n">Nat.totient_pos</span>.<span class="lean-const" data-name="Iff.mpr" data-signature="Iff.mpr {a b : Prop} (self : a ↔ b) : b → a" data-docs="Modus ponens for if and only if, reversed. If `a ↔ b` and `b`, then `a`. " title="Iff.mpr {a b : Prop} (self : a ↔ b) : b → a
Modus ponens for if and only if, reversed. If `a ↔ b` and `b`, then `a`. ">mpr</span> <span class="lean-bracket-1">(</span><span class="lean-const" data-name="Nat.pow_pos" data-signature="Nat.pow_pos {a n : ℕ} (h : 0 &lt; a) : 0 &lt; a ^ n" title="Nat.pow_pos {a n : ℕ} (h : 0 &lt; a) : 0 &lt; a ^ n">Nat.pow_pos</span> <span class="lean-var" data-type="Nat.Prime q" title="Nat.Prime q">hq_prime</span>.<span class="lean-const" data-name="Nat.Prime.pos" data-signature="Nat.Prime.pos {p : ℕ} (pp : Nat.Prime p) : 0 &lt; p" title="Nat.Prime.pos {p : ℕ} (pp : Nat.Prime p) : 0 &lt; p">pos</span><span class="lean-bracket-1">)</span>
  <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L121-L164" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:psi-pos-of-odd');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:psi-le-totient">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.8</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:psi-le-totient">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000021"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0006.html#lem:totient-ge-two">Theorem A.0.4</a></li>
          
          <li><a href="sect0002.html#lem:two-le-totient-prime-pow">Theorem 2.0.5</a></li>
          
          <li><a href="sect0002.html#lem:psi-prime-pow">Theorem 2.0.1</a></li>
          
          <li><a href="sect0002.html#lem:factorization-split-lt">Theorem 2.0.6</a></li>
          
          <li><a href="sect0002.html#lem:psi-coprime-add">Theorem 2.0.3</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.psi_le_totient" class="lean_decl">Crystallographic.psi_le_totient</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        For all \(m \geq 1\), we have \(\psi (m) \leq \varphi (m)\). </p>
<p>We prove \(\psi (m) \leq \varphi (m)\) by strong induction on \(m\). The key observation is that \(\psi \) excludes the contribution from \((2, 1)\), while \(\varphi \) includes \(\varphi (2) = 1\), so \(\psi \leq \varphi \) with equality when \(2 \nmid m\) or \(4 \mid m\). </p>
<p>The proof proceeds by strong induction on \(m\): </p>
<ul class="itemize">
  <li><p>For \(m = 1\): \(\psi (1) = 0 \leq 1 = \varphi (1)\) </p>
</li>
  <li><p>For prime powers \(p^k\): \(\psi (p^k) = \varphi (p^k)\) (with the exception \(\psi (2) = 0\)) </p>
</li>
  <li><p>For composite \(m = 2 \cdot \text{odd}\): \(\psi (m) = \psi (\text{odd}) \leq \varphi (\text{odd}) = \varphi (m)\) </p>
</li>
  <li><p>For general composite without \(2^1\) factor: each \(\varphi (p^k) \geq 2\), so sum \(\leq \) product </p>
</li>
</ul>
<p>  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000021">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> By strong induction on \(m\). For \(m = 1\): both sides are \(0\). For \(m {\gt} 1\): use coprime factorization \(m = a \cdot b\) with \(1 {\lt} a, b {\lt} m\). Then \(\psi (m) = \psi (a) + \psi (b) \leq \varphi (a) + \varphi (b) \leq \varphi (m)\) by the inductive hypothesis and multiplicativity of \(\varphi \). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> <span class="lean-const lean-def" data-name="Crystallographic.psi_le_totient" data-signature="Crystallographic.psi_le_totient (m : ℕ) (hm : 0 &lt; m) : psi m ≤ m.totient" data-docs="psi(m) ≤ totient(m) for all m ≥ 1.

The proof proceeds by strong induction on m, using the coprime multiplicativity
of both psi (additive) and totient (multiplicative).

Key cases:
- m = 1: psi(1) = 0 ≤ 1 = totient(1)
- m = prime power p^k: psi = totient (except psi(2) = 0 ≤ 1 = totient(2))
- m = 2 * odd (with odd &gt; 1): psi(m) = psi(odd) ≤ totient(odd) = totient(m)
- m = composite without 2^1 factor: each φ(p^k) ≥ 2, so sum ≤ product " title="Crystallographic.psi_le_totient (m : ℕ) (hm : 0 &lt; m) : psi m ≤ m.totient
psi(m) ≤ totient(m) for all m ≥ 1....">psi_le_totient</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">m</span> : ℕ<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="0 &lt; m" title="0 &lt; m">hm</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span><span class="lean-bracket-1">)</span> : <span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-operator">≤</span> <span class="lean-const" data-name="Nat.totient" data-signature="Nat.totient (n : ℕ) : ℕ" data-docs="Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are
coprime with `n`. " title="Nat.totient (n : ℕ) : ℕ
Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are...">Nat.totient</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span></code><code class="lean-proof-body">
  <span class="lean-comment">-- Strong induction on m</span>
  <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
" title="Assuming `x` is a variable in the local context with an inductive type,">induction</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-keyword">using</span> <span class="lean-const" data-name="Nat.strong_induction_on" data-signature="Nat.strong_induction_on {p : ℕ → Prop} (n : ℕ) (h : ∀ (n : ℕ), (∀ m &lt; n, p m) → p n) : p n" title="Nat.strong_induction_on {p : ℕ → Prop} (n : ℕ) (h : ∀ (n : ℕ), (∀ m &lt; n, p m) → p n) : p n">Nat.strong_induction_on</span> <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
" title="After `with`, there is an optional tactic that runs on all branches, and">with</span>
  | _ <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-var" data-type="∀ m_1 &lt; m, 0 &lt; m_1 → psi m_1 ≤ m_1.totient" title="∀ m_1 &lt; m, 0 &lt; m_1 → psi m_1 ≤ m_1.totient">IH</span> =&gt;
  <span class="lean-comment">-- Handle small cases separately</span>
  <span class="lean-keyword" data-docs="`rcases` is a tactic that will perform `cases` recursively, according to a pattern. It is used to
destructure hypotheses or expressions composed of inductive types like `h1 : a ∧ b ∧ c ∨ d` or
`h2 : ∃ x y, trans_rel R x y`. Usual usage might be `rcases h1 with ⟨ha, hb, hc⟩ | hd` or
`rcases h2 with ⟨x, y, _ | ⟨z, hxz, hzy⟩⟩` for these examples.

Each element of an `rcases` pattern is matched against a particular local hypothesis (most of which
are generated during the execution of `rcases` and represent individual elements destructured from
the input expression). An `rcases` pattern has the following grammar:

* A name like `x`, which names the active hypothesis as `x`.
* A blank `_`, which does nothing (letting the automatic naming system used by `cases` name the
  hypothesis).
* A hyphen `-`, which clears the active hypothesis and any dependents.
* The keyword `rfl`, which expects the hypothesis to be `h : a = b`, and calls `subst` on the
  hypothesis (which has the effect of replacing `b` with `a` everywhere or vice versa).
* A type ascription `p : ty`, which sets the type of the hypothesis to `ty` and then matches it
  against `p`. (Of course, `ty` must unify with the actual type of `h` for this to work.)
* A tuple pattern `⟨p1, p2, p3⟩`, which matches a constructor with many arguments, or a series
  of nested conjunctions or existentials. For example if the active hypothesis is `a ∧ b ∧ c`,
  then the conjunction will be destructured, and `p1` will be matched against `a`, `p2` against `b`
  and so on.
* A `@` before a tuple pattern as in `@⟨p1, p2, p3⟩` will bind all arguments in the constructor,
  while leaving the `@` off will only use the patterns on the explicit arguments.
* An alternation pattern `p1 | p2 | p3`, which matches an inductive type with multiple constructors,
  or a nested disjunction like `a ∨ b ∨ c`.

A pattern like `⟨a, b, c⟩ | ⟨d, e⟩` will do a split over the inductive datatype,
naming the first three parameters of the first constructor as `a,b,c` and the
first two of the second constructor `d,e`. If the list is not as long as the
number of arguments to the constructor or the number of constructors, the
remaining variables will be automatically named. If there are nested brackets
such as `⟨⟨a⟩, b | c⟩ | d` then these will cause more case splits as necessary.
If there are too many arguments, such as `⟨a, b, c⟩` for splitting on
`∃ x, ∃ y, p x`, then it will be treated as `⟨a, ⟨b, c⟩⟩`, splitting the last
parameter as necessary.

`rcases` also has special support for quotient types: quotient induction into Prop works like
matching on the constructor `quot.mk`.

`rcases h : e with PAT` will do the same as `rcases e with PAT` with the exception that an
assumption `h : e = PAT` will be added to the context.
" title="`rcases` is a tactic that will perform `cases` recursively, according to a pattern. It is used to">rcases</span> <span class="lean-const" data-name="Nat.lt_trichotomy" data-signature="Nat.lt_trichotomy (a b : ℕ) : a &lt; b ∨ a = b ∨ b &lt; a" title="Nat.lt_trichotomy (a b : ℕ) : a &lt; b ∨ a = b ∨ b &lt; a">Nat.lt_trichotomy</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> <span class="lean-keyword">with</span> <span class="lean-var" data-type="m &lt; 1" title="m &lt; 1">hm0</span> | <span class="lean-var" data-type="m = 1" title="m = 1">rfl</span> | <span class="lean-var" data-type="1 &lt; m" title="1 &lt; m">hm_gt1</span>
  <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span> <span class="lean-comment">-- m &lt; <span class="lean-number">1</span> contradicts hm</span>
  <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Crystallographic.psi_one" data-signature="Crystallographic.psi_one : psi 1 = 0" data-docs="`psi 1 = 0`: The identity matrix has order 1 in any dimension. " title="Crystallographic.psi_one : psi 1 = 0
`psi 1 = 0`: The identity matrix has order 1 in any dimension. ">psi_one</span><span class="lean-bracket-1">]</span> <span class="lean-comment">-- m = <span class="lean-number">1</span></span>
  <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="`rcases` is a tactic that will perform `cases` recursively, according to a pattern. It is used to
destructure hypotheses or expressions composed of inductive types like `h1 : a ∧ b ∧ c ∨ d` or
`h2 : ∃ x y, trans_rel R x y`. Usual usage might be `rcases h1 with ⟨ha, hb, hc⟩ | hd` or
`rcases h2 with ⟨x, y, _ | ⟨z, hxz, hzy⟩⟩` for these examples.

Each element of an `rcases` pattern is matched against a particular local hypothesis (most of which
are generated during the execution of `rcases` and represent individual elements destructured from
the input expression). An `rcases` pattern has the following grammar:

* A name like `x`, which names the active hypothesis as `x`.
* A blank `_`, which does nothing (letting the automatic naming system used by `cases` name the
  hypothesis).
* A hyphen `-`, which clears the active hypothesis and any dependents.
* The keyword `rfl`, which expects the hypothesis to be `h : a = b`, and calls `subst` on the
  hypothesis (which has the effect of replacing `b` with `a` everywhere or vice versa).
* A type ascription `p : ty`, which sets the type of the hypothesis to `ty` and then matches it
  against `p`. (Of course, `ty` must unify with the actual type of `h` for this to work.)
* A tuple pattern `⟨p1, p2, p3⟩`, which matches a constructor with many arguments, or a series
  of nested conjunctions or existentials. For example if the active hypothesis is `a ∧ b ∧ c`,
  then the conjunction will be destructured, and `p1` will be matched against `a`, `p2` against `b`
  and so on.
* A `@` before a tuple pattern as in `@⟨p1, p2, p3⟩` will bind all arguments in the constructor,
  while leaving the `@` off will only use the patterns on the explicit arguments.
* An alternation pattern `p1 | p2 | p3`, which matches an inductive type with multiple constructors,
  or a nested disjunction like `a ∨ b ∨ c`.

A pattern like `⟨a, b, c⟩ | ⟨d, e⟩` will do a split over the inductive datatype,
naming the first three parameters of the first constructor as `a,b,c` and the
first two of the second constructor `d,e`. If the list is not as long as the
number of arguments to the constructor or the number of constructors, the
remaining variables will be automatically named. If there are nested brackets
such as `⟨⟨a⟩, b | c⟩ | d` then these will cause more case splits as necessary.
If there are too many arguments, such as `⟨a, b, c⟩` for splitting on
`∃ x, ∃ y, p x`, then it will be treated as `⟨a, ⟨b, c⟩⟩`, splitting the last
parameter as necessary.

`rcases` also has special support for quotient types: quotient induction into Prop works like
matching on the constructor `quot.mk`.

`rcases h : e with PAT` will do the same as `rcases e with PAT` with the exception that an
assumption `h : e = PAT` will be added to the context.
" title="`rcases` is a tactic that will perform `cases` recursively, according to a pattern. It is used to">rcases</span> <span class="lean-const" data-name="Nat.lt_trichotomy" data-signature="Nat.lt_trichotomy (a b : ℕ) : a &lt; b ∨ a = b ∨ b &lt; a" title="Nat.lt_trichotomy (a b : ℕ) : a &lt; b ∨ a = b ∨ b &lt; a">Nat.lt_trichotomy</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> <span class="lean-keyword">with</span> <span class="lean-var" data-type="m &lt; 2" title="m &lt; 2">hm_lt2</span> | <span class="lean-var" data-type="m = 2" title="m = 2">rfl</span> | <span class="lean-var" data-type="2 &lt; m" title="2 &lt; m">hm_ge3</span>
    <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span> <span class="lean-comment">-- m &lt; <span class="lean-number">2</span> but m &gt; <span class="lean-number">1</span>, contradiction</span>
    <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Crystallographic.psi_two" data-signature="Crystallographic.psi_two : psi 2 = 0" data-docs="`psi 2 = 0`: The negation of identity has order 2 in any dimension ≥ 1. " title="Crystallographic.psi_two : psi 2 = 0
`psi 2 = 0`: The negation of identity has order 2 in any dimension ≥ 1. ">psi_two</span><span class="lean-bracket-1">]</span> <span class="lean-comment">-- m = <span class="lean-number">2</span></span>
    <span class="lean-operator">·</span> <span class="lean-comment">-- m <span class="lean-operator">≥</span> <span class="lean-number">3</span></span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="1 &lt; m" title="1 &lt; m">hm_gt1</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span>
      <span class="lean-comment">-- Check if m is a prime power</span>
      <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
" title="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `">by_cases</span> <span class="lean-var" data-type="IsPrimePow m" title="IsPrimePow m">hpow</span> : <span class="lean-const" data-name="IsPrimePow" data-signature="IsPrimePow.{u_1} {R : Type u_1} [CommMonoidWithZero R] (n : R) : Prop" data-docs="`n` is a prime power if there is a prime `p` and a positive natural `k` such that `n` can be
written as `p^k`. " title="IsPrimePow.{u_1} {R : Type u_1} [CommMonoidWithZero R] (n : R) : Prop
`n` is a prime power if there is a prime `p` and a positive natural `k` such that `n` can be...">IsPrimePow</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span>
      <span class="lean-operator">·</span> <span class="lean-comment">-- m is a prime power p^k</span>
        <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="isPrimePow_nat_iff" data-signature="isPrimePow_nat_iff (n : ℕ) : IsPrimePow n ↔ ∃ p k, Nat.Prime p ∧ 0 &lt; k ∧ p ^ k = n" title="isPrimePow_nat_iff (n : ℕ) : IsPrimePow n ↔ ∃ p k, Nat.Prime p ∧ 0 &lt; k ∧ p ^ k = n">isPrimePow_nat_iff</span><span class="lean-bracket-1">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
" title="Location specifications are used by many tactics that can operate on either the">at</span> <span class="lean-var" data-type="IsPrimePow m" title="IsPrimePow m">hpow</span>
        <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
" title="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for">obtain</span> <span class="lean-bracket-1">⟨</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span>, <span class="lean-var" data-type="ℕ" title="ℕ">k</span>, <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hp</span>, <span class="lean-var" data-type="0 &lt; k" title="0 &lt; k">hk</span>, <span class="lean-var" data-type="p ^ k = m" title="p ^ k = m">rfl</span><span class="lean-bracket-1">⟩</span> := <span class="lean-var" data-type="∃ p k, Nat.Prime p ∧ 0 &lt; k ∧ p ^ k = m" title="∃ p k, Nat.Prime p ∧ 0 &lt; k ∧ p ^ k = m">hpow</span>
        <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Crystallographic.psi_prime_pow" data-signature="Crystallographic.psi_prime_pow (p k : ℕ) (hp : Nat.Prime p) (hk : 0 &lt; k) :
  psi (p ^ k) = if p = 2 ∧ k = 1 then 0 else (p ^ k).totient" data-docs="`psi` of a prime power p^k equals phi(p^k), except `psi 2 = 0` " title="Crystallographic.psi_prime_pow (p k : ℕ) (hp : Nat.Prime p) (hk : 0 &lt; k) :
  psi (p ^ k) = if p = 2 ∧ k = 1 then 0 else (p ^ k).totient
`psi` of a prime power p^k equals phi(p^k), except `psi 2 = 0` ">psi_prime_pow</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> <span class="lean-var" data-type="ℕ" title="ℕ">k</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hp</span> <span class="lean-var" data-type="0 &lt; k" title="0 &lt; k">hk</span><span class="lean-bracket-1">]</span>
        <span class="lean-keyword" data-docs="Splits all if-then-else-expressions into multiple goals.
Given a goal of the form `g (if p then x else y)`, `split_ifs` will produce
two goals: `p ⊢ g x` and `¬p ⊢ g y`.
If there are multiple ite-expressions, then `split_ifs` will split them all,
starting with a top-most one whose condition does not contain another
ite-expression.
`split_ifs at *` splits all ite-expressions in all hypotheses as well as the goal.
`split_ifs with h₁ h₂ h₃` overrides the default names for the hypotheses.
" title="Splits all if-then-else-expressions into multiple goals.">split_ifs</span> <span class="lean-keyword">with</span> h21
        <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-comment">-- psi</span><span class="lean-bracket-1">(</span><span class="lean-number">2</span><span class="lean-bracket-1">)</span> = <span class="lean-number">0</span> <span class="lean-operator">≤</span> totient<span class="lean-bracket-1">(</span><span class="lean-number">2</span><span class="lean-bracket-1">)</span>
        <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-const" data-name="le_refl" data-signature="le_refl.{u_1} {α : Type u_1} [Preorder α] (a : α) : a ≤ a" data-docs="The relation `≤` on a preorder is reflexive. " title="le_refl.{u_1} {α : Type u_1} [Preorder α] (a : α) : a ≤ a
The relation `≤` on a preorder is reflexive. ">le_refl</span> _ <span class="lean-comment">-- psi</span><span class="lean-bracket-1">(</span>p^k<span class="lean-bracket-1">)</span> = totient<span class="lean-bracket-1">(</span>p^k<span class="lean-bracket-1">)</span> for other prime powers
      <span class="lean-operator">·</span> <span class="lean-comment">-- m is not a prime power, so it has multiple distinct prime factors</span>
        <span class="lean-comment">-- Factor m = p^e * m&#x27; using factorization_split_lt</span>
        <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
" title="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for">obtain</span> <span class="lean-bracket-1">⟨</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span>, <span class="lean-var" data-type="ℕ" title="ℕ">e</span>, <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span>, <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hp</span>, <span class="lean-var" data-type="0 &lt; e" title="0 &lt; e">he_pos</span>, <span class="lean-var" data-type="p ^ e * m&#x27; = m" title="p ^ e * m&#x27; = m">hm_eq</span>, <span class="lean-var" data-type="(p ^ e).Coprime m&#x27;" title="(p ^ e).Coprime m&#x27;">hcop</span>, <span class="lean-var" data-type="1 &lt; m&#x27;" title="1 &lt; m&#x27;">hm&#x27;_gt_one</span>, <span class="lean-var" data-type="m&#x27; &lt; m" title="m&#x27; &lt; m">hm&#x27;_lt</span>, _<span class="lean-bracket-1">⟩</span> :=
          <span class="lean-const" data-name="Crystallographic.factorization_split_lt" data-signature="Crystallographic.factorization_split_lt {m : ℕ} (hm : 2 &lt; m) (h_not_pp : ¬IsPrimePow m) :
  ∃ p e m&#x27;, Nat.Prime p ∧ 0 &lt; e ∧ p ^ e * m&#x27; = m ∧ (p ^ e).Coprime m&#x27; ∧ 1 &lt; m&#x27; ∧ m&#x27; &lt; m ∧ p ^ e &lt; m" title="Crystallographic.factorization_split_lt {m : ℕ} (hm : 2 &lt; m) (h_not_pp : ¬IsPrimePow m) :
  ∃ p e m&#x27;, Nat.Prime p ∧ 0 &lt; e ∧ p ^ e * m&#x27; = m ∧ (p ^ e).Coprime m&#x27; ∧ 1 &lt; m&#x27; ∧ m&#x27; &lt; m ∧ p ^ e &lt; m">factorization_split_lt</span> <span class="lean-bracket-1">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span> : <span class="lean-number">2</span> &lt; m<span class="lean-bracket-1">)</span> <span class="lean-var" data-type="¬IsPrimePow m" title="¬IsPrimePow m">hpow</span>
        <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="0 &lt; m&#x27;" title="0 &lt; m&#x27;">hm&#x27;_pos</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span>
        <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="m&#x27; ≠ 1" title="m&#x27; ≠ 1">hm&#x27;_ne_one</span> : <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> <span class="lean-operator">≠</span> <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span>
        <span class="lean-comment">-- psi and totient are additive/multiplicative on coprime factors</span>
        <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-operator">←</span> <span class="lean-var" data-type="p ^ e * m&#x27; = m" title="p ^ e * m&#x27; = m">hm_eq</span>, <span class="lean-const" data-name="Crystallographic.psi_coprime_add" data-signature="Crystallographic.psi_coprime_add (m n : ℕ) (hm : 0 &lt; m) (hn : 0 &lt; n) (h : m.Coprime n) : psi (m * n) = psi m + psi n" data-docs="`psi` is additive on coprime factors.

For coprime m and n, `psi (m * n) = psi m + psi n`. This follows from the
factorization m * n = prod(p_i^{k_i}) * prod(q_j^{l_j}) where the prime
factors of m and n are disjoint. " title="Crystallographic.psi_coprime_add (m n : ℕ) (hm : 0 &lt; m) (hn : 0 &lt; n) (h : m.Coprime n) : psi (m * n) = psi m + psi n
`psi` is additive on coprime factors....">psi_coprime_add</span> _ _ <span class="lean-bracket-2">(</span><span class="lean-const" data-name="Nat.pow_pos" data-signature="Nat.pow_pos {a n : ℕ} (h : 0 &lt; a) : 0 &lt; a ^ n" title="Nat.pow_pos {a n : ℕ} (h : 0 &lt; a) : 0 &lt; a ^ n">Nat.pow_pos</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hp</span>.<span class="lean-const" data-name="Nat.Prime.pos" data-signature="Nat.Prime.pos {p : ℕ} (pp : Nat.Prime p) : 0 &lt; p" title="Nat.Prime.pos {p : ℕ} (pp : Nat.Prime p) : 0 &lt; p">pos</span><span class="lean-bracket-2">)</span> <span class="lean-var" data-type="0 &lt; m&#x27;" title="0 &lt; m&#x27;">hm&#x27;_pos</span> <span class="lean-var" data-type="(p ^ e).Coprime m&#x27;" title="(p ^ e).Coprime m&#x27;">hcop</span>,
            <span class="lean-const" data-name="Nat.totient_mul" data-signature="Nat.totient_mul {m n : ℕ} (h : m.Coprime n) : (m * n).totient = m.totient * n.totient" title="Nat.totient_mul {m n : ℕ} (h : m.Coprime n) : (m * n).totient = m.totient * n.totient">Nat.totient_mul</span> <span class="lean-var" data-type="(p ^ e).Coprime m&#x27;" title="(p ^ e).Coprime m&#x27;">hcop</span><span class="lean-bracket-1">]</span>
        <span class="lean-comment">-- By IH: psi</span><span class="lean-bracket-1">(</span>m&#x27;<span class="lean-bracket-1">)</span> <span class="lean-operator">≤</span> totient<span class="lean-bracket-1">(</span>m&#x27;<span class="lean-bracket-1">)</span>
        <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="psi m&#x27; ≤ m&#x27;.totient" title="psi m&#x27; ≤ m&#x27;.totient">IH_m&#x27;</span> : <span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span> <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> <span class="lean-operator">≤</span> <span class="lean-const" data-name="Nat.totient" data-signature="Nat.totient (n : ℕ) : ℕ" data-docs="Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are
coprime with `n`. " title="Nat.totient (n : ℕ) : ℕ
Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are...">Nat.totient</span> <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> := <span class="lean-var" data-type="∀ m_1 &lt; m, 0 &lt; m_1 → psi m_1 ≤ m_1.totient" title="∀ m_1 &lt; m, 0 &lt; m_1 → psi m_1 ≤ m_1.totient">IH</span> <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> <span class="lean-var" data-type="m&#x27; &lt; m" title="m&#x27; &lt; m">hm&#x27;_lt</span> <span class="lean-var" data-type="0 &lt; m&#x27;" title="0 &lt; m&#x27;">hm&#x27;_pos</span>
        <span class="lean-comment">-- For the prime power part: psi</span><span class="lean-bracket-1">(</span>p^e<span class="lean-bracket-1">)</span> <span class="lean-operator">≤</span> totient<span class="lean-bracket-1">(</span>p^e<span class="lean-bracket-1">)</span>
        <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="psi (p ^ e) ≤ (p ^ e).totient" title="psi (p ^ e) ≤ (p ^ e).totient">hpsi_pe</span> : <span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span><span class="lean-bracket-1">)</span> <span class="lean-operator">≤</span> <span class="lean-const" data-name="Nat.totient" data-signature="Nat.totient (n : ℕ) : ℕ" data-docs="Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are
coprime with `n`. " title="Nat.totient (n : ℕ) : ℕ
Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are...">Nat.totient</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span><span class="lean-bracket-1">)</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
          <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Crystallographic.psi_prime_pow" data-signature="Crystallographic.psi_prime_pow (p k : ℕ) (hp : Nat.Prime p) (hk : 0 &lt; k) :
  psi (p ^ k) = if p = 2 ∧ k = 1 then 0 else (p ^ k).totient" data-docs="`psi` of a prime power p^k equals phi(p^k), except `psi 2 = 0` " title="Crystallographic.psi_prime_pow (p k : ℕ) (hp : Nat.Prime p) (hk : 0 &lt; k) :
  psi (p ^ k) = if p = 2 ∧ k = 1 then 0 else (p ^ k).totient
`psi` of a prime power p^k equals phi(p^k), except `psi 2 = 0` ">psi_prime_pow</span> <span class="lean-var" data-type="ℕ" title="ℕ">p</span> <span class="lean-var" data-type="ℕ" title="ℕ">e</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hp</span> <span class="lean-var" data-type="0 &lt; e" title="0 &lt; e">he_pos</span><span class="lean-bracket-1">]</span>
          <span class="lean-keyword" data-docs="Splits all if-then-else-expressions into multiple goals.
Given a goal of the form `g (if p then x else y)`, `split_ifs` will produce
two goals: `p ⊢ g x` and `¬p ⊢ g y`.
If there are multiple ite-expressions, then `split_ifs` will split them all,
starting with a top-most one whose condition does not contain another
ite-expression.
`split_ifs at *` splits all ite-expressions in all hypotheses as well as the goal.
`split_ifs with h₁ h₂ h₃` overrides the default names for the hypotheses.
" title="Splits all if-then-else-expressions into multiple goals.">split_ifs</span> &lt;;&gt; <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span>
        <span class="lean-comment">-- Three cases based on whether p^e or m&#x27; equals <span class="lean-number">2</span></span>
        <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
" title="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `">by_cases</span> <span class="lean-var" data-type="p = 2 ∧ e = 1" title="p = 2 ∧ e = 1">h21</span> : <span class="lean-var" data-type="ℕ" title="ℕ">p</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> <span class="lean-operator">∧</span> <span class="lean-var" data-type="ℕ" title="ℕ">e</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">1</span>
        <span class="lean-operator">·</span> <span class="lean-comment">-- Case <span class="lean-number">1</span>: p^e = <span class="lean-number">2</span>, so psi</span><span class="lean-bracket-1">(</span><span class="lean-number">2</span><span class="lean-bracket-1">)</span> = <span class="lean-number">0</span> and totient<span class="lean-bracket-1">(</span><span class="lean-number">2</span><span class="lean-bracket-1">)</span> = <span class="lean-number">1</span>
          <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
" title="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for">obtain</span> <span class="lean-bracket-1">⟨</span><span class="lean-var" data-type="p = 2" title="p = 2">hp2</span>, <span class="lean-var" data-type="e = 1" title="e = 1">he1</span><span class="lean-bracket-1">⟩</span> := <span class="lean-var" data-type="p = 2 ∧ e = 1" title="p = 2 ∧ e = 1">h21</span>
          <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-var" data-type="p = 2" title="p = 2">hp2</span>, <span class="lean-var" data-type="e = 1" title="e = 1">he1</span>, <span class="lean-const" data-name="pow_one" data-signature="pow_one.{u_2} {M : Type u_2} [Monoid M] (a : M) : a ^ 1 = a" title="pow_one.{u_2} {M : Type u_2} [Monoid M] (a : M) : a ^ 1 = a">pow_one</span>, <span class="lean-const" data-name="Crystallographic.psi_two" data-signature="Crystallographic.psi_two : psi 2 = 0" data-docs="`psi 2 = 0`: The negation of identity has order 2 in any dimension ≥ 1. " title="Crystallographic.psi_two : psi 2 = 0
`psi 2 = 0`: The negation of identity has order 2 in any dimension ≥ 1. ">psi_two</span>, <span class="lean-const" data-name="Nat.totient_two" data-signature="Nat.totient_two : Nat.totient 2 = 1" title="Nat.totient_two : Nat.totient 2 = 1">Nat.totient_two</span>, <span class="lean-const" data-name="zero_add" data-signature="zero_add.{u} {M : Type u} [AddZeroClass M] (a : M) : 0 + a = a" title="zero_add.{u} {M : Type u} [AddZeroClass M] (a : M) : 0 + a = a">zero_add</span>,
            <span class="lean-const" data-name="one_mul" data-signature="one_mul.{u} {M : Type u} [MulOneClass M] (a : M) : 1 * a = a" title="one_mul.{u} {M : Type u} [MulOneClass M] (a : M) : 1 * a = a">one_mul</span><span class="lean-bracket-1">]</span>
          <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-var" data-type="psi m&#x27; ≤ m&#x27;.totient" title="psi m&#x27; ≤ m&#x27;.totient">IH_m&#x27;</span>
        <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
" title="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `">by_cases</span> <span class="lean-var" data-type="m&#x27; = 2" title="m&#x27; = 2">hm&#x27;2</span> : <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">2</span>
          <span class="lean-operator">·</span> <span class="lean-comment">-- Case <span class="lean-number">2</span>: m&#x27; = <span class="lean-number">2</span>, so psi</span><span class="lean-bracket-1">(</span><span class="lean-number">2</span><span class="lean-bracket-1">)</span> = <span class="lean-number">0</span> and totient<span class="lean-bracket-1">(</span><span class="lean-number">2</span><span class="lean-bracket-1">)</span> = <span class="lean-number">1</span>
            <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-var" data-type="m&#x27; = 2" title="m&#x27; = 2">hm&#x27;2</span>, <span class="lean-const" data-name="Crystallographic.psi_two" data-signature="Crystallographic.psi_two : psi 2 = 0" data-docs="`psi 2 = 0`: The negation of identity has order 2 in any dimension ≥ 1. " title="Crystallographic.psi_two : psi 2 = 0
`psi 2 = 0`: The negation of identity has order 2 in any dimension ≥ 1. ">psi_two</span>, <span class="lean-const" data-name="Nat.totient_two" data-signature="Nat.totient_two : Nat.totient 2 = 1" title="Nat.totient_two : Nat.totient 2 = 1">Nat.totient_two</span>, <span class="lean-const" data-name="add_zero" data-signature="add_zero.{u} {M : Type u} [AddZeroClass M] (a : M) : a + 0 = a" title="add_zero.{u} {M : Type u} [AddZeroClass M] (a : M) : a + 0 = a">add_zero</span>, <span class="lean-const" data-name="mul_one" data-signature="mul_one.{u} {M : Type u} [MulOneClass M] (a : M) : a * 1 = a" title="mul_one.{u} {M : Type u} [MulOneClass M] (a : M) : a * 1 = a">mul_one</span><span class="lean-bracket-1">]</span>
            <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-var" data-type="psi (p ^ e) ≤ (p ^ e).totient" title="psi (p ^ e) ≤ (p ^ e).totient">hpsi_pe</span>
          <span class="lean-operator">·</span> <span class="lean-comment">-- Case <span class="lean-number">3</span>: Neither is <span class="lean-number">2</span>^<span class="lean-number">1</span>, so both totients &gt;= <span class="lean-number">2</span></span>
            <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="2 ≤ m&#x27;.totient" title="2 ≤ m&#x27;.totient">htot_m&#x27;_ge2</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> <span class="lean-operator">≤</span> <span class="lean-const" data-name="Nat.totient" data-signature="Nat.totient (n : ℕ) : ℕ" data-docs="Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are
coprime with `n`. " title="Nat.totient (n : ℕ) : ℕ
Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are...">Nat.totient</span> <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> :=
              <span class="lean-const" data-name="Crystallographic.two_le_totient_of_two_lt" data-signature="Crystallographic.two_le_totient_of_two_lt (n : ℕ) (hn : 2 &lt; n) : 2 ≤ n.totient" data-docs="Euler&#x27;s totient function is at least 2 for any n &gt; 2. " title="Crystallographic.two_le_totient_of_two_lt (n : ℕ) (hn : 2 &lt; n) : 2 ≤ n.totient
Euler&#x27;s totient function is at least 2 for any n &gt; 2. ">two_le_totient_of_two_lt</span> <span class="lean-var" data-type="ℕ" title="ℕ">m&#x27;</span> <span class="lean-bracket-1">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span> : <span class="lean-number">2</span> &lt; m&#x27;<span class="lean-bracket-1">)</span>
            <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="2 ≤ (p ^ e).totient" title="2 ≤ (p ^ e).totient">htot_pe_ge2</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> <span class="lean-operator">≤</span> <span class="lean-const" data-name="Nat.totient" data-signature="Nat.totient (n : ℕ) : ℕ" data-docs="Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are
coprime with `n`. " title="Nat.totient (n : ℕ) : ℕ
Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are...">Nat.totient</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">e</span><span class="lean-bracket-1">)</span> := <span class="lean-const" data-name="Crystallographic.two_le_totient_primePow" data-signature="Crystallographic.two_le_totient_primePow {p k : ℕ} (hp : Nat.Prime p) (hk : 0 &lt; k) (h : ¬(p = 2 ∧ k = 1)) :
  2 ≤ (p ^ k).totient" title="Crystallographic.two_le_totient_primePow {p k : ℕ} (hp : Nat.Prime p) (hk : 0 &lt; k) (h : ¬(p = 2 ∧ k = 1)) :
  2 ≤ (p ^ k).totient">two_le_totient_primePow</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hp</span> <span class="lean-var" data-type="0 &lt; e" title="0 &lt; e">he_pos</span> <span class="lean-var" data-type="¬(p = 2 ∧ e = 1)" title="¬(p = 2 ∧ e = 1)">h21</span>
            <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-const" data-name="_private.0.Crystallographic.psi_sum_le_totient_prod_of_ge_two" data-signature="Crystallographic.psi_sum_le_totient_prod_of_ge_two {a b : ℕ} (hpsi_a : psi a ≤ a.totient) (hpsi_b : psi b ≤ b.totient)
  (htot_a_ge2 : 2 ≤ a.totient) (htot_b_ge2 : 2 ≤ b.totient) : psi a + psi b ≤ a.totient * b.totient" data-docs="For coprime factors with both totients ≥ 2, psi sum ≤ totient product.

This handles the &quot;composite without 2^1 factor&quot; case in `psi_le_totient`:
when neither factor is 2, both totients are ≥ 2, so the sum of psi values
is bounded by the sum of totients, which is bounded by their product. " title="Crystallographic.psi_sum_le_totient_prod_of_ge_two {a b : ℕ} (hpsi_a : psi a ≤ a.totient) (hpsi_b : psi b ≤ b.totient)
  (htot_a_ge2 : 2 ≤ a.totient) (htot_b_ge2 : 2 ≤ b.totient) : psi a + psi b ≤ a.totient * b.totient
For coprime factors with both totients ≥ 2, psi sum ≤ totient product....">psi_sum_le_totient_prod_of_ge_two</span> <span class="lean-var" data-type="psi (p ^ e) ≤ (p ^ e).totient" title="psi (p ^ e) ≤ (p ^ e).totient">hpsi_pe</span> <span class="lean-var" data-type="psi m&#x27; ≤ m&#x27;.totient" title="psi m&#x27; ≤ m&#x27;.totient">IH_m&#x27;</span> <span class="lean-var" data-type="2 ≤ (p ^ e).totient" title="2 ≤ (p ^ e).totient">htot_pe_ge2</span> <span class="lean-var" data-type="2 ≤ m&#x27;.totient" title="2 ≤ m&#x27;.totient">htot_m&#x27;_ge2</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L168-L251" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:psi-le-totient');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:prime-pow-achieved-of-lcm-eq">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.9</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:prime-pow-achieved-of-lcm-eq">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000022"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0006.html#lem:lcm-factorization-le-sup">Theorem A.0.2</a></li>
          
          <li><a href="sect0006.html#lem:lcm-factorization-le-sup">Theorem A.0.2</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.primePow_achieved_of_lcm_eq" class="lean_decl">Crystallographic.primePow_achieved_of_lcm_eq</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(S\) is a finite set of divisors of \(m\) with \(\mathrm{lcm}(S) = m\), then for each prime \(q\) dividing \(m\), some element \(d \in S\) is divisible by \(q^{\nu _q(m)}\). </p>
<p>In other words, the full \(q\)-power component of \(m\) must be "achieved" by some element of \(S\). This is the key combinatorial fact ensuring that \(\psi (m) \leq \sum _{d \in S} \varphi (d)\).  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000022">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> By contradiction: if all \(d \in S\) have \(\nu _q(d) {\lt} \nu _q(m)\), then \(\nu _q(\mathrm{lcm}(S)) = \sup _{d \in S} \nu _q(d) {\lt} \nu _q(m)\), contradicting \(\mathrm{lcm}(S) = m\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> <span class="lean-const lean-def" data-name="Crystallographic.primePow_achieved_of_lcm_eq" data-signature="Crystallographic.primePow_achieved_of_lcm_eq {m : ℕ} (hm : 0 &lt; m) (S : Finset ℕ) (hS_sub : ∀ d ∈ S, d ∣ m)
  (hS_lcm : S.lcm id = m) (q : ℕ) : q ∈ m.factorization.support → ∃ d ∈ S, q ^ m.factorization q ∣ d" title="Crystallographic.primePow_achieved_of_lcm_eq {m : ℕ} (hm : 0 &lt; m) (S : Finset ℕ) (hS_sub : ∀ d ∈ S, d ∣ m)
  (hS_lcm : S.lcm id = m) (q : ℕ) : q ∈ m.factorization.support → ∃ d ∈ S, q ^ m.factorization q ∣ d">primePow_achieved_of_lcm_eq</span> <span class="lean-bracket-1">{</span><span class="lean-var" data-type="ℕ" title="ℕ">m</span> : ℕ<span class="lean-bracket-1">}</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="0 &lt; m" title="0 &lt; m">hm</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span><span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span> : <span class="lean-const" data-name="Finset" data-signature="Finset.{u_4} (α : Type u_4) : Type u_4" data-docs="`Finset α` is the type of finite sets of elements of `α`. It is implemented
as a multiset (a list up to permutation) which has no duplicate elements. " title="Finset.{u_4} (α : Type u_4) : Type u_4
`Finset α` is the type of finite sets of elements of `α`. It is implemented...">Finset</span> ℕ<span class="lean-bracket-1">)</span>
    <span class="lean-bracket-1">(</span><span class="lean-var" data-type="∀ d ∈ S, d ∣ m" title="∀ d ∈ S, d ∣ m">hS_sub</span> : <span class="lean-operator">∀</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>, <span class="lean-var" data-type="ℕ" title="ℕ">d</span> ∣ <span class="lean-var" data-type="ℕ" title="ℕ">m</span><span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="S.lcm id = m" title="S.lcm id = m">hS_lcm</span> : <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>.<span class="lean-const" data-name="Finset.lcm" data-signature="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α" data-docs="Least common multiple of a finite set " title="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α
Least common multiple of a finite set ">lcm</span> <span class="lean-const" data-name="id" data-signature="id.{u} {α : Sort u} (a : α) : α" data-docs="The identity function. `id` takes an implicit argument `α : Sort u`
(a type in any universe), and an argument `a : α`, and returns `a`.

Although this may look like a useless function, one application of the identity
function is to explicitly put a type on an expression. If `e` has type `T`,
and `T&#x27;` is definitionally equal to `T`, then `@id T&#x27; e` typechecks, and Lean
knows that this expression has type `T&#x27;` rather than `T`. This can make a
difference for typeclass inference, since `T` and `T&#x27;` may have different
typeclass instances on them. `show T&#x27; from e` is sugar for an `@id T&#x27; e`
expression.
" title="id.{u} {α : Sort u} (a : α) : α
The identity function. `id` takes an implicit argument `α : Sort u`...">id</span> = <span class="lean-var" data-type="ℕ" title="ℕ">m</span><span class="lean-bracket-1">)</span> :
    <span class="lean-operator">∀</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span>.<span class="lean-const" data-name="Finsupp.support" data-signature="Finsupp.support.{u_9, u_10} {α : Type u_9} {M : Type u_10} [Zero M] (self : α →₀ M) : Finset α" data-docs="The support of a finitely supported function (aka `Finsupp`). " title="Finsupp.support.{u_9, u_10} {α : Type u_9} {M : Type u_10} [Zero M] (self : α →₀ M) : Finset α
The support of a finitely supported function (aka `Finsupp`). ">support</span>, <span class="lean-operator">∃</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>, <span class="lean-var" data-type="ℕ" title="ℕ">q</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> ∣ <span class="lean-var" data-type="ℕ" title="ℕ">d</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span></code><code class="lean-proof-body">
  <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
" title="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.">intro</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-var" data-type="q ∈ m.factorization.support" title="q ∈ m.factorization.support">hq</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="Nat.Prime q" title="Nat.Prime q">hq_prime</span> := <span class="lean-const" data-name="Nat.prime_of_mem_primeFactors" data-signature="Nat.prime_of_mem_primeFactors {n p : ℕ} (hp : p ∈ n.primeFactors) : Nat.Prime p" title="Nat.prime_of_mem_primeFactors {n p : ℕ} (hp : p ∈ n.primeFactors) : Nat.Prime p">Nat.prime_of_mem_primeFactors</span> <span class="lean-bracket-1">(</span><span class="lean-const" data-name="Nat.support_factorization" data-signature="Nat.support_factorization (n : ℕ) : n.factorization.support = n.primeFactors" data-docs="The support of `n.factorization` is exactly `n.primeFactors`. " title="Nat.support_factorization (n : ℕ) : n.factorization.support = n.primeFactors
The support of `n.factorization` is exactly `n.primeFactors`. ">Nat.support_factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> ▸ <span class="lean-var" data-type="q ∈ m.factorization.support" title="q ∈ m.factorization.support">hq</span><span class="lean-bracket-1">)</span>
  <span class="lean-keyword" data-docs="`by_contra h` proves `⊢ p` by contradiction,
introducing a hypothesis `h : ¬p` and proving `False`.
* If `p` is a negation `¬q`, `h : q` will be introduced instead of `¬¬q`.
* If `p` is decidable, it uses `Decidable.byContradiction` instead of `Classical.byContradiction`.
* If `h` is omitted, the introduced variable will be called `this`.
" title="`by_contra h` proves `⊢ p` by contradiction,">by_contra</span> <span class="lean-var" data-type="¬∃ d ∈ S, q ^ m.factorization q ∣ d" title="¬∃ d ∈ S, q ^ m.factorization q ∣ d">hall</span>
  <span class="lean-keyword" data-docs="Push negations into the conclusion or a hypothesis.
For instance, a hypothesis `h : ¬ ∀ x, ∃ y, x ≤ y` will be transformed by `push_neg at h` into
`h : ∃ x, ∀ y, y &lt; x`. Binder names are preserved.

`push_neg` is a special case of the more general `push` tactic, namely `push Not`.
The `push` tactic can be extended using the `@[push]` attribute. `push` has special-casing
built in for `push Not`, so that it can preserve binder names, and so that `¬ (p ∧ q)` can be
transformed to either `p → ¬ q` (default) or `¬ p ∨ ¬ q` (`push_neg +distrib`).

Tactics that introduce a negation usually have a version that automatically calls `push_neg` on
that negation. These include `by_cases!`, `contrapose!` and `by_contra!`.

Another example: given a hypothesis
```lean
h : ¬ ∀ ε &gt; 0, ∃ δ &gt; 0, ∀ x, |x - x₀| ≤ δ → |f x - y₀| ≤ ε
```
writing `push_neg at h` will turn `h` into
```lean
h : ∃ ε &gt; 0, ∀ δ &gt; 0, ∃ x, |x - x₀| ≤ δ ∧ ε &lt; |f x - y₀|
```
Note that binder names are preserved by this tactic, contrary to what would happen with `simp`
using the relevant lemmas. One can use this tactic at the goal using `push_neg`,
at every hypothesis and the goal using `push_neg at *` or at selected hypotheses and the goal
using say `push_neg at h h&#x27; ⊢`, as usual.
" title="Push negations into the conclusion or a hypothesis.">push_neg</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
" title="Location specifications are used by many tactics that can operate on either the">at</span> <span class="lean-var" data-type="¬∃ d ∈ S, q ^ m.factorization q ∣ d" title="¬∃ d ∈ S, q ^ m.factorization q ∣ d">hall</span>
  <span class="lean-comment">-- All d <span class="lean-operator">∈</span> S have q^</span><span class="lean-bracket-1">{</span>ord_q<span class="lean-bracket-2">(</span>m<span class="lean-bracket-2">)</span><span class="lean-bracket-1">}</span> not dividing d
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="∀ d ∈ S, d.factorization q &lt; m.factorization q" title="∀ d ∈ S, d.factorization q &lt; m.factorization q">hall&#x27;</span> : <span class="lean-operator">∀</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>, <span class="lean-var" data-type="ℕ" title="ℕ">d</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
" title="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.">intro</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="¬q ^ m.factorization q ∣ d" title="¬q ^ m.factorization q ∣ d">hndvd</span> := <span class="lean-var" data-type="∀ d ∈ S, ¬q ^ m.factorization q ∣ d" title="∀ d ∈ S, ¬q ^ m.factorization q ∣ d">hall</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="d ∣ m" title="d ∣ m">hdvd</span> : <span class="lean-var" data-type="ℕ" title="ℕ">d</span> ∣ <span class="lean-var" data-type="ℕ" title="ℕ">m</span> := <span class="lean-var" data-type="∀ d ∈ S, d ∣ m" title="∀ d ∈ S, d ∣ m">hS_sub</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="0 &lt; d" title="0 &lt; d">hd_pos</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">d</span> := <span class="lean-const" data-name="Nat.pos_of_dvd_of_pos" data-signature="Nat.pos_of_dvd_of_pos {m n : ℕ} (H1 : m ∣ n) (H2 : 0 &lt; n) : 0 &lt; m" title="Nat.pos_of_dvd_of_pos {m n : ℕ} (H1 : m ∣ n) (H2 : 0 &lt; n) : 0 &lt; m">Nat.pos_of_dvd_of_pos</span> <span class="lean-var" data-type="d ∣ m" title="d ∣ m">hdvd</span> <span class="lean-var" data-type="0 &lt; m" title="0 &lt; m">hm</span>
    <span class="lean-keyword" data-docs="`by_contra h` proves `⊢ p` by contradiction,
introducing a hypothesis `h : ¬p` and proving `False`.
* If `p` is a negation `¬q`, `h : q` will be introduced instead of `¬¬q`.
* If `p` is decidable, it uses `Decidable.byContradiction` instead of `Classical.byContradiction`.
* If `h` is omitted, the introduced variable will be called `this`.
" title="`by_contra h` proves `⊢ p` by contradiction,">by_contra</span> <span class="lean-var" data-type="¬d.factorization q &lt; m.factorization q" title="¬d.factorization q &lt; m.factorization q">hge</span>
    <span class="lean-keyword" data-docs="Push negations into the conclusion or a hypothesis.
For instance, a hypothesis `h : ¬ ∀ x, ∃ y, x ≤ y` will be transformed by `push_neg at h` into
`h : ∃ x, ∀ y, y &lt; x`. Binder names are preserved.

`push_neg` is a special case of the more general `push` tactic, namely `push Not`.
The `push` tactic can be extended using the `@[push]` attribute. `push` has special-casing
built in for `push Not`, so that it can preserve binder names, and so that `¬ (p ∧ q)` can be
transformed to either `p → ¬ q` (default) or `¬ p ∨ ¬ q` (`push_neg +distrib`).

Tactics that introduce a negation usually have a version that automatically calls `push_neg` on
that negation. These include `by_cases!`, `contrapose!` and `by_contra!`.

Another example: given a hypothesis
```lean
h : ¬ ∀ ε &gt; 0, ∃ δ &gt; 0, ∀ x, |x - x₀| ≤ δ → |f x - y₀| ≤ ε
```
writing `push_neg at h` will turn `h` into
```lean
h : ∃ ε &gt; 0, ∀ δ &gt; 0, ∃ x, |x - x₀| ≤ δ ∧ ε &lt; |f x - y₀|
```
Note that binder names are preserved by this tactic, contrary to what would happen with `simp`
using the relevant lemmas. One can use this tactic at the goal using `push_neg`,
at every hypothesis and the goal using `push_neg at *` or at selected hypotheses and the goal
using say `push_neg at h h&#x27; ⊢`, as usual.
" title="Push negations into the conclusion or a hypothesis.">push_neg</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
" title="Location specifications are used by many tactics that can operate on either the">at</span> <span class="lean-var" data-type="¬d.factorization q &lt; m.factorization q" title="¬d.factorization q &lt; m.factorization q">hge</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> := <span class="lean-bracket-1">(</span><span class="lean-var" data-type="Nat.Prime q" title="Nat.Prime q">hq_prime</span>.<span class="lean-const" data-name="Nat.Prime.pow_dvd_iff_le_factorization" data-signature="Nat.Prime.pow_dvd_iff_le_factorization {p k n : ℕ} (pp : Nat.Prime p) (hn : n ≠ 0) : p ^ k ∣ n ↔ k ≤ n.factorization p" title="Nat.Prime.pow_dvd_iff_le_factorization {p k n : ℕ} (pp : Nat.Prime p) (hn : n ≠ 0) : p ^ k ∣ n ↔ k ≤ n.factorization p">pow_dvd_iff_le_factorization</span> <span class="lean-var" data-type="0 &lt; d" title="0 &lt; d">hd_pos</span>.<span class="lean-const" data-name="LT.lt.ne&#x27;" data-signature="LT.lt.ne&#x27;.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : b &lt; a) : a ≠ b" title="LT.lt.ne&#x27;.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : b &lt; a) : a ≠ b">ne&#x27;</span><span class="lean-bracket-1">)</span>.<span class="lean-const" data-name="Iff.mpr" data-signature="Iff.mpr {a b : Prop} (self : a ↔ b) : b → a" data-docs="Modus ponens for if and only if, reversed. If `a ↔ b` and `b`, then `a`. " title="Iff.mpr {a b : Prop} (self : a ↔ b) : b → a
Modus ponens for if and only if, reversed. If `a ↔ b` and `b`, then `a`. ">mpr</span> <span class="lean-var" data-type="m.factorization q ≤ d.factorization q" title="m.factorization q ≤ d.factorization q">hge</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-var" data-type="¬q ^ m.factorization q ∣ d" title="¬q ^ m.factorization q ∣ d">hndvd</span> <span class="lean-var" data-type="q ^ m.factorization q ∣ d" title="q ^ m.factorization q ∣ d">this</span>
  <span class="lean-comment">-- lcm</span><span class="lean-bracket-1">(</span>S<span class="lean-bracket-1">)</span>.factorization q = sup of d.factorization q, which is &lt; m.factorization q
  <span class="lean-comment">-- This contradicts hS_lcm since lcm</span><span class="lean-bracket-1">(</span>S<span class="lean-bracket-1">)</span> = m requires matching factorizations.
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="S.lcm id ≠ 0" title="S.lcm id ≠ 0">hne_zero</span> : <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>.<span class="lean-const" data-name="Finset.lcm" data-signature="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α" data-docs="Least common multiple of a finite set " title="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α
Least common multiple of a finite set ">lcm</span> <span class="lean-const" data-name="id" data-signature="id.{u} {α : Sort u} (a : α) : α" data-docs="The identity function. `id` takes an implicit argument `α : Sort u`
(a type in any universe), and an argument `a : α`, and returns `a`.

Although this may look like a useless function, one application of the identity
function is to explicitly put a type on an expression. If `e` has type `T`,
and `T&#x27;` is definitionally equal to `T`, then `@id T&#x27; e` typechecks, and Lean
knows that this expression has type `T&#x27;` rather than `T`. This can make a
difference for typeclass inference, since `T` and `T&#x27;` may have different
typeclass instances on them. `show T&#x27; from e` is sugar for an `@id T&#x27; e`
expression.
" title="id.{u} {α : Sort u} (a : α) : α
The identity function. `id` takes an implicit argument `α : Sort u`...">id</span> <span class="lean-operator">≠</span> <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-var" data-type="S.lcm id = m" title="S.lcm id = m">hS_lcm</span><span class="lean-bracket-1">]</span>; <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-var" data-type="0 &lt; m" title="0 &lt; m">hm</span>.<span class="lean-const" data-name="LT.lt.ne&#x27;" data-signature="LT.lt.ne&#x27;.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : b &lt; a) : a ≠ b" title="LT.lt.ne&#x27;.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : b &lt; a) : a ≠ b">ne&#x27;</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="0 &lt; m.factorization q" title="0 &lt; m.factorization q">hk_pos</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> := <span class="lean-const" data-name="Finsupp.mem_support_iff" data-signature="Finsupp.mem_support_iff.{u_1, u_4} {α : Type u_1} {M : Type u_4} [Zero M] {f : α →₀ M} {a : α} : a ∈ f.support ↔ f a ≠ 0" title="Finsupp.mem_support_iff.{u_1, u_4} {α : Type u_1} {M : Type u_4} [Zero M] {f : α →₀ M} {a : α} : a ∈ f.support ↔ f a ≠ 0">Finsupp.mem_support_iff</span>.<span class="lean-const" data-name="Iff.mp" data-signature="Iff.mp {a b : Prop} (self : a ↔ b) : a → b" data-docs="Modus ponens for if and only if. If `a ↔ b` and `a`, then `b`. " title="Iff.mp {a b : Prop} (self : a ↔ b) : a → b
Modus ponens for if and only if. If `a ↔ b` and `a`, then `b`. ">mp</span> <span class="lean-var" data-type="q ∈ m.factorization.support" title="q ∈ m.factorization.support">hq</span> |&gt; <span class="lean-const" data-name="Nat.pos_of_ne_zero" data-signature="Nat.pos_of_ne_zero {n : ℕ} : n ≠ 0 → 0 &lt; n" title="Nat.pos_of_ne_zero {n : ℕ} : n ≠ 0 → 0 &lt; n">Nat.pos_of_ne_zero</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="(S.lcm id).factorization q &lt; m.factorization q" title="(S.lcm id).factorization q &lt; m.factorization q">hfact_q</span> : <span class="lean-bracket-1">(</span><span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>.<span class="lean-const" data-name="Finset.lcm" data-signature="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α" data-docs="Least common multiple of a finite set " title="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α
Least common multiple of a finite set ">lcm</span> <span class="lean-const" data-name="id" data-signature="id.{u} {α : Sort u} (a : α) : α" data-docs="The identity function. `id` takes an implicit argument `α : Sort u`
(a type in any universe), and an argument `a : α`, and returns `a`.

Although this may look like a useless function, one application of the identity
function is to explicitly put a type on an expression. If `e` has type `T`,
and `T&#x27;` is definitionally equal to `T`, then `@id T&#x27; e` typechecks, and Lean
knows that this expression has type `T&#x27;` rather than `T`. This can make a
difference for typeclass inference, since `T` and `T&#x27;` may have different
typeclass instances on them. `show T&#x27; from e` is sugar for an `@id T&#x27; e`
expression.
" title="id.{u} {α : Sort u} (a : α) : α
The identity function. `id` takes an implicit argument `α : Sort u`...">id</span><span class="lean-bracket-1">)</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-comment">-- Show: </span><span class="lean-bracket-1">(</span>S.lcm id<span class="lean-bracket-1">)</span>.factorization q <span class="lean-operator">≤</span> S.sup <span class="lean-bracket-1">(</span>d.factorization q<span class="lean-bracket-1">)</span> &lt; m.factorization q
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="(S.sup fun d =&gt; d.factorization q) &lt; m.factorization q" title="(S.sup fun d =&gt; d.factorization q) &lt; m.factorization q">hsup_lt</span> : <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>.<span class="lean-const" data-name="Finset.sup" data-signature="Finset.sup.{u_2, u_3} {α : Type u_2} {β : Type u_3} [SemilatticeSup α] [OrderBot α] (s : Finset β) (f : β → α) : α" data-docs="Supremum of a finite set: `sup {a, b, c} f = f a ⊔ f b ⊔ f c` " title="Finset.sup.{u_2, u_3} {α : Type u_2} {β : Type u_3} [SemilatticeSup α] [OrderBot α] (s : Finset β) (f : β → α) : α
Supremum of a finite set: `sup {a, b, c} f = f a ⊔ f b ⊔ f c` ">sup</span> <span class="lean-bracket-1">(</span><span class="lean-keyword">fun</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> =&gt; <span class="lean-var" data-type="ℕ" title="ℕ">d</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span><span class="lean-bracket-1">)</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> :=
      <span class="lean-const" data-name="Finset.sup_lt_iff" data-signature="Finset.sup_lt_iff.{u_2, u_5} {α : Type u_2} {ι : Type u_5} [LinearOrder α] [OrderBot α] {s : Finset ι} {f : ι → α}
  {a : α} (ha : ⊥ &lt; a) : s.sup f &lt; a ↔ ∀ b ∈ s, f b &lt; a" title="Finset.sup_lt_iff.{u_2, u_5} {α : Type u_2} {ι : Type u_5} [LinearOrder α] [OrderBot α] {s : Finset ι} {f : ι → α}
  {a : α} (ha : ⊥ &lt; a) : s.sup f &lt; a ↔ ∀ b ∈ s, f b &lt; a">Finset.sup_lt_iff</span> <span class="lean-var" data-type="0 &lt; m.factorization q" title="0 &lt; m.factorization q">hk_pos</span> |&gt;.<span class="lean-const" data-name="Iff.mpr" data-signature="Iff.mpr {a b : Prop} (self : a ↔ b) : b → a" data-docs="Modus ponens for if and only if, reversed. If `a ↔ b` and `b`, then `a`. " title="Iff.mpr {a b : Prop} (self : a ↔ b) : b → a
Modus ponens for if and only if, reversed. If `a ↔ b` and `b`, then `a`. ">mpr</span> <span class="lean-bracket-1">(</span><span class="lean-keyword">fun</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span> =&gt; <span class="lean-var" data-type="∀ d ∈ S, d.factorization q &lt; m.factorization q" title="∀ d ∈ S, d.factorization q &lt; m.factorization q">hall&#x27;</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span><span class="lean-bracket-1">)</span>
    <span class="lean-comment">-- Use extracted lemma for lcm factorization bound</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="∀ d ∈ S, d ≠ 0" title="∀ d ∈ S, d ≠ 0">hS_ne_zero</span> : <span class="lean-operator">∀</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>, <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-operator">≠</span> <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> := <span class="lean-keyword">fun</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span> =&gt;
      <span class="lean-bracket-1">(</span><span class="lean-const" data-name="Nat.pos_of_dvd_of_pos" data-signature="Nat.pos_of_dvd_of_pos {m n : ℕ} (H1 : m ∣ n) (H2 : 0 &lt; n) : 0 &lt; m" title="Nat.pos_of_dvd_of_pos {m n : ℕ} (H1 : m ∣ n) (H2 : 0 &lt; n) : 0 &lt; m">Nat.pos_of_dvd_of_pos</span> <span class="lean-bracket-2">(</span><span class="lean-var" data-type="∀ d ∈ S, d ∣ m" title="∀ d ∈ S, d ∣ m">hS_sub</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span><span class="lean-bracket-2">)</span> <span class="lean-var" data-type="0 &lt; m" title="0 &lt; m">hm</span><span class="lean-bracket-1">)</span>.<span class="lean-const" data-name="LT.lt.ne&#x27;" data-signature="LT.lt.ne&#x27;.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : b &lt; a) : a ≠ b" title="LT.lt.ne&#x27;.{u_1} {α : Type u_1} [Preorder α] {a b : α} (h : b &lt; a) : a ≠ b">ne&#x27;</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-const" data-name="lt_of_le_of_lt" data-signature="lt_of_le_of_lt.{u_1} {α : Type u_1} [Preorder α] {a b c : α} (hab : a ≤ b) (hbc : b &lt; c) : a &lt; c" title="lt_of_le_of_lt.{u_1} {α : Type u_1} [Preorder α] {a b c : α} (hab : a ≤ b) (hbc : b &lt; c) : a &lt; c">lt_of_le_of_lt</span> <span class="lean-bracket-1">(</span><span class="lean-const" data-name="Finset.lcm_factorization_le_sup" data-signature="Finset.lcm_factorization_le_sup.{u_1} {α : Type u_1} [DecidableEq α] (S : Finset α) (f : α → ℕ) (q : ℕ)
  (hS_ne_zero : ∀ x ∈ S, f x ≠ 0) : (S.lcm f).factorization q ≤ S.sup fun x =&gt; (f x).factorization q" data-docs="The factorization of a finset lcm at any prime is at most the supremum. " title="Finset.lcm_factorization_le_sup.{u_1} {α : Type u_1} [DecidableEq α] (S : Finset α) (f : α → ℕ) (q : ℕ)
  (hS_ne_zero : ∀ x ∈ S, f x ≠ 0) : (S.lcm f).factorization q ≤ S.sup fun x =&gt; (f x).factorization q
The factorization of a finset lcm at any prime is at most the supremum. ">Finset.lcm_factorization_le_sup</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span> <span class="lean-const" data-name="id" data-signature="id.{u} {α : Sort u} (a : α) : α" data-docs="The identity function. `id` takes an implicit argument `α : Sort u`
(a type in any universe), and an argument `a : α`, and returns `a`.

Although this may look like a useless function, one application of the identity
function is to explicitly put a type on an expression. If `e` has type `T`,
and `T&#x27;` is definitionally equal to `T`, then `@id T&#x27; e` typechecks, and Lean
knows that this expression has type `T&#x27;` rather than `T`. This can make a
difference for typeclass inference, since `T` and `T&#x27;` may have different
typeclass instances on them. `show T&#x27; from e` is sugar for an `@id T&#x27; e`
expression.
" title="id.{u} {α : Sort u} (a : α) : α
The identity function. `id` takes an implicit argument `α : Sort u`...">id</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-var" data-type="∀ d ∈ S, d ≠ 0" title="∀ d ∈ S, d ≠ 0">hS_ne_zero</span><span class="lean-bracket-1">)</span> <span class="lean-var" data-type="(S.sup fun d =&gt; d.factorization q) &lt; m.factorization q" title="(S.sup fun d =&gt; d.factorization q) &lt; m.factorization q">hsup_lt</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-var" data-type="S.lcm id = m" title="S.lcm id = m">hS_lcm</span><span class="lean-bracket-1">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
" title="Location specifications are used by many tactics that can operate on either the">at</span> <span class="lean-var" data-type="(S.lcm id).factorization q &lt; m.factorization q" title="(S.lcm id).factorization q &lt; m.factorization q">hfact_q</span>
  <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L253-L293" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:prime-pow-achieved-of-lcm-eq');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:finset-nonempty-of-two-le-lcm">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.10</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:finset-nonempty-of-two-le-lcm">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000023"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.Finset.nonempty_of_two_le_lcm" class="lean_decl">Crystallographic.Finset.nonempty_of_two_le_lcm</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(\mathrm{lcm}(S) \geq 2\) for a finite set \(S\) of natural numbers, then \(S\) is nonempty. </p>
<p>This follows immediately from the fact that \(\mathrm{lcm}(\emptyset ) = 1\) by convention.  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000023">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>By contradiction: if \(S = \emptyset \), then \(\mathrm{lcm}(S) = 1 {\lt} 2\), contradicting the hypothesis. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> <span class="lean-const lean-def" data-name="Crystallographic.Finset.nonempty_of_two_le_lcm" data-signature="Crystallographic.Finset.nonempty_of_two_le_lcm {S : Finset ℕ} (hS_lcm_ge2 : 2 ≤ S.lcm id) : S.Nonempty" title="Crystallographic.Finset.nonempty_of_two_le_lcm {S : Finset ℕ} (hS_lcm_ge2 : 2 ≤ S.lcm id) : S.Nonempty">Finset.nonempty_of_two_le_lcm</span> <span class="lean-bracket-1">{</span><span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span> : <span class="lean-const" data-name="Finset" data-signature="Finset.{u_4} (α : Type u_4) : Type u_4" data-docs="`Finset α` is the type of finite sets of elements of `α`. It is implemented
as a multiset (a list up to permutation) which has no duplicate elements. " title="Finset.{u_4} (α : Type u_4) : Type u_4
`Finset α` is the type of finite sets of elements of `α`. It is implemented...">Finset</span> ℕ<span class="lean-bracket-1">}</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="2 ≤ S.lcm id" title="2 ≤ S.lcm id">hS_lcm_ge2</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> <span class="lean-operator">≤</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>.<span class="lean-const" data-name="Finset.lcm" data-signature="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α" data-docs="Least common multiple of a finite set " title="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α
Least common multiple of a finite set ">lcm</span> <span class="lean-const" data-name="id" data-signature="id.{u} {α : Sort u} (a : α) : α" data-docs="The identity function. `id` takes an implicit argument `α : Sort u`
(a type in any universe), and an argument `a : α`, and returns `a`.

Although this may look like a useless function, one application of the identity
function is to explicitly put a type on an expression. If `e` has type `T`,
and `T&#x27;` is definitionally equal to `T`, then `@id T&#x27; e` typechecks, and Lean
knows that this expression has type `T&#x27;` rather than `T`. This can make a
difference for typeclass inference, since `T` and `T&#x27;` may have different
typeclass instances on them. `show T&#x27; from e` is sugar for an `@id T&#x27; e`
expression.
" title="id.{u} {α : Sort u} (a : α) : α
The identity function. `id` takes an implicit argument `α : Sort u`...">id</span><span class="lean-bracket-1">)</span> :
    <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>.<span class="lean-const" data-name="Finset.Nonempty" data-signature="Finset.Nonempty.{u_1} {α : Type u_1} (s : Finset α) : Prop" data-docs="The property `s.Nonempty` expresses the fact that the finset `s` is not empty. It should be used
in theorem assumptions instead of `∃ x, x ∈ s` or `s ≠ ∅` as it gives access to a nice API thanks
to the dot notation. " title="Finset.Nonempty.{u_1} {α : Type u_1} (s : Finset α) : Prop
The property `s.Nonempty` expresses the fact that the finset `s` is not empty. It should be used...">Nonempty</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span></code><code class="lean-proof-body">
  <span class="lean-keyword" data-docs="`by_contra h` proves `⊢ p` by contradiction,
introducing a hypothesis `h : ¬p` and proving `False`.
* If `p` is a negation `¬q`, `h : q` will be introduced instead of `¬¬q`.
* If `p` is decidable, it uses `Decidable.byContradiction` instead of `Classical.byContradiction`.
* If `h` is omitted, the introduced variable will be called `this`.
" title="`by_contra h` proves `⊢ p` by contradiction,">by_contra</span> <span class="lean-var" data-type="¬S.Nonempty" title="¬S.Nonempty">h</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="Finset.not_nonempty_iff_eq_empty" data-signature="Finset.not_nonempty_iff_eq_empty.{u_1} {α : Type u_1} {s : Finset α} : ¬s.Nonempty ↔ s = ∅" title="Finset.not_nonempty_iff_eq_empty.{u_1} {α : Type u_1} {s : Finset α} : ¬s.Nonempty ↔ s = ∅">Finset.not_nonempty_iff_eq_empty</span><span class="lean-bracket-1">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
" title="Location specifications are used by many tactics that can operate on either the">at</span> <span class="lean-var" data-type="¬S.Nonempty" title="¬S.Nonempty">h</span>
  <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-var" data-type="S = ∅" title="S = ∅">h</span>, <span class="lean-const" data-name="Finset.lcm_empty" data-signature="Finset.lcm_empty.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α]
  {f : β → α} : ∅.lcm f = 1" title="Finset.lcm_empty.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α]
  {f : β → α} : ∅.lcm f = 1">Finset.lcm_empty</span><span class="lean-bracket-1">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
" title="Location specifications are used by many tactics that can operate on either the">at</span> <span class="lean-var" data-type="2 ≤ S.lcm id" title="2 ≤ S.lcm id">hS_lcm_ge2</span>
  <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L418-L431" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:finset-nonempty-of-two-le-lcm');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:finset-exists-one-lt-of-two-le-lcm">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.11</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:finset-exists-one-lt-of-two-le-lcm">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000024"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#lem:finset-nonempty-of-two-le-lcm">Theorem 2.0.10</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.Finset.exists_one_lt_of_two_le_lcm" class="lean_decl">Crystallographic.Finset.exists_one_lt_of_two_le_lcm</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(S\) is a finite set of positive integers with \(\mathrm{lcm}(S) \geq 2\), then some element \(d \in S\) satisfies \(d {\gt} 1\). </p>
<p>This is because \(\mathrm{lcm}\) of a set where all elements equal \(1\) would be \(1\).  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000024">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>By contradiction: if all \(d \in S\) satisfy \(d \leq 1\), then since all \(d {\gt} 0\) we have \(d = 1\) for all \(d \in S\). Thus \(\mathrm{lcm}(S) = 1 {\lt} 2\), a contradiction. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> <span class="lean-const lean-def" data-name="Crystallographic.Finset.exists_one_lt_of_two_le_lcm" data-signature="Crystallographic.Finset.exists_one_lt_of_two_le_lcm {S : Finset ℕ} (hS_pos : ∀ d ∈ S, 0 &lt; d)
  (hS_lcm_ge2 : 2 ≤ S.lcm id) : ∃ d ∈ S, 1 &lt; d" title="Crystallographic.Finset.exists_one_lt_of_two_le_lcm {S : Finset ℕ} (hS_pos : ∀ d ∈ S, 0 &lt; d)
  (hS_lcm_ge2 : 2 ≤ S.lcm id) : ∃ d ∈ S, 1 &lt; d">Finset.exists_one_lt_of_two_le_lcm</span> <span class="lean-bracket-1">{</span><span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span> : <span class="lean-const" data-name="Finset" data-signature="Finset.{u_4} (α : Type u_4) : Type u_4" data-docs="`Finset α` is the type of finite sets of elements of `α`. It is implemented
as a multiset (a list up to permutation) which has no duplicate elements. " title="Finset.{u_4} (α : Type u_4) : Type u_4
`Finset α` is the type of finite sets of elements of `α`. It is implemented...">Finset</span> ℕ<span class="lean-bracket-1">}</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="∀ d ∈ S, 0 &lt; d" title="∀ d ∈ S, 0 &lt; d">hS_pos</span> : <span class="lean-operator">∀</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>, <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">d</span><span class="lean-bracket-1">)</span>
    <span class="lean-bracket-1">(</span><span class="lean-var" data-type="2 ≤ S.lcm id" title="2 ≤ S.lcm id">hS_lcm_ge2</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> <span class="lean-operator">≤</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>.<span class="lean-const" data-name="Finset.lcm" data-signature="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α" data-docs="Least common multiple of a finite set " title="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α
Least common multiple of a finite set ">lcm</span> <span class="lean-const" data-name="id" data-signature="id.{u} {α : Sort u} (a : α) : α" data-docs="The identity function. `id` takes an implicit argument `α : Sort u`
(a type in any universe), and an argument `a : α`, and returns `a`.

Although this may look like a useless function, one application of the identity
function is to explicitly put a type on an expression. If `e` has type `T`,
and `T&#x27;` is definitionally equal to `T`, then `@id T&#x27; e` typechecks, and Lean
knows that this expression has type `T&#x27;` rather than `T`. This can make a
difference for typeclass inference, since `T` and `T&#x27;` may have different
typeclass instances on them. `show T&#x27; from e` is sugar for an `@id T&#x27; e`
expression.
" title="id.{u} {α : Sort u} (a : α) : α
The identity function. `id` takes an implicit argument `α : Sort u`...">id</span><span class="lean-bracket-1">)</span> : <span class="lean-operator">∃</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>, <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">d</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span></code><code class="lean-proof-body">
  <span class="lean-keyword" data-docs="`by_contra h` proves `⊢ p` by contradiction,
introducing a hypothesis `h : ¬p` and proving `False`.
* If `p` is a negation `¬q`, `h : q` will be introduced instead of `¬¬q`.
* If `p` is decidable, it uses `Decidable.byContradiction` instead of `Classical.byContradiction`.
* If `h` is omitted, the introduced variable will be called `this`.
" title="`by_contra h` proves `⊢ p` by contradiction,">by_contra</span> <span class="lean-var" data-type="¬∃ d ∈ S, 1 &lt; d" title="¬∃ d ∈ S, 1 &lt; d">hall_le1</span>
  <span class="lean-keyword" data-docs="Push negations into the conclusion or a hypothesis.
For instance, a hypothesis `h : ¬ ∀ x, ∃ y, x ≤ y` will be transformed by `push_neg at h` into
`h : ∃ x, ∀ y, y &lt; x`. Binder names are preserved.

`push_neg` is a special case of the more general `push` tactic, namely `push Not`.
The `push` tactic can be extended using the `@[push]` attribute. `push` has special-casing
built in for `push Not`, so that it can preserve binder names, and so that `¬ (p ∧ q)` can be
transformed to either `p → ¬ q` (default) or `¬ p ∨ ¬ q` (`push_neg +distrib`).

Tactics that introduce a negation usually have a version that automatically calls `push_neg` on
that negation. These include `by_cases!`, `contrapose!` and `by_contra!`.

Another example: given a hypothesis
```lean
h : ¬ ∀ ε &gt; 0, ∃ δ &gt; 0, ∀ x, |x - x₀| ≤ δ → |f x - y₀| ≤ ε
```
writing `push_neg at h` will turn `h` into
```lean
h : ∃ ε &gt; 0, ∀ δ &gt; 0, ∃ x, |x - x₀| ≤ δ ∧ ε &lt; |f x - y₀|
```
Note that binder names are preserved by this tactic, contrary to what would happen with `simp`
using the relevant lemmas. One can use this tactic at the goal using `push_neg`,
at every hypothesis and the goal using `push_neg at *` or at selected hypotheses and the goal
using say `push_neg at h h&#x27; ⊢`, as usual.
" title="Push negations into the conclusion or a hypothesis.">push_neg</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
" title="Location specifications are used by many tactics that can operate on either the">at</span> <span class="lean-var" data-type="¬∃ d ∈ S, 1 &lt; d" title="¬∃ d ∈ S, 1 &lt; d">hall_le1</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="∀ d ∈ S, d = 1" title="∀ d ∈ S, d = 1">hall_eq1</span> : <span class="lean-operator">∀</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>, <span class="lean-var" data-type="ℕ" title="ℕ">d</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> := <span class="lean-keyword">fun</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span> =&gt; <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="0 &lt; d" title="0 &lt; d">hd_pos</span> := <span class="lean-var" data-type="∀ d ∈ S, 0 &lt; d" title="∀ d ∈ S, 0 &lt; d">hS_pos</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="d ≤ 1" title="d ≤ 1">hd_le1</span> := <span class="lean-var" data-type="∀ d ∈ S, d ≤ 1" title="∀ d ∈ S, d ≤ 1">hall_le1</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span>
    <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="S.lcm id = 1" title="S.lcm id = 1">hlcm_eq1</span> : <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>.<span class="lean-const" data-name="Finset.lcm" data-signature="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α" data-docs="Least common multiple of a finite set " title="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α
Least common multiple of a finite set ">lcm</span> <span class="lean-const" data-name="id" data-signature="id.{u} {α : Sort u} (a : α) : α" data-docs="The identity function. `id` takes an implicit argument `α : Sort u`
(a type in any universe), and an argument `a : α`, and returns `a`.

Although this may look like a useless function, one application of the identity
function is to explicitly put a type on an expression. If `e` has type `T`,
and `T&#x27;` is definitionally equal to `T`, then `@id T&#x27; e` typechecks, and Lean
knows that this expression has type `T&#x27;` rather than `T`. This can make a
difference for typeclass inference, since `T` and `T&#x27;` may have different
typeclass instances on them. `show T&#x27; from e` is sugar for an `@id T&#x27; e`
expression.
" title="id.{u} {α : Sort u} (a : α) : α
The identity function. `id` takes an implicit argument `α : Sort u`...">id</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
" title="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.">apply</span> <span class="lean-const" data-name="Nat.eq_one_of_dvd_one" data-signature="Nat.eq_one_of_dvd_one {n : ℕ} (H : n ∣ 1) : n = 1" title="Nat.eq_one_of_dvd_one {n : ℕ} (H : n ∣ 1) : n = 1">Nat.eq_one_of_dvd_one</span>
    <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
" title="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.">apply</span> <span class="lean-const" data-name="Finset.lcm_dvd_iff" data-signature="Finset.lcm_dvd_iff.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α]
  {s : Finset β} {f : β → α} {a : α} : s.lcm f ∣ a ↔ ∀ b ∈ s, f b ∣ a" title="Finset.lcm_dvd_iff.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α]
  {s : Finset β} {f : β → α} {a : α} : s.lcm f ∣ a ↔ ∀ b ∈ s, f b ∣ a">Finset.lcm_dvd_iff</span>.<span class="lean-const" data-name="Iff.mpr" data-signature="Iff.mpr {a b : Prop} (self : a ↔ b) : b → a" data-docs="Modus ponens for if and only if, reversed. If `a ↔ b` and `b`, then `a`. " title="Iff.mpr {a b : Prop} (self : a ↔ b) : b → a
Modus ponens for if and only if, reversed. If `a ↔ b` and `b`, then `a`. ">mpr</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
" title="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.">intro</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="id_eq" data-signature="id_eq.{u_1} {α : Sort u_1} (a : α) : id a = a" data-docs="`id x = x`, as a `@[simp]` lemma. " title="id_eq.{u_1} {α : Sort u_1} (a : α) : id a = a
`id x = x`, as a `@[simp]` lemma. ">id_eq</span>, <span class="lean-var" data-type="∀ d ∈ S, d = 1" title="∀ d ∈ S, d = 1">hall_eq1</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span>, <span class="lean-const" data-name="Nat.one_dvd" data-signature="Nat.one_dvd (n : ℕ) : 1 ∣ n" title="Nat.one_dvd (n : ℕ) : 1 ∣ n">Nat.one_dvd</span><span class="lean-bracket-1">]</span>
  <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L433-L455" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:finset-exists-one-lt-of-two-le-lcm');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:sum-totient-ge-psi">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">2.0.12</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0002.html#lem:sum-totient-ge-psi">#</a>
    
    <a class="icon proof" href="sect0002.html#a0000000025"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    <button class="modal"><svg  class="icon icon-mindmap "><use xlink:href="symbol-defs.svg#icon-mindmap"></use></svg>
</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Uses</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="sect0002.html#psi-def">Definition 2.0.2</a></li>
          
          <li><a href="sect0002.html#lem:psi-le-totient">Theorem 2.0.8</a></li>
          
          <li><a href="sect0002.html#lem:finset-nonempty-of-two-le-lcm">Theorem 2.0.10</a></li>
          
          <li><a href="sect0002.html#lem:finset-exists-one-lt-of-two-le-lcm">Theorem 2.0.11</a></li>
          
          <li><a href="sect0002.html#lem:prime-pow-achieved-of-lcm-eq">Theorem 2.0.9</a></li>
          
          <li><a href="sect0002.html#lem:finset-exists-one-lt-of-two-le-lcm">Theorem 2.0.11</a></li>
          
          <li><a href="sect0002.html#psiPrimePow-def">Definition 2.0.1</a></li>
          
          <li><a href="sect0002.html#lem:psi-le-totient">Theorem 2.0.8</a></li>
          
          <li><a href="sect0002.html#lem:two-le-totient-prime-pow">Theorem 2.0.5</a></li>
          
          <li><a href="sect0002.html#lem:finset-nonempty-of-two-le-lcm">Theorem 2.0.10</a></li>
          
          <li><a href="sect0006.html#lem:sum-le-prod">Theorem A.0.1</a></li>
          
          <li><a href="sect0002.html#lem:prime-pow-achieved-of-lcm-eq">Theorem 2.0.9</a></li>
          
          <li><a href="sect0006.html#lem:primePow-mem-of-lcm-eq">Theorem A.0.3</a></li>
          
          <li><a href="sect0006.html#lem:totient-prod-coprime">Theorem A.0.6</a></li>
          
          <li><a href="sect0006.html#lem:prod-coprime-dvd">Theorem A.0.5</a></li>
          
        </ul>
    
      </div>
    </div>

    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.sum_totient_ge_psi_of_lcm_eq" class="lean_decl">Crystallographic.sum_totient_ge_psi_of_lcm_eq</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>        For any finite set \(S\) of divisors of \(m\) with \(\mathrm{lcm}(S) = m\), we have \(\psi (m) \leq \sum _{d \in S} \varphi (d)\). </p>
<p>For a finite set \(S\) of divisors of \(m\) with \(\mathrm{lcm}(S) = m\), we have \(\sum _{d \in S} \varphi (d) \geq \psi (m)\). This follows from the prime factorization structure: each prime power \(p^k \|  m\) must appear in some \(d \in S\), contributing at least \(\psi _{\mathrm{pp}}(p, k)\). This is the combinatorial heart of the forward direction. The minimum sum is achieved when \(S\) consists of one prime power for each distinct prime in \(m\)’s prime factorization, giving exactly \(\psi (m)\).  - </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000025">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p> For each prime power \(p^k \|  m\), some \(d \in S\) must have \(p^k \mid d\) (since \(\mathrm{lcm}(S) = m\)). The element with maximal \(p\)-valuation contributes at least \(\varphi (p^k) \geq \psi _{\mathrm{pp}}(p, k)\). Summing over distinct prime powers and using non-negativity gives the bound. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> <span class="lean-const lean-def" data-name="Crystallographic.sum_totient_ge_psi_of_lcm_eq" data-signature="Crystallographic.sum_totient_ge_psi_of_lcm_eq (m : ℕ) (hm : 0 &lt; m) (S : Finset ℕ) (hS_sub : ∀ d ∈ S, d ∣ m)
  (hS_lcm : S.lcm id = m) : psi m ≤ ∑ d ∈ S, d.totient" data-docs="Key lemma: For any S ⊆ m.divisors with lcm(S) = m, we have Σ_{d∈S} φ(d) ≥ psi(m).

This is the combinatorial heart of the forward direction. The minimum is achieved when
S consists of one prime power for each distinct prime in m&#x27;s factorization, giving psi(m).

The proof proceeds by showing that any other choice of S either:
1. Includes redundant elements (increasing the sum), or
2. Uses a composite element d covering multiple prime powers, which costs
   φ(d) = Π φ(p^k) ≥ Σ φ(p^k) when each φ(p^k) ≥ 2. " title="Crystallographic.sum_totient_ge_psi_of_lcm_eq (m : ℕ) (hm : 0 &lt; m) (S : Finset ℕ) (hS_sub : ∀ d ∈ S, d ∣ m)
  (hS_lcm : S.lcm id = m) : psi m ≤ ∑ d ∈ S, d.totient
Key lemma: For any S ⊆ m.divisors with lcm(S) = m, we have Σ_{d∈S} φ(d) ≥ psi(m)....">sum_totient_ge_psi_of_lcm_eq</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">m</span> : ℕ<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="0 &lt; m" title="0 &lt; m">hm</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">m</span><span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span> : <span class="lean-const" data-name="Finset" data-signature="Finset.{u_4} (α : Type u_4) : Type u_4" data-docs="`Finset α` is the type of finite sets of elements of `α`. It is implemented
as a multiset (a list up to permutation) which has no duplicate elements. " title="Finset.{u_4} (α : Type u_4) : Type u_4
`Finset α` is the type of finite sets of elements of `α`. It is implemented...">Finset</span> ℕ<span class="lean-bracket-1">)</span>
    <span class="lean-bracket-1">(</span><span class="lean-var" data-type="∀ d ∈ S, d ∣ m" title="∀ d ∈ S, d ∣ m">hS_sub</span> : <span class="lean-operator">∀</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>, <span class="lean-var" data-type="ℕ" title="ℕ">d</span> ∣ <span class="lean-var" data-type="ℕ" title="ℕ">m</span><span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="S.lcm id = m" title="S.lcm id = m">hS_lcm</span> : <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>.<span class="lean-const" data-name="Finset.lcm" data-signature="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α" data-docs="Least common multiple of a finite set " title="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α
Least common multiple of a finite set ">lcm</span> <span class="lean-const" data-name="id" data-signature="id.{u} {α : Sort u} (a : α) : α" data-docs="The identity function. `id` takes an implicit argument `α : Sort u`
(a type in any universe), and an argument `a : α`, and returns `a`.

Although this may look like a useless function, one application of the identity
function is to explicitly put a type on an expression. If `e` has type `T`,
and `T&#x27;` is definitionally equal to `T`, then `@id T&#x27; e` typechecks, and Lean
knows that this expression has type `T&#x27;` rather than `T`. This can make a
difference for typeclass inference, since `T` and `T&#x27;` may have different
typeclass instances on them. `show T&#x27; from e` is sugar for an `@id T&#x27; e`
expression.
" title="id.{u} {α : Sort u} (a : α) : α
The identity function. `id` takes an implicit argument `α : Sort u`...">id</span> = <span class="lean-var" data-type="ℕ" title="ℕ">m</span><span class="lean-bracket-1">)</span> :
    <span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-operator">≤</span> <span class="lean-operator">∑</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>, <span class="lean-const" data-name="Nat.totient" data-signature="Nat.totient (n : ℕ) : ℕ" data-docs="Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are
coprime with `n`. " title="Nat.totient (n : ℕ) : ℕ
Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are...">Nat.totient</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span></code><code class="lean-proof-body">
  <span class="lean-comment">-- If m <span class="lean-operator">∈</span> S, apply helper lemma directly</span>
  <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
" title="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `">by_cases</span> <span class="lean-var" data-type="m ∈ S" title="m ∈ S">hm_in_S</span> : <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>
  <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-const" data-name="Crystallographic.totient_sum_ge_psi_of_mem" data-signature="Crystallographic.totient_sum_ge_psi_of_mem {m : ℕ} (hm : 0 &lt; m) (S : Finset ℕ) (hS_sub : ∀ d ∈ S, d ∣ m)
  (hm_in_S : m ∈ S) : psi m ≤ ∑ d ∈ S, d.totient" data-docs="If m ∈ S, then ∑_{d∈S} φ(d) ≥ psi(m) follows from psi(m) ≤ φ(m) and m contributing to the sum. " title="Crystallographic.totient_sum_ge_psi_of_mem {m : ℕ} (hm : 0 &lt; m) (S : Finset ℕ) (hS_sub : ∀ d ∈ S, d ∣ m)
  (hm_in_S : m ∈ S) : psi m ≤ ∑ d ∈ S, d.totient
If m ∈ S, then ∑_{d∈S} φ(d) ≥ psi(m) follows from psi(m) ≤ φ(m) and m contributing to the sum. ">totient_sum_ge_psi_of_mem</span> <span class="lean-var" data-type="0 &lt; m" title="0 &lt; m">hm</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span> <span class="lean-var" data-type="∀ d ∈ S, d ∣ m" title="∀ d ∈ S, d ∣ m">hS_sub</span> <span class="lean-var" data-type="m ∈ S" title="m ∈ S">hm_in_S</span>
  <span class="lean-comment">-- If m <span class="lean-operator">∉</span> S, we use strong induction on m</span>
  <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
" title="Assuming `x` is a variable in the local context with an inductive type,">induction</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-keyword">using</span> <span class="lean-const" data-name="Nat.strong_induction_on" data-signature="Nat.strong_induction_on {p : ℕ → Prop} (n : ℕ) (h : ∀ (n : ℕ), (∀ m &lt; n, p m) → p n) : p n" title="Nat.strong_induction_on {p : ℕ → Prop} (n : ℕ) (h : ∀ (n : ℕ), (∀ m &lt; n, p m) → p n) : p n">Nat.strong_induction_on</span> <span class="lean-keyword">generalizing</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span> <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
" title="After `with`, there is an optional tactic that runs on all branches, and">with</span>
    | _ <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-var" data-type="∀ m_1 &lt; m, 0 &lt; m_1 → ∀ (S : Finset ℕ), (∀ d ∈ S, d ∣ m_1) → S.lcm id = m_1 → m_1 ∉ S → psi m_1 ≤ ∑ d ∈ S, d.totient" title="∀ m_1 &lt; m, 0 &lt; m_1 → ∀ (S : Finset ℕ), (∀ d ∈ S, d ∣ m_1) → S.lcm id = m_1 → m_1 ∉ S → psi m_1 ≤ ∑ d ∈ S, d.totient">IH</span> =&gt;
    <span class="lean-comment">-- For m = <span class="lean-number">1</span>: psi</span><span class="lean-bracket-1">(</span><span class="lean-number">1</span><span class="lean-bracket-1">)</span> = <span class="lean-number">0</span> <span class="lean-operator">≤</span> any sum
    <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
" title="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `">by_cases</span> <span class="lean-var" data-type="m = 1" title="m = 1">hm_eq1</span> : <span class="lean-var" data-type="ℕ" title="ℕ">m</span> = <span class="lean-expr" data-type="ℕ" title="ℕ">1</span>
    <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-var" data-type="m = 1" title="m = 1">hm_eq1</span>, <span class="lean-const" data-name="Crystallographic.psi_one" data-signature="Crystallographic.psi_one : psi 1 = 0" data-docs="`psi 1 = 0`: The identity matrix has order 1 in any dimension. " title="Crystallographic.psi_one : psi 1 = 0
`psi 1 = 0`: The identity matrix has order 1 in any dimension. ">psi_one</span>, <span class="lean-const" data-name="Nat.zero_le" data-signature="Nat.zero_le (n : ℕ) : 0 ≤ n" title="Nat.zero_le (n : ℕ) : 0 ≤ n">Nat.zero_le</span><span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="2 ≤ m" title="2 ≤ m">hm_ge2</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> <span class="lean-operator">≤</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
" title="The `omega` tactic, for resolving integer and natural linear arithmetic problems.">omega</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="2 ≤ S.lcm id" title="2 ≤ S.lcm id">hS_lcm_ge2</span> : <span class="lean-expr" data-type="ℕ" title="ℕ">2</span> <span class="lean-operator">≤</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>.<span class="lean-const" data-name="Finset.lcm" data-signature="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α" data-docs="Least common multiple of a finite set " title="Finset.lcm.{u_2, u_3} {α : Type u_2} {β : Type u_3} [CancelCommMonoidWithZero α] [NormalizedGCDMonoid α] (s : Finset β)
  (f : β → α) : α
Least common multiple of a finite set ">lcm</span> <span class="lean-const" data-name="id" data-signature="id.{u} {α : Sort u} (a : α) : α" data-docs="The identity function. `id` takes an implicit argument `α : Sort u`
(a type in any universe), and an argument `a : α`, and returns `a`.

Although this may look like a useless function, one application of the identity
function is to explicitly put a type on an expression. If `e` has type `T`,
and `T&#x27;` is definitionally equal to `T`, then `@id T&#x27; e` typechecks, and Lean
knows that this expression has type `T&#x27;` rather than `T`. This can make a
difference for typeclass inference, since `T` and `T&#x27;` may have different
typeclass instances on them. `show T&#x27; from e` is sugar for an `@id T&#x27; e`
expression.
" title="id.{u} {α : Sort u} (a : α) : α
The identity function. `id` takes an implicit argument `α : Sort u`...">id</span> := <span class="lean-var" data-type="S.lcm id = m" title="S.lcm id = m">hS_lcm</span> ▸ <span class="lean-var" data-type="2 ≤ m" title="2 ≤ m">hm_ge2</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="∀ d ∈ S, 0 &lt; d" title="∀ d ∈ S, 0 &lt; d">hS_pos</span> : <span class="lean-operator">∀</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>, <span class="lean-expr" data-type="ℕ" title="ℕ">0</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">d</span> := <span class="lean-keyword">fun</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span> =&gt; <span class="lean-const" data-name="Nat.pos_of_dvd_of_pos" data-signature="Nat.pos_of_dvd_of_pos {m n : ℕ} (H1 : m ∣ n) (H2 : 0 &lt; n) : 0 &lt; m" title="Nat.pos_of_dvd_of_pos {m n : ℕ} (H1 : m ∣ n) (H2 : 0 &lt; n) : 0 &lt; m">Nat.pos_of_dvd_of_pos</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="∀ d ∈ S, d ∣ m" title="∀ d ∈ S, d ∣ m">hS_sub</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span><span class="lean-bracket-1">)</span> <span class="lean-var" data-type="0 &lt; m" title="0 &lt; m">hm</span>
    <span class="lean-comment">-- S is nonempty since lcm</span><span class="lean-bracket-1">(</span>S<span class="lean-bracket-1">)</span> &gt;= <span class="lean-number">2</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="S.Nonempty" title="S.Nonempty">_hS_ne</span> : <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>.<span class="lean-const" data-name="Finset.Nonempty" data-signature="Finset.Nonempty.{u_1} {α : Type u_1} (s : Finset α) : Prop" data-docs="The property `s.Nonempty` expresses the fact that the finset `s` is not empty. It should be used
in theorem assumptions instead of `∃ x, x ∈ s` or `s ≠ ∅` as it gives access to a nice API thanks
to the dot notation. " title="Finset.Nonempty.{u_1} {α : Type u_1} (s : Finset α) : Prop
The property `s.Nonempty` expresses the fact that the finset `s` is not empty. It should be used...">Nonempty</span> := <span class="lean-const" data-name="Crystallographic.Finset.nonempty_of_two_le_lcm" data-signature="Crystallographic.Finset.nonempty_of_two_le_lcm {S : Finset ℕ} (hS_lcm_ge2 : 2 ≤ S.lcm id) : S.Nonempty" title="Crystallographic.Finset.nonempty_of_two_le_lcm {S : Finset ℕ} (hS_lcm_ge2 : 2 ≤ S.lcm id) : S.Nonempty">Finset.nonempty_of_two_le_lcm</span> <span class="lean-var" data-type="2 ≤ S.lcm id" title="2 ≤ S.lcm id">hS_lcm_ge2</span>
    <span class="lean-comment">-- Some element of S is &gt; <span class="lean-number">1</span></span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="∃ d ∈ S, 1 &lt; d" title="∃ d ∈ S, 1 &lt; d">_hS_has_gt1</span> : <span class="lean-operator">∃</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>, <span class="lean-expr" data-type="ℕ" title="ℕ">1</span> &lt; <span class="lean-var" data-type="ℕ" title="ℕ">d</span> := <span class="lean-const" data-name="Crystallographic.Finset.exists_one_lt_of_two_le_lcm" data-signature="Crystallographic.Finset.exists_one_lt_of_two_le_lcm {S : Finset ℕ} (hS_pos : ∀ d ∈ S, 0 &lt; d)
  (hS_lcm_ge2 : 2 ≤ S.lcm id) : ∃ d ∈ S, 1 &lt; d" title="Crystallographic.Finset.exists_one_lt_of_two_le_lcm {S : Finset ℕ} (hS_pos : ∀ d ∈ S, 0 &lt; d)
  (hS_lcm_ge2 : 2 ≤ S.lcm id) : ∃ d ∈ S, 1 &lt; d">Finset.exists_one_lt_of_two_le_lcm</span> <span class="lean-var" data-type="∀ d ∈ S, 0 &lt; d" title="∀ d ∈ S, 0 &lt; d">hS_pos</span> <span class="lean-var" data-type="2 ≤ S.lcm id" title="2 ≤ S.lcm id">hS_lcm_ge2</span>
    <span class="lean-comment">-- Check if m is a prime power</span>
    <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
" title="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `">by_cases</span> <span class="lean-var" data-type="IsPrimePow m" title="IsPrimePow m">hpow</span> : <span class="lean-const" data-name="IsPrimePow" data-signature="IsPrimePow.{u_1} {R : Type u_1} [CommMonoidWithZero R] (n : R) : Prop" data-docs="`n` is a prime power if there is a prime `p` and a positive natural `k` such that `n` can be
written as `p^k`. " title="IsPrimePow.{u_1} {R : Type u_1} [CommMonoidWithZero R] (n : R) : Prop
`n` is a prime power if there is a prime `p` and a positive natural `k` such that `n` can be...">IsPrimePow</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span>
    <span class="lean-operator">·</span> <span class="lean-comment">-- m is a prime power p^k: contradiction since p^k must be in S</span>
      <span class="lean-keyword" data-docs="`exfalso` converts a goal `⊢ tgt` into `⊢ False` by applying `False.elim`. " title="`exfalso` converts a goal `⊢ tgt` into `⊢ False` by applying `False.elim`. ">exfalso</span>
      <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
" title="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.">rw</span> <span class="lean-bracket-1">[</span><span class="lean-const" data-name="isPrimePow_nat_iff" data-signature="isPrimePow_nat_iff (n : ℕ) : IsPrimePow n ↔ ∃ p k, Nat.Prime p ∧ 0 &lt; k ∧ p ^ k = n" title="isPrimePow_nat_iff (n : ℕ) : IsPrimePow n ↔ ∃ p k, Nat.Prime p ∧ 0 &lt; k ∧ p ^ k = n">isPrimePow_nat_iff</span><span class="lean-bracket-1">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
" title="Location specifications are used by many tactics that can operate on either the">at</span> <span class="lean-var" data-type="IsPrimePow m" title="IsPrimePow m">hpow</span>
      <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
" title="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for">obtain</span> <span class="lean-bracket-1">⟨</span><span class="lean-var" data-type="ℕ" title="ℕ">p</span>, <span class="lean-var" data-type="ℕ" title="ℕ">k</span>, <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hp</span>, <span class="lean-var" data-type="0 &lt; k" title="0 &lt; k">hk</span>, <span class="lean-var" data-type="p ^ k = m" title="p ^ k = m">hm_eq</span><span class="lean-bracket-1">⟩</span> := <span class="lean-var" data-type="∃ p k, Nat.Prime p ∧ 0 &lt; k ∧ p ^ k = m" title="∃ p k, Nat.Prime p ∧ 0 &lt; k ∧ p ^ k = m">hpow</span>
      <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-var" data-type="m ∉ S" title="m ∉ S">hm_in_S</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="p ^ k = m" title="p ^ k = m">hm_eq</span> ▸ <span class="lean-const" data-name="Crystallographic.Finset.prime_pow_mem_of_lcm_eq" data-signature="Crystallographic.Finset.prime_pow_mem_of_lcm_eq {p k : ℕ} (hp : Nat.Prime p) (hk : 0 &lt; k) (S : Finset ℕ)
  (hS_sub : ∀ d ∈ S, d ∣ p ^ k) (hS_lcm : S.lcm id = p ^ k) : p ^ k ∈ S" data-docs="For a prime power `p^k`, if a finset `S` of divisors of `p^k` has lcm equal to `p^k`,
then `p^k` must be an element of `S`.

The proof proceeds by contradiction: if `p^k ∉ S`, then every element of `S` is a proper
divisor of `p^k`, hence divides `p^(k-1)`. But then `lcm(S) ∣ p^(k-1) &lt; p^k`, contradicting
that `lcm(S) = p^k`. " title="Crystallographic.Finset.prime_pow_mem_of_lcm_eq {p k : ℕ} (hp : Nat.Prime p) (hk : 0 &lt; k) (S : Finset ℕ)
  (hS_sub : ∀ d ∈ S, d ∣ p ^ k) (hS_lcm : S.lcm id = p ^ k) : p ^ k ∈ S
For a prime power `p^k`, if a finset `S` of divisors of `p^k` has lcm equal to `p^k`,...">Finset.prime_pow_mem_of_lcm_eq</span> <span class="lean-var" data-type="Nat.Prime p" title="Nat.Prime p">hp</span> <span class="lean-var" data-type="0 &lt; k" title="0 &lt; k">hk</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>
        <span class="lean-bracket-2">(</span><span class="lean-keyword">fun</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span> =&gt; <span class="lean-var" data-type="p ^ k = m" title="p ^ k = m">hm_eq</span> ▸ <span class="lean-var" data-type="∀ d ∈ S, d ∣ m" title="∀ d ∈ S, d ∣ m">hS_sub</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-var" data-type="d ∈ S" title="d ∈ S">hd</span><span class="lean-bracket-2">)</span> <span class="lean-bracket-2">(</span><span class="lean-var" data-type="p ^ k = m" title="p ^ k = m">hm_eq</span> ▸ <span class="lean-var" data-type="S.lcm id = m" title="S.lcm id = m">hS_lcm</span><span class="lean-bracket-2">)</span><span class="lean-bracket-1">)</span>
    <span class="lean-operator">·</span> <span class="lean-comment">-- m is not a prime power: use achiever function approach</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="∀ q ∈ m.factorization.support, ∃ d ∈ S, q ^ m.factorization q ∣ d" title="∀ q ∈ m.factorization.support, ∃ d ∈ S, q ^ m.factorization q ∣ d">h_achieves</span> := <span class="lean-const" data-name="Crystallographic.primePow_achieved_of_lcm_eq" data-signature="Crystallographic.primePow_achieved_of_lcm_eq {m : ℕ} (hm : 0 &lt; m) (S : Finset ℕ) (hS_sub : ∀ d ∈ S, d ∣ m)
  (hS_lcm : S.lcm id = m) (q : ℕ) : q ∈ m.factorization.support → ∃ d ∈ S, q ^ m.factorization q ∣ d" title="Crystallographic.primePow_achieved_of_lcm_eq {m : ℕ} (hm : 0 &lt; m) (S : Finset ℕ) (hS_sub : ∀ d ∈ S, d ∣ m)
  (hS_lcm : S.lcm id = m) (q : ℕ) : q ∈ m.factorization.support → ∃ d ∈ S, q ^ m.factorization q ∣ d">primePow_achieved_of_lcm_eq</span> <span class="lean-var" data-type="0 &lt; m" title="0 &lt; m">hm</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span> <span class="lean-var" data-type="∀ d ∈ S, d ∣ m" title="∀ d ∈ S, d ∣ m">hS_sub</span> <span class="lean-var" data-type="S.lcm id = m" title="S.lcm id = m">hS_lcm</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="∀ q ∈ nontrivialPrimes m, ∃ d ∈ S, q ^ m.factorization q ∣ d" title="∀ q ∈ nontrivialPrimes m, ∃ d ∈ S, q ^ m.factorization q ∣ d">h_ach</span> : <span class="lean-operator">∀</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-operator">∈</span> <span class="lean-const" data-name="_private.0.Crystallographic.nontrivialPrimes" data-signature="Crystallographic.nontrivialPrimes (m : ℕ) : Finset ℕ" data-docs="The nontrivial primes of m are those q with q^k || m where (q,k) ≠ (2,1). " title="Crystallographic.nontrivialPrimes (m : ℕ) : Finset ℕ
The nontrivial primes of m are those q with q^k || m where (q,k) ≠ (2,1). ">nontrivialPrimes</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span>, <span class="lean-operator">∃</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>, <span class="lean-var" data-type="ℕ" title="ℕ">q</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> ∣ <span class="lean-var" data-type="ℕ" title="ℕ">d</span> := <span class="lean-keyword">fun</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-var" data-type="q ∈ nontrivialPrimes m" title="q ∈ nontrivialPrimes m">hq</span> =&gt;
        <span class="lean-var" data-type="∀ q ∈ m.factorization.support, ∃ d ∈ S, q ^ m.factorization q ∣ d" title="∀ q ∈ m.factorization.support, ∃ d ∈ S, q ^ m.factorization q ∣ d">h_achieves</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-bracket-1">(</span><span class="lean-const" data-name="Finset.mem_of_mem_filter" data-signature="Finset.mem_of_mem_filter.{u_1} {α : Type u_1} {p : α → Prop} [DecidablePred p] {s : Finset α} (x : α)
  (h : x ∈ Finset.filter p s) : x ∈ s" title="Finset.mem_of_mem_filter.{u_1} {α : Type u_1} {p : α → Prop} [DecidablePred p] {s : Finset α} (x : α)
  (h : x ∈ Finset.filter p s) : x ∈ s">Finset.mem_of_mem_filter</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-var" data-type="q ∈ nontrivialPrimes m" title="q ∈ nontrivialPrimes m">hq</span><span class="lean-bracket-1">)</span>
      <span class="lean-comment">-- Construct achiever function and prove its properties</span>
      <span class="lean-keyword" data-docs="The `let` tactic is for adding definitions to the local context of the main goal.
The definition can be unfolded, unlike definitions introduced by `have`.

* `let x : t := e` adds the definition `x : t := e` if `e` is a term of type `t`.
* `let x := e` uses the type of `e` for `t`.
* `let : t := e` and `let := e` use `this` for the name of the hypothesis.
* `let pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that let only one applicable constructor.
  For example, given `p : α × β × γ`, `let ⟨x, y, z⟩ := p` produces the
  local variables `x : α`, `y : β`, and `z : γ`.
* The syntax `let (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `let` term.

## Properties and relations

* Unlike `have`, it is possible to unfold definitions introduced using `let`, using tactics
  such as `simp`, `dsimp`, `unfold`, and `subst`.
* The `clear_value` tactic turns a `let` definition into a `have` definition after the fact.
  The tactic might fail if the local context depends on the value of the variable.
* The `let` tactic is preferred for data (non-propositions).
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
" title="The `let` tactic is for adding definitions to the local context of the main goal.">let</span> <span class="lean-var" data-type="ℕ → ℕ" title="ℕ → ℕ">achiever</span> : ℕ <span class="lean-operator">→</span> ℕ := <span class="lean-keyword">fun</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> =&gt;
        <span class="lean-keyword" data-docs="&quot;Dependent&quot; if-then-else, normally written via the notation `if h : c then t(h) else e(h)`,
is sugar for `dite c (fun h =&gt; t(h)) (fun h =&gt; e(h))`, and it is the same as
`if c then t else e` except that `t` is allowed to depend on a proof `h : c`,
and `e` can depend on `h : ¬c`. (Both branches use the same name for the hypothesis,
even though it has different types in the two cases.)

We use this to be able to communicate the if-then-else condition to the branches.
For example, `Array.get arr i h` expects a proof `h : i &lt; arr.size` in order to
avoid a bounds check, so you can write `if h : i &lt; arr.size then arr.get i h else ...`
to avoid the bounds check inside the if branch. (Of course in this case we have only
lifted the check into an explicit `if`, but we could also use this proof multiple times
or derive `i &lt; arr.size` from some other proposition that we are checking in the `if`.)
" title="&quot;Dependent&quot; if-then-else, normally written via the notation `if h : c then t(h) else e(h)`,">if</span> <span class="lean-var" data-type="q ∈ nontrivialPrimes m" title="q ∈ nontrivialPrimes m">hq</span> : <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-operator">∈</span> <span class="lean-const" data-name="_private.0.Crystallographic.nontrivialPrimes" data-signature="Crystallographic.nontrivialPrimes (m : ℕ) : Finset ℕ" data-docs="The nontrivial primes of m are those q with q^k || m where (q,k) ≠ (2,1). " title="Crystallographic.nontrivialPrimes (m : ℕ) : Finset ℕ
The nontrivial primes of m are those q with q^k || m where (q,k) ≠ (2,1). ">nontrivialPrimes</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span> <span class="lean-keyword" data-docs="&quot;Dependent&quot; if-then-else, normally written via the notation `if h : c then t(h) else e(h)`,
is sugar for `dite c (fun h =&gt; t(h)) (fun h =&gt; e(h))`, and it is the same as
`if c then t else e` except that `t` is allowed to depend on a proof `h : c`,
and `e` can depend on `h : ¬c`. (Both branches use the same name for the hypothesis,
even though it has different types in the two cases.)

We use this to be able to communicate the if-then-else condition to the branches.
For example, `Array.get arr i h` expects a proof `h : i &lt; arr.size` in order to
avoid a bounds check, so you can write `if h : i &lt; arr.size then arr.get i h else ...`
to avoid the bounds check inside the if branch. (Of course in this case we have only
lifted the check into an explicit `if`, but we could also use this proof multiple times
or derive `i &lt; arr.size` from some other proposition that we are checking in the `if`.)
" title="&quot;Dependent&quot; if-then-else, normally written via the notation `if h : c then t(h) else e(h)`,">then</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="∀ q ∈ nontrivialPrimes m, ∃ d ∈ S, q ^ m.factorization q ∣ d" title="∀ q ∈ nontrivialPrimes m, ∃ d ∈ S, q ^ m.factorization q ∣ d">h_ach</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-var" data-type="q ∈ nontrivialPrimes m" title="q ∈ nontrivialPrimes m">hq</span><span class="lean-bracket-1">)</span>.<span class="lean-const" data-name="Exists.choose" data-signature="Exists.choose.{u_1} {α : Sort u_1} {p : α → Prop} (P : ∃ a, p a) : α" data-docs="Extract an element from an existential statement, using `Classical.choose`. " title="Exists.choose.{u_1} {α : Sort u_1} {p : α → Prop} (P : ∃ a, p a) : α
Extract an element from an existential statement, using `Classical.choose`. ">choose</span> <span class="lean-keyword" data-docs="&quot;Dependent&quot; if-then-else, normally written via the notation `if h : c then t(h) else e(h)`,
is sugar for `dite c (fun h =&gt; t(h)) (fun h =&gt; e(h))`, and it is the same as
`if c then t else e` except that `t` is allowed to depend on a proof `h : c`,
and `e` can depend on `h : ¬c`. (Both branches use the same name for the hypothesis,
even though it has different types in the two cases.)

We use this to be able to communicate the if-then-else condition to the branches.
For example, `Array.get arr i h` expects a proof `h : i &lt; arr.size` in order to
avoid a bounds check, so you can write `if h : i &lt; arr.size then arr.get i h else ...`
to avoid the bounds check inside the if branch. (Of course in this case we have only
lifted the check into an explicit `if`, but we could also use this proof multiple times
or derive `i &lt; arr.size` from some other proposition that we are checking in the `if`.)
" title="&quot;Dependent&quot; if-then-else, normally written via the notation `if h : c then t(h) else e(h)`,">else</span> <span class="lean-expr" data-type="ℕ" title="ℕ">0</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="∀ q ∈ nontrivialPrimes m, achiever q ∈ S" title="∀ q ∈ nontrivialPrimes m, achiever q ∈ S">h_achiever_mem</span> : <span class="lean-operator">∀</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-operator">∈</span> <span class="lean-const" data-name="_private.0.Crystallographic.nontrivialPrimes" data-signature="Crystallographic.nontrivialPrimes (m : ℕ) : Finset ℕ" data-docs="The nontrivial primes of m are those q with q^k || m where (q,k) ≠ (2,1). " title="Crystallographic.nontrivialPrimes (m : ℕ) : Finset ℕ
The nontrivial primes of m are those q with q^k || m where (q,k) ≠ (2,1). ">nontrivialPrimes</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span>, <span class="lean-var" data-type="ℕ → ℕ" title="ℕ → ℕ">achiever</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span> := <span class="lean-keyword">fun</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-var" data-type="q ∈ nontrivialPrimes m" title="q ∈ nontrivialPrimes m">hq</span> =&gt; <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
        <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-var" data-type="ℕ → ℕ" title="ℕ → ℕ">achiever</span>, <span class="lean-const" data-name="dif_pos" data-signature="dif_pos.{u} {c : Prop} {h : Decidable c} (hc : c) {α : Sort u} {t : c → α} {e : ¬c → α} : dite c t e = t hc" title="dif_pos.{u} {c : Prop} {h : Decidable c} (hc : c) {α : Sort u} {t : c → α} {e : ¬c → α} : dite c t e = t hc">dif_pos</span> <span class="lean-var" data-type="q ∈ nontrivialPrimes m" title="q ∈ nontrivialPrimes m">hq</span><span class="lean-bracket-1">]</span>; <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="∀ q ∈ nontrivialPrimes m, ∃ d ∈ S, q ^ m.factorization q ∣ d" title="∀ q ∈ nontrivialPrimes m, ∃ d ∈ S, q ^ m.factorization q ∣ d">h_ach</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-var" data-type="q ∈ nontrivialPrimes m" title="q ∈ nontrivialPrimes m">hq</span><span class="lean-bracket-1">)</span>.<span class="lean-const" data-name="Exists.choose_spec" data-signature="Exists.choose_spec.{u_1} {α : Sort u_1} {p : α → Prop} (P : ∃ a, p a) : p P.choose" data-docs="Show that an element extracted from `P : ∃ a, p a` using `P.choose` satisfies `p`. " title="Exists.choose_spec.{u_1} {α : Sort u_1} {p : α → Prop} (P : ∃ a, p a) : p P.choose
Show that an element extracted from `P : ∃ a, p a` using `P.choose` satisfies `p`. ">choose_spec</span>.<span class="lean-number">1</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

" title="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main g">have</span> <span class="lean-var" data-type="∀ q ∈ nontrivialPrimes m, q ^ m.factorization q ∣ achiever q" title="∀ q ∈ nontrivialPrimes m, q ^ m.factorization q ∣ achiever q">h_achiever_dvd</span> : <span class="lean-operator">∀</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-operator">∈</span> <span class="lean-const" data-name="_private.0.Crystallographic.nontrivialPrimes" data-signature="Crystallographic.nontrivialPrimes (m : ℕ) : Finset ℕ" data-docs="The nontrivial primes of m are those q with q^k || m where (q,k) ≠ (2,1). " title="Crystallographic.nontrivialPrimes (m : ℕ) : Finset ℕ
The nontrivial primes of m are those q with q^k || m where (q,k) ≠ (2,1). ">nontrivialPrimes</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span>, <span class="lean-var" data-type="ℕ" title="ℕ">q</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> ∣ <span class="lean-var" data-type="ℕ → ℕ" title="ℕ → ℕ">achiever</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> :=
        <span class="lean-keyword">fun</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-var" data-type="q ∈ nontrivialPrimes m" title="q ∈ nontrivialPrimes m">hq</span> =&gt; <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. " title="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
" title="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span><span class="lean-var" data-type="ℕ → ℕ" title="ℕ → ℕ">achiever</span>, <span class="lean-const" data-name="dif_pos" data-signature="dif_pos.{u} {c : Prop} {h : Decidable c} (hc : c) {α : Sort u} {t : c → α} {e : ¬c → α} : dite c t e = t hc" title="dif_pos.{u} {c : Prop} {h : Decidable c} (hc : c) {α : Sort u} {t : c → α} {e : ¬c → α} : dite c t e = t hc">dif_pos</span> <span class="lean-var" data-type="q ∈ nontrivialPrimes m" title="q ∈ nontrivialPrimes m">hq</span><span class="lean-bracket-1">]</span>; <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
" title="`exact e` closes the main goal if its target type matches that of `e`.">exact</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="∀ q ∈ nontrivialPrimes m, ∃ d ∈ S, q ^ m.factorization q ∣ d" title="∀ q ∈ nontrivialPrimes m, ∃ d ∈ S, q ^ m.factorization q ∣ d">h_ach</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-var" data-type="q ∈ nontrivialPrimes m" title="q ∈ nontrivialPrimes m">hq</span><span class="lean-bracket-1">)</span>.<span class="lean-const" data-name="Exists.choose_spec" data-signature="Exists.choose_spec.{u_1} {α : Sort u_1} {p : α → Prop} (P : ∃ a, p a) : p P.choose" data-docs="Show that an element extracted from `P : ∃ a, p a` using `P.choose` satisfies `p`. " title="Exists.choose_spec.{u_1} {α : Sort u_1} {p : α → Prop} (P : ∃ a, p a) : p P.choose
Show that an element extracted from `P : ∃ a, p a` using `P.choose` satisfies `p`. ">choose_spec</span>.<span class="lean-number">2</span>
      <span class="lean-comment">-- Apply the fiberwise bound</span>
      <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
" title="Step-wise reasoning over transitive relations.">calc</span> <span class="lean-const" data-name="Crystallographic.psi" data-signature="Crystallographic.psi (m : ℕ) : ℕ" data-docs="The psi function for crystallographic restriction.
psi(m) is the minimum dimension N such that an N×N integer matrix can have order m.

Defined as the sum over prime power factors: if m = prod p_i^{k_i}, then
psi(m) = sum_i (if p_i = 2 and k_i = 1 then 0 else phi(p_i^{k_i})) " title="Crystallographic.psi (m : ℕ) : ℕ
The psi function for crystallographic restriction....">psi</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span>
          = <span class="lean-operator">∑</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span> <span class="lean-operator">∈</span> <span class="lean-const" data-name="_private.0.Crystallographic.nontrivialPrimes" data-signature="Crystallographic.nontrivialPrimes (m : ℕ) : Finset ℕ" data-docs="The nontrivial primes of m are those q with q^k || m where (q,k) ≠ (2,1). " title="Crystallographic.nontrivialPrimes (m : ℕ) : Finset ℕ
The nontrivial primes of m are those q with q^k || m where (q,k) ≠ (2,1). ">nontrivialPrimes</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span>, <span class="lean-const" data-name="Nat.totient" data-signature="Nat.totient (n : ℕ) : ℕ" data-docs="Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are
coprime with `n`. " title="Nat.totient (n : ℕ) : ℕ
Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are...">Nat.totient</span> <span class="lean-bracket-1">(</span><span class="lean-var" data-type="ℕ" title="ℕ">q</span> ^ <span class="lean-var" data-type="ℕ" title="ℕ">m</span>.<span class="lean-const" data-name="Nat.factorization" data-signature="Nat.factorization (n : ℕ) : ℕ →₀ ℕ" data-docs="`n.factorization` is the finitely supported function `ℕ →₀ ℕ`
mapping each prime factor of `n` to its multiplicity in `n`. " title="Nat.factorization (n : ℕ) : ℕ →₀ ℕ
`n.factorization` is the finitely supported function `ℕ →₀ ℕ`...">factorization</span> <span class="lean-var" data-type="ℕ" title="ℕ">q</span><span class="lean-bracket-1">)</span> :=
            <span class="lean-const" data-name="Crystallographic.psi_eq_sum_nontrivial_totients" data-signature="Crystallographic.psi_eq_sum_nontrivial_totients (m : ℕ) :
  psi m = ∑ q ∈ nontrivialPrimes m, (q ^ m.factorization q).totient" data-docs="psi(m) equals the sum of φ(q^{ord_q(m)}) over nontrivial primes q of m.
This rewrites psi in terms of the filtered factorization support. " title="Crystallographic.psi_eq_sum_nontrivial_totients (m : ℕ) :
  psi m = ∑ q ∈ nontrivialPrimes m, (q ^ m.factorization q).totient
psi(m) equals the sum of φ(q^{ord_q(m)}) over nontrivial primes q of m....">psi_eq_sum_nontrivial_totients</span> <span class="lean-var" data-type="ℕ" title="ℕ">m</span>
        _ <span class="lean-operator">≤</span> <span class="lean-operator">∑</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> <span class="lean-operator">∈</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span>, <span class="lean-const" data-name="Nat.totient" data-signature="Nat.totient (n : ℕ) : ℕ" data-docs="Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are
coprime with `n`. " title="Nat.totient (n : ℕ) : ℕ
Euler&#x27;s totient function. This counts the number of naturals strictly less than `n` which are...">Nat.totient</span> <span class="lean-var" data-type="ℕ" title="ℕ">d</span> :=
            <span class="lean-const" data-name="Crystallographic.sum_nontrivial_totients_le_sum_totients" data-signature="Crystallographic.sum_nontrivial_totients_le_sum_totients {m : ℕ} (S : Finset ℕ) (hS_pos : ∀ d ∈ S, 0 &lt; d)
  (achiever : ℕ → ℕ) (h_achiever_mem : ∀ q ∈ nontrivialPrimes m, achiever q ∈ S)
  (h_achiever_dvd : ∀ q ∈ nontrivialPrimes m, q ^ m.factorization q ∣ achiever q) :
  ∑ q ∈ nontrivialPrimes m, (q ^ m.factorization q).totient ≤ ∑ d ∈ S, d.totient" data-docs="For a finite set S of divisors of m with achiever function mapping nontrivial primes
to elements of S, the sum of φ(q^k) over nontrivial primes is bounded by ∑_{d∈S} φ(d).

This is the fiberwise bound: we partition nontrivial primes by their achiever,
and for each fiber, the sum of φ(q^k) is bounded by φ(d) where d is the achiever. " title="Crystallographic.sum_nontrivial_totients_le_sum_totients {m : ℕ} (S : Finset ℕ) (hS_pos : ∀ d ∈ S, 0 &lt; d)
  (achiever : ℕ → ℕ) (h_achiever_mem : ∀ q ∈ nontrivialPrimes m, achiever q ∈ S)
  (h_achiever_dvd : ∀ q ∈ nontrivialPrimes m, q ^ m.factorization q ∣ achiever q) :
  ∑ q ∈ nontrivialPrimes m, (q ^ m.factorization q).totient ≤ ∑ d ∈ S, d.totient
For a finite set S of divisors of m with achiever function mapping nontrivial primes...">sum_nontrivial_totients_le_sum_totients</span> <span class="lean-var" data-type="Finset ℕ" title="Finset ℕ">S</span> <span class="lean-var" data-type="∀ d ∈ S, 0 &lt; d" title="∀ d ∈ S, 0 &lt; d">hS_pos</span> <span class="lean-var" data-type="ℕ → ℕ" title="ℕ → ℕ">achiever</span> <span class="lean-var" data-type="∀ q ∈ nontrivialPrimes m, achiever q ∈ S" title="∀ q ∈ nontrivialPrimes m, achiever q ∈ S">h_achiever_mem</span> <span class="lean-var" data-type="∀ q ∈ nontrivialPrimes m, q ^ m.factorization q ∣ achiever q" title="∀ q ∈ nontrivialPrimes m, q ^ m.factorization q ∣ achiever q">h_achiever_dvd</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Psi/Bounds.lean#L457-L524" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:sum-totient-ge-psi');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>



</div> <!--main-text -->
</div> <!-- content-wrapper -->
</div> <!-- content -->
</div> <!-- wrapper -->

<nav class="prev_up_next">
  <svg  id="showmore-minus" class="icon icon-eye-minus showmore"><use xlink:href="symbol-defs.svg#icon-eye-minus"></use></svg>

  <svg  id="showmore-plus" class="icon icon-eye-plus showmore"><use xlink:href="symbol-defs.svg#icon-eye-plus"></use></svg>

  <a href="sect0001.html" title="Introduction"><svg  class="icon icon-arrow-left "><use xlink:href="symbol-defs.svg#icon-arrow-left"></use></svg>
</a>
  <a href="index.html" title="Crystallographic Restriction Theorem"><svg  class="icon icon-arrow-up "><use xlink:href="symbol-defs.svg#icon-arrow-up"></use></svg>
</a>
  <a href="sect0003.html" title="Integer Matrix Orders"><svg  class="icon icon-arrow-right "><use xlink:href="symbol-defs.svg#icon-arrow-right"></use></svg>
</a>
</nav>

<script type="text/javascript" src="js/jquery.min.js"></script>
<script type="text/javascript" src="js/plastex.js"></script>
<script type="text/javascript" src="js/svgxuse.js"></script>
<script type="text/javascript" src="js/js.cookie.min.js"></script>
<script type="text/javascript" src="js/showmore.js"></script>
</body>
</html>