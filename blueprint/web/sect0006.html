<!DOCTYPE html>
<html lang="en">
<head>
<script>
  MathJax = { 
    tex: {
		    inlineMath: [['$','$'], ['\\(','\\)']]
	} }
</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
<meta name="generator" content="plasTeX" />
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Appendix</title>
<link rel="prev" href="sect0005.html" title="The Crystallographic Restriction Theorem" />
<link rel="up" href="index.html" title="Crystallographic Restriction Theorem" />
<link rel="stylesheet" href="styles/theme-blue.css" />
<link rel="stylesheet" href="styles/showmore.css" />
<link rel="stylesheet" href="styles/blueprint.css" />
<link rel="stylesheet" href="styles/amsthm.css" />
<link rel="stylesheet" href="styles/style.css" />
</head>

<body>
<header>
<svg  id="toc-toggle" class="icon icon-list-numbered "><use xlink:href="symbol-defs.svg#icon-list-numbered"></use></svg>
<h1 id="doc_title"><a href="index.html">Crystallographic Restriction Theorem</a></h1>
</header>

<div class="wrapper">
<nav class="toc">
<ul class="sub-toc-0">
<li class="">
  <a href="sect0001.html"><span class="toc_ref">1</span> <span class="toc_entry">Introduction</span></a>
 </li>
<li class="">
  <a href="sect0002.html"><span class="toc_ref">2</span> <span class="toc_entry">The Psi Function</span></a>
 </li>
<li class="">
  <a href="sect0003.html"><span class="toc_ref">3</span> <span class="toc_entry">Integer Matrix Orders</span></a>
 </li>
<li class="">
  <a href="sect0004.html"><span class="toc_ref">4</span> <span class="toc_entry">Companion Matrices</span></a>
 </li>
<li class="">
  <a href="sect0005.html"><span class="toc_ref">5</span> <span class="toc_entry">The Crystallographic Restriction Theorem</span></a>
 </li>
<li class=" active current">
  <a href="sect0006.html"><span class="toc_ref">A</span> <span class="toc_entry">Appendix</span></a>
 </li>
<li ><a href="dep_graph_document.html">Dependency graph</a></li>
</ul>
</nav>

<div class="content">
<div class="content-wrapper">


<div class="main-text">
<h1 id="a0000000007">A Appendix</h1>
<p>This appendix collects technical lemmas used throughout the proof. These are general-purpose results about finite sets, coprime products, Euler’s totient function, and matrix orders that support the main arguments. </p>
<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:sum-le-prod">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">A.0.1</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0006.html#lem:sum-le-prod">#</a>
    
    <a class="icon proof" href="sect0006.html#a0000000063"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Finset.sum_le_prod_of_all_ge_two" class="lean_decl">Finset.sum_le_prod_of_all_ge_two</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       For a finite set where all values \(\geq 2\), the sum is at most the product. </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000063">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>By induction on the size of the finite set. Base case: empty sum is \(0 \leq 1\) (empty product). Inductive step: if \(\sum _{x \in s} f(x) \leq \prod _{x \in s} f(x)\) and \(f(a) \geq 2\), then \(\sum _{x \in s \cup \{ a\} } f(x) = f(a) + \sum _s f \leq f(a) \cdot \prod _s f \leq \prod _{s \cup \{ a\} } f\) using \(1 + y \leq 2y\) for \(y \geq 1\) and \(f(a) \geq 2\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> sum_le_prod_of_all_ge_two <span class="lean-bracket-1">{</span>α : <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-bracket-1">}</span> <span class="lean-bracket-1">[</span>DecidableEq α<span class="lean-bracket-1">]</span>
    <span class="lean-bracket-1">(</span>s : Finset α<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span>f : α <span class="lean-operator">→</span> ℕ<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span>hf : <span class="lean-operator">∀</span> x <span class="lean-operator">∈</span> s, <span class="lean-number">2</span> <span class="lean-operator">≤</span> f x<span class="lean-bracket-1">)</span> :
    <span class="lean-operator">∑</span> x <span class="lean-operator">∈</span> s, f x <span class="lean-operator">≤</span> <span class="lean-operator">∏</span> x <span class="lean-operator">∈</span> s, f x :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
">induction</span> s <span class="lean-keyword">using</span> Finset.induction <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
">with</span>
  | empty =&gt; <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span>
  | @insert a s&#x27; ha IH =&gt;
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>Finset.sum_insert ha, Finset.prod_insert ha<span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> h2_a : <span class="lean-number">2</span> <span class="lean-operator">≤</span> f a := hf a <span class="lean-bracket-1">(</span>Finset.mem_insert_self a s&#x27;<span class="lean-bracket-1">)</span>
    <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> hs_empty : s&#x27; = <span class="lean-operator">∅</span>
    <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-bracket-1">[</span>hs_empty<span class="lean-bracket-1">]</span>
    <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hs_nonempty : s&#x27;.Nonempty := Finset.nonempty_of_ne_empty hs_empty
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hs&#x27;_ge2 : <span class="lean-operator">∀</span> x <span class="lean-operator">∈</span> s&#x27;, <span class="lean-number">2</span> <span class="lean-operator">≤</span> f x := <span class="lean-keyword">fun</span> x hx =&gt; hf x <span class="lean-bracket-1">(</span>Finset.mem_insert_of_mem hx<span class="lean-bracket-1">)</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> h2_prod : <span class="lean-number">2</span> <span class="lean-operator">≤</span> <span class="lean-operator">∏</span> x <span class="lean-operator">∈</span> s&#x27;, f x := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
        <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-bracket-1">⟨</span>b, hb<span class="lean-bracket-1">⟩</span> := hs_nonempty
        <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> h1 : <span class="lean-operator">∀</span> x <span class="lean-operator">∈</span> s&#x27;, <span class="lean-number">1</span> <span class="lean-operator">≤</span> f x := <span class="lean-keyword">fun</span> x hx =&gt; Nat.one_le_of_lt <span class="lean-bracket-1">(</span>hs&#x27;_ge2 x hx<span class="lean-bracket-1">)</span>
        <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
">calc</span> <span class="lean-operator">∏</span> x <span class="lean-operator">∈</span> s&#x27;, f x <span class="lean-operator">≥</span> f b := Finset.single_le_prod&#x27; h1 hb
          _ <span class="lean-operator">≥</span> <span class="lean-number">2</span> := hs&#x27;_ge2 b hb
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> IH&#x27; := IH hs&#x27;_ge2
      <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
">calc</span> f a + <span class="lean-operator">∑</span> x <span class="lean-operator">∈</span> s&#x27;, f x
          <span class="lean-operator">≤</span> f a + <span class="lean-operator">∏</span> x <span class="lean-operator">∈</span> s&#x27;, f x := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
        _ <span class="lean-operator">≤</span> f a * <span class="lean-operator">∏</span> x <span class="lean-operator">∈</span> s&#x27;, f x := Nat.add_le_mul h2_a h2_prod</code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/Lemmas.lean#L41-L74" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:sum-le-prod');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:lcm-factorization-le-sup">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">A.0.2</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0006.html#lem:lcm-factorization-le-sup">#</a>
    
    <a class="icon proof" href="sect0006.html#a0000000064"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Finset.lcm_factorization_le_sup" class="lean_decl">Finset.lcm_factorization_le_sup</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       The factorization of \(\mathrm{lcm}(S)\) at prime \(q\) is bounded by \(\sup _{x \in S} v_q(x)\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000064">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>The \(q\)-adic valuation of \(\mathrm{lcm}(S)\) is the maximum of \(q\)-adic valuations over elements of \(S\). This follows from the definition of lcm via factorization: \(v_q(\mathrm{lcm}(S)) = \sup _{x \in S} v_q(x)\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> lcm_factorization_le_sup <span class="lean-bracket-1">{</span>α : <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-bracket-1">}</span> <span class="lean-bracket-1">[</span>DecidableEq α<span class="lean-bracket-1">]</span> <span class="lean-bracket-1">(</span>S : Finset α<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span>f : α <span class="lean-operator">→</span> ℕ<span class="lean-bracket-1">)</span>
    <span class="lean-bracket-1">(</span>q : ℕ<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span>hS_ne_zero : <span class="lean-operator">∀</span> x <span class="lean-operator">∈</span> S, f x <span class="lean-operator">≠</span> <span class="lean-number">0</span><span class="lean-bracket-1">)</span> :
    <span class="lean-bracket-1">(</span>S.lcm f<span class="lean-bracket-1">)</span>.factorization q <span class="lean-operator">≤</span> S.sup <span class="lean-bracket-1">(</span><span class="lean-keyword">fun</span> x =&gt; <span class="lean-bracket-2">(</span>f x<span class="lean-bracket-2">)</span>.factorization q<span class="lean-bracket-1">)</span> :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
">induction</span> S <span class="lean-keyword">using</span> Finset.induction <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
">with</span>
  | empty =&gt;
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span>Finset.lcm_empty, Nat.factorization_one, Finsupp.coe_zero, Pi.zero_apply,
      Finset.sup_empty, bot_eq_zero, le_refl<span class="lean-bracket-1">]</span>
  | @insert a s&#x27; ha IH =&gt;
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span>Finset.lcm_insert, Finset.sup_insert<span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> hs&#x27;_empty : s&#x27; = <span class="lean-operator">∅</span>
    <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-bracket-1">[</span>hs&#x27;_empty<span class="lean-bracket-1">]</span>
    <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hs&#x27;_ne_zero : s&#x27;.lcm f <span class="lean-operator">≠</span> <span class="lean-number">0</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
        <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>ne_eq, Finset.lcm_eq_zero_iff<span class="lean-bracket-1">]</span>
        <span class="lean-keyword" data-docs="Push negations into the conclusion or a hypothesis.
For instance, a hypothesis `h : ¬ ∀ x, ∃ y, x ≤ y` will be transformed by `push_neg at h` into
`h : ∃ x, ∀ y, y &lt; x`. Binder names are preserved.

`push_neg` is a special case of the more general `push` tactic, namely `push Not`.
The `push` tactic can be extended using the `@[push]` attribute. `push` has special-casing
built in for `push Not`, so that it can preserve binder names, and so that `¬ (p ∧ q)` can be
transformed to either `p → ¬ q` (default) or `¬ p ∨ ¬ q` (`push_neg +distrib`).

Tactics that introduce a negation usually have a version that automatically calls `push_neg` on
that negation. These include `by_cases!`, `contrapose!` and `by_contra!`.

Another example: given a hypothesis
```lean
h : ¬ ∀ ε &gt; 0, ∃ δ &gt; 0, ∀ x, |x - x₀| ≤ δ → |f x - y₀| ≤ ε
```
writing `push_neg at h` will turn `h` into
```lean
h : ∃ ε &gt; 0, ∀ δ &gt; 0, ∃ x, |x - x₀| ≤ δ ∧ ε &lt; |f x - y₀|
```
Note that binder names are preserved by this tactic, contrary to what would happen with `simp`
using the relevant lemmas. One can use this tactic at the goal using `push_neg`,
at every hypothesis and the goal using `push_neg at *` or at selected hypotheses and the goal
using say `push_neg at h h&#x27; ⊢`, as usual.
">push_neg</span>
        <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> x hx
        <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> hS_ne_zero x <span class="lean-bracket-1">(</span>Finset.mem_insert_of_mem hx<span class="lean-bracket-1">)</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> ha_ne_zero : f a <span class="lean-operator">≠</span> <span class="lean-number">0</span> := hS_ne_zero a <span class="lean-bracket-1">(</span>Finset.mem_insert_self a s&#x27;<span class="lean-bracket-1">)</span>
      <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>lcm_eq_nat_lcm, Nat.factorization_lcm ha_ne_zero hs&#x27;_ne_zero<span class="lean-bracket-1">]</span>
      <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-bracket-1">[</span>Finsupp.sup_apply, sup_le_iff<span class="lean-bracket-1">]</span>
      <span class="lean-keyword" data-docs="If the main goal&#x27;s target type is an inductive type, `constructor` solves it with
the first matching constructor, or else fails.
">constructor</span>
      <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> le_sup_left
      <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hIH := IH <span class="lean-bracket-1">(</span><span class="lean-keyword">fun</span> x hx =&gt; hS_ne_zero x <span class="lean-bracket-2">(</span>Finset.mem_insert_of_mem hx<span class="lean-bracket-2">)</span><span class="lean-bracket-1">)</span>
        <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> le_trans hIH le_sup_right</code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/Lemmas.lean#L78-L106" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:lcm-factorization-le-sup');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:primePow-mem-of-lcm-eq">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">A.0.3</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0006.html#lem:primePow-mem-of-lcm-eq">#</a>
    
    <a class="icon proof" href="sect0006.html#a0000000065"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.Finset.prime_pow_mem_of_lcm_eq" class="lean_decl">Crystallographic.Finset.prime_pow_mem_of_lcm_eq</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(\mathrm{lcm}(S) = p^k\) and all elements of \(S\) divide \(p^k\), then \(p^k \in S\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000065">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>Since \(\mathrm{lcm}(S) = p^k\) and all elements divide \(p^k\), each element has form \(p^j\) for some \(j \leq k\). Taking lcm over these powers gives \(p^{\max _j} = p^k\), so some element must have \(j = k\), meaning \(p^k \in S\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">lemma</span> Finset.prime_pow_mem_of_lcm_eq <span class="lean-bracket-1">{</span>p k : ℕ<span class="lean-bracket-1">}</span> <span class="lean-bracket-1">(</span>hp : p.Prime<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span>hk : <span class="lean-number">0</span> &lt; k<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span>S : Finset ℕ<span class="lean-bracket-1">)</span>
    <span class="lean-bracket-1">(</span>hS_sub : <span class="lean-operator">∀</span> d <span class="lean-operator">∈</span> S, d ∣ p ^ k<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span>hS_lcm : S.lcm id = p ^ k<span class="lean-bracket-1">)</span> :
    p ^ k <span class="lean-operator">∈</span> S :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="`by_contra h` proves `⊢ p` by contradiction,
introducing a hypothesis `h : ¬p` and proving `False`.
* If `p` is a negation `¬q`, `h : q` will be introduced instead of `¬¬q`.
* If `p` is decidable, it uses `Decidable.byContradiction` instead of `Classical.byContradiction`.
* If `h` is omitted, the introduced variable will be called `this`.
">by_contra</span> hm_not_in
  <span class="lean-comment">-- All elements of S are proper divisors of p^k, so they divide p^</span><span class="lean-bracket-1">(</span>k-<span class="lean-number">1</span><span class="lean-bracket-1">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hall_lt : <span class="lean-operator">∀</span> d <span class="lean-operator">∈</span> S, d &lt; p ^ k := <span class="lean-keyword">fun</span> d hd =&gt;
    Nat.lt_of_le_of_ne <span class="lean-bracket-1">(</span>Nat.le_of_dvd <span class="lean-bracket-2">(</span>Nat.pow_pos hp.pos<span class="lean-bracket-2">)</span> <span class="lean-bracket-2">(</span>hS_sub d hd<span class="lean-bracket-2">)</span><span class="lean-bracket-1">)</span>
      <span class="lean-bracket-1">(</span><span class="lean-keyword">fun</span> heq =&gt; hm_not_in <span class="lean-bracket-2">(</span>heq ▸ hd<span class="lean-bracket-2">)</span><span class="lean-bracket-1">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hall_le : <span class="lean-operator">∀</span> d <span class="lean-operator">∈</span> S, d ∣ p ^ <span class="lean-bracket-1">(</span>k - <span class="lean-number">1</span><span class="lean-bracket-1">)</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> d hd
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hdvd := hS_sub d hd
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hd_lt := hall_lt d hd
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hpr : Prime p := Nat.Prime.prime hp
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>dvd_prime_pow hpr<span class="lean-bracket-1">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hdvd
    <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-bracket-1">⟨</span>j, _, hassoc<span class="lean-bracket-1">⟩</span> := hdvd
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hd_eq := associated_iff_eq.mp hassoc
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>hd_eq<span class="lean-bracket-1">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hd_lt
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hj_lt : j &lt; k := <span class="lean-bracket-1">(</span>Nat.pow_lt_pow_iff_right hp.one_lt<span class="lean-bracket-1">)</span>.mp hd_lt
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hj_le : j <span class="lean-operator">≤</span> k - <span class="lean-number">1</span> := Nat.lt_succ_iff.mp <span class="lean-bracket-1">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span><span class="lean-bracket-1">)</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>hd_eq<span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> Nat.pow_dvd_pow p hj_le
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hlcm_le : S.lcm id ∣ p ^ <span class="lean-bracket-1">(</span>k - <span class="lean-number">1</span><span class="lean-bracket-1">)</span> := Finset.lcm_dvd_iff.mpr <span class="lean-bracket-1">(</span><span class="lean-keyword">fun</span> d hd =&gt; hall_le d hd<span class="lean-bracket-1">)</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>hS_lcm<span class="lean-bracket-1">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> hlcm_le
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hle : p ^ k <span class="lean-operator">≤</span> p ^ <span class="lean-bracket-1">(</span>k - <span class="lean-number">1</span><span class="lean-bracket-1">)</span> := Nat.le_of_dvd <span class="lean-bracket-1">(</span>Nat.pow_pos hp.pos<span class="lean-bracket-1">)</span> hlcm_le
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hpow_strict : p ^ <span class="lean-bracket-1">(</span>k - <span class="lean-number">1</span><span class="lean-bracket-1">)</span> &lt; p ^ k :=
    Nat.pow_lt_pow_right hp.one_lt <span class="lean-bracket-1">(</span>Nat.sub_lt hk Nat.one_pos<span class="lean-bracket-1">)</span>
  <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/Lemmas.lean#L114-L151" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:primePow-mem-of-lcm-eq');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:totient-ge-two">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">A.0.4</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0006.html#lem:totient-ge-two">#</a>
    
    <a class="icon proof" href="sect0006.html#a0000000066"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.two_le_totient_of_two_lt" class="lean_decl">Crystallographic.two_le_totient_of_two_lt</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       For \(n {\gt} 2\), we have \(\varphi (n) \geq 2\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000066">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>Since \(n {\gt} 2\), we have \(n \neq 1\) and \(n \neq 2\). By the fact that \(\varphi (n) = 1\) if and only if \(n \in \{ 1, 2\} \), we conclude that \(\varphi (n) \neq 1\). Also \(\varphi (n) \neq 0\) since \(n {\gt} 0\). Therefore \(\varphi (n) \geq 2\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> two_le_totient_of_two_lt <span class="lean-bracket-1">(</span>n : ℕ<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span>hn : <span class="lean-number">2</span> &lt; n<span class="lean-bracket-1">)</span> : <span class="lean-number">2</span> <span class="lean-operator">≤</span> Nat.totient n :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> := Nat.totient_pos.mpr <span class="lean-bracket-1">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span> : <span class="lean-number">0</span> &lt; n<span class="lean-bracket-1">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> := Nat.totient_eq_one_iff.not.mpr <span class="lean-bracket-1">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span> : <span class="lean-operator">¬</span><span class="lean-bracket-2">(</span>n = <span class="lean-number">1</span> <span class="lean-operator">∨</span> n = <span class="lean-number">2</span><span class="lean-bracket-2">)</span><span class="lean-bracket-1">)</span>
  <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/Lemmas.lean#L155-L165" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:totient-ge-two');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:prod-coprime-dvd">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">A.0.5</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0006.html#lem:prod-coprime-dvd">#</a>
    
    <a class="icon proof" href="sect0006.html#a0000000067"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Finset.prod_coprime_dvd" class="lean_decl">Finset.prod_coprime_dvd</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If each \(f(a)\) divides \(d\) and the \(f(a)\) are pairwise coprime, then \(\prod _{a \in S} f(a)\) divides \(d\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000067">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>By induction on the finite set. Empty case: \(1 \mid d\) trivially. Insert case: we have \(f(q) \mid d\) and \(\prod _{s'} f(r) \mid d\) by IH. Show \(f(q)\) is coprime to \(\prod _{s'} f(r)\) using ‘Nat.Coprime.prod_right‘, then apply ‘Nat.Coprime.mul_dvd_of_dvd_of_dvd‘. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> prod_coprime_dvd <span class="lean-bracket-1">{</span>α : <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-bracket-1">}</span> <span class="lean-bracket-1">[</span>DecidableEq α<span class="lean-bracket-1">]</span> <span class="lean-bracket-1">(</span>S : Finset α<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span>f : α <span class="lean-operator">→</span> ℕ<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span>d : ℕ<span class="lean-bracket-1">)</span>
    <span class="lean-bracket-1">(</span>h_dvd : <span class="lean-operator">∀</span> a <span class="lean-operator">∈</span> S, f a ∣ d<span class="lean-bracket-1">)</span>
    <span class="lean-bracket-1">(</span>h_coprime : <span class="lean-operator">∀</span> a₁ <span class="lean-operator">∈</span> S, <span class="lean-operator">∀</span> a₂ <span class="lean-operator">∈</span> S, a₁ <span class="lean-operator">≠</span> a₂ <span class="lean-operator">→</span> <span class="lean-bracket-2">(</span>f a₁<span class="lean-bracket-2">)</span>.Coprime <span class="lean-bracket-2">(</span>f a₂<span class="lean-bracket-2">)</span><span class="lean-bracket-1">)</span> :
    <span class="lean-bracket-1">(</span><span class="lean-operator">∏</span> a <span class="lean-operator">∈</span> S, f a<span class="lean-bracket-1">)</span> ∣ d :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
">induction</span> S <span class="lean-keyword">using</span> Finset.induction <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
">with</span>
  | empty =&gt; <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span>
  | @insert q s&#x27; hq_notin IH =&gt;
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>Finset.prod_insert hq_notin<span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hq_dvd : f q ∣ d := h_dvd q <span class="lean-bracket-1">(</span>Finset.mem_insert_self q s&#x27;<span class="lean-bracket-1">)</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hs&#x27;_dvd : <span class="lean-bracket-1">(</span><span class="lean-operator">∏</span> r <span class="lean-operator">∈</span> s&#x27;, f r<span class="lean-bracket-1">)</span> ∣ d := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
      <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> IH
      <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> r hr; <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> h_dvd r <span class="lean-bracket-1">(</span>Finset.mem_insert_of_mem hr<span class="lean-bracket-1">)</span>
      <span class="lean-operator">·</span> <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> a₁ ha₁ a₂ ha₂ hne
        <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> h_coprime a₁ <span class="lean-bracket-1">(</span>Finset.mem_insert_of_mem ha₁<span class="lean-bracket-1">)</span> a₂
          <span class="lean-bracket-1">(</span>Finset.mem_insert_of_mem ha₂<span class="lean-bracket-1">)</span> hne
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> h_cop : <span class="lean-bracket-1">(</span>f q<span class="lean-bracket-1">)</span>.Coprime <span class="lean-bracket-1">(</span><span class="lean-operator">∏</span> r <span class="lean-operator">∈</span> s&#x27;, f r<span class="lean-bracket-1">)</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
      <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> Nat.Coprime.prod_right
      <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> r hr
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hne : q <span class="lean-operator">≠</span> r := <span class="lean-keyword">fun</span> heq =&gt; hq_notin <span class="lean-bracket-1">(</span>heq ▸ hr<span class="lean-bracket-1">)</span>
      <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> h_coprime q <span class="lean-bracket-1">(</span>Finset.mem_insert_self q s&#x27;<span class="lean-bracket-1">)</span> r
        <span class="lean-bracket-1">(</span>Finset.mem_insert_of_mem hr<span class="lean-bracket-1">)</span> hne
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> h_cop.mul_dvd_of_dvd_of_dvd hq_dvd hs&#x27;_dvd</code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/Lemmas.lean#L173-L202" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:prod-coprime-dvd');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:totient-prod-coprime">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">A.0.6</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0006.html#lem:totient-prod-coprime">#</a>
    
    <a class="icon proof" href="sect0006.html#a0000000068"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Nat.totient_finset_prod_of_coprime" class="lean_decl">Nat.totient_finset_prod_of_coprime</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       For pairwise coprime \(\{ f(a)\} _{a \in S}\), we have \(\varphi (\prod _{a \in S} f(a)) = \prod _{a \in S} \varphi (f(a))\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000068">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>By induction on the finite set. Empty case: \(\varphi (1) = 1\) equals empty product. Insert case: use \(\varphi (ab) = \varphi (a)\varphi (b)\) for coprime \(a, b\) (‘Nat.totient_mul‘), where coprimality follows from ‘Nat.Coprime.prod_right‘. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> totient_finset_prod_of_coprime <span class="lean-bracket-1">{</span>α : <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-bracket-1">}</span> <span class="lean-bracket-1">[</span>DecidableEq α<span class="lean-bracket-1">]</span> <span class="lean-bracket-1">(</span>S : Finset α<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span>f : α <span class="lean-operator">→</span> ℕ<span class="lean-bracket-1">)</span>
    <span class="lean-bracket-1">(</span>h_coprime : <span class="lean-operator">∀</span> a₁ <span class="lean-operator">∈</span> S, <span class="lean-operator">∀</span> a₂ <span class="lean-operator">∈</span> S, a₁ <span class="lean-operator">≠</span> a₂ <span class="lean-operator">→</span> <span class="lean-bracket-2">(</span>f a₁<span class="lean-bracket-2">)</span>.Coprime <span class="lean-bracket-2">(</span>f a₂<span class="lean-bracket-2">)</span><span class="lean-bracket-1">)</span> :
    Nat.totient <span class="lean-bracket-1">(</span><span class="lean-operator">∏</span> a <span class="lean-operator">∈</span> S, f a<span class="lean-bracket-1">)</span> = <span class="lean-operator">∏</span> a <span class="lean-operator">∈</span> S, Nat.totient <span class="lean-bracket-1">(</span>f a<span class="lean-bracket-1">)</span> :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
">induction</span> S <span class="lean-keyword">using</span> Finset.induction <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
">with</span>
  | empty =&gt; <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span>
  | @insert q s&#x27; hq_notin IH =&gt;
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>Finset.prod_insert hq_notin, Finset.prod_insert hq_notin<span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> h_cop_q_s : <span class="lean-bracket-1">(</span>f q<span class="lean-bracket-1">)</span>.Coprime <span class="lean-bracket-1">(</span><span class="lean-operator">∏</span> r <span class="lean-operator">∈</span> s&#x27;, f r<span class="lean-bracket-1">)</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
      <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> Nat.Coprime.prod_right
      <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> r hr
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hne : q <span class="lean-operator">≠</span> r := <span class="lean-keyword">fun</span> heq =&gt; hq_notin <span class="lean-bracket-1">(</span>heq ▸ hr<span class="lean-bracket-1">)</span>
      <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> h_coprime q <span class="lean-bracket-1">(</span>Finset.mem_insert_self q s&#x27;<span class="lean-bracket-1">)</span> r
        <span class="lean-bracket-1">(</span>Finset.mem_insert_of_mem hr<span class="lean-bracket-1">)</span> hne
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>Nat.totient_mul h_cop_q_s<span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="Apply congruence (recursively) to goals of the form `⊢ f as = f bs` and `⊢ f as ≍ f bs`.
The optional parameter is the depth of the recursive applications.
This is useful when `congr` is too aggressive in breaking down the goal.
For example, given `⊢ f (g (x + y)) = f (g (y + x))`,
`congr` produces the goals `⊢ x = y` and `⊢ y = x`,
while `congr 2` produces the intended `⊢ x + y = y + x`.
">congr</span> <span class="lean-number">1</span>
    <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> IH
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> a₁ ha₁ a₂ ha₂ hne
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> h_coprime a₁ <span class="lean-bracket-1">(</span>Finset.mem_insert_of_mem ha₁<span class="lean-bracket-1">)</span> a₂
      <span class="lean-bracket-1">(</span>Finset.mem_insert_of_mem ha₂<span class="lean-bracket-1">)</span> hne</code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/Lemmas.lean#L210-L242" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:totient-prod-coprime');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>


<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:orderOf-neg-of-odd-order">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">A.0.7</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0006.html#lem:orderOf-neg-of-odd-order">#</a>
    
    <a class="icon proof" href="sect0006.html#a0000000069"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.orderOf_neg_of_odd_order" class="lean_decl">Crystallographic.orderOf_neg_of_odd_order</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(A\) has odd order \(k\), then \(-A\) has order \(2k\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000069">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>We have \(-A = (-1) \cdot A\) where \(-1\) commutes with \(A\). In characteristic \(0\), the order of \(-1\) is \(2\). Since \(k\) is odd, \(\gcd (2, k) = 1\), so by the product formula for commuting elements with coprime orders, the order of \(-A\) equals the order of \(-1\) times the order of \(A\), which is \(2k\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-keyword">theorem</span> orderOf_neg_of_odd_order <span class="lean-bracket-1">{</span>n : ℕ<span class="lean-bracket-1">}</span> <span class="lean-bracket-1">[</span>NeZero n<span class="lean-bracket-1">]</span> <span class="lean-bracket-1">(</span>k : ℕ<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span>hk_odd : Odd k<span class="lean-bracket-1">)</span>
    <span class="lean-bracket-1">(</span>A : Matrix <span class="lean-bracket-2">(</span>Fin n<span class="lean-bracket-2">)</span> <span class="lean-bracket-2">(</span>Fin n<span class="lean-bracket-2">)</span> ℤ<span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span>hA_ord : orderOf A = k<span class="lean-bracket-1">)</span> :
    orderOf <span class="lean-bracket-1">(</span>-A<span class="lean-bracket-1">)</span> = <span class="lean-number">2</span> * k :=</code><code class="lean-proof-body"> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-comment">-- Express -A as </span><span class="lean-bracket-1">(</span>-<span class="lean-number">1</span><span class="lean-bracket-1">)</span> * A
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hneg_eq : -A = <span class="lean-bracket-1">(</span>-<span class="lean-number">1</span> : Matrix <span class="lean-bracket-2">(</span>Fin n<span class="lean-bracket-2">)</span> <span class="lean-bracket-2">(</span>Fin n<span class="lean-bracket-2">)</span> ℤ<span class="lean-bracket-1">)</span> * A := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>hneg_eq<span class="lean-bracket-1">]</span>
  <span class="lean-comment">-- -<span class="lean-number">1</span> and A commute</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hcomm : Commute <span class="lean-bracket-1">(</span>-<span class="lean-number">1</span> : Matrix <span class="lean-bracket-2">(</span>Fin n<span class="lean-bracket-2">)</span> <span class="lean-bracket-2">(</span>Fin n<span class="lean-bracket-2">)</span> ℤ<span class="lean-bracket-1">)</span> A := Commute.neg_one_left A
  <span class="lean-comment">-- orderOf</span><span class="lean-bracket-1">(</span>-<span class="lean-number">1</span><span class="lean-bracket-1">)</span> = <span class="lean-number">2</span> in char <span class="lean-number">0</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hord_neg1 : orderOf <span class="lean-bracket-1">(</span>-<span class="lean-number">1</span> : Matrix <span class="lean-bracket-2">(</span>Fin n<span class="lean-bracket-2">)</span> <span class="lean-bracket-2">(</span>Fin n<span class="lean-bracket-2">)</span> ℤ<span class="lean-bracket-1">)</span> = <span class="lean-number">2</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>orderOf_neg_one, ringChar_matrix_int<span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span>
  <span class="lean-comment">-- Coprimality: gcd</span><span class="lean-bracket-1">(</span><span class="lean-number">2</span>, k<span class="lean-bracket-1">)</span> = <span class="lean-number">1</span> since k is odd
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hcop : Nat.Coprime <span class="lean-number">2</span> k := Nat.Coprime.symm <span class="lean-bracket-1">(</span>Odd.coprime_two_right hk_odd<span class="lean-bracket-1">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> hord_cop : Nat.Coprime <span class="lean-bracket-1">(</span>orderOf <span class="lean-bracket-2">(</span>-<span class="lean-number">1</span> : Matrix <span class="lean-bracket-3">(</span>Fin n<span class="lean-bracket-3">)</span> <span class="lean-bracket-3">(</span>Fin n<span class="lean-bracket-3">)</span> ℤ<span class="lean-bracket-2">)</span><span class="lean-bracket-1">)</span> <span class="lean-bracket-1">(</span>orderOf A<span class="lean-bracket-1">)</span> := <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>hord_neg1, hA_ord<span class="lean-bracket-1">]</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> hcop
  <span class="lean-comment">-- Apply the product formula</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>hcomm.orderOf_mul_eq_mul_orderOf_of_coprime hord_cop<span class="lean-bracket-1">]</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-bracket-1">[</span>hord_neg1, hA_ord<span class="lean-bracket-1">]</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/Lemmas.lean#L250-L278" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>
<script>
(function() {
  var container = document.getElementById('lem:orderOf-neg-of-odd-order');
  if (!container) return;
  var proofHeading = container.querySelector('.proof_heading');
  var leanProofBody = container.querySelector('.lean-proof-body');
  if (!proofHeading || !leanProofBody) return;

  proofHeading.addEventListener('click', function() {
    // Read icon state after plastex.js has toggled it
    setTimeout(function() {
      var icon = container.querySelector('.expand-proof');
      var isExpanded = icon && icon.textContent.trim() === '▼';
      // Toggle expanded class for smooth CSS animation
      if (isExpanded) {
        leanProofBody.classList.add('expanded');
      } else {
        leanProofBody.classList.remove('expanded');
      }
    }, 50);
  });
})();
</script>



</div> <!--main-text -->
</div> <!-- content-wrapper -->
</div> <!-- content -->
</div> <!-- wrapper -->

<nav class="prev_up_next">
  <svg  id="showmore-minus" class="icon icon-eye-minus showmore"><use xlink:href="symbol-defs.svg#icon-eye-minus"></use></svg>

  <svg  id="showmore-plus" class="icon icon-eye-plus showmore"><use xlink:href="symbol-defs.svg#icon-eye-plus"></use></svg>

  <a href="sect0005.html" title="The Crystallographic Restriction Theorem"><svg  class="icon icon-arrow-left "><use xlink:href="symbol-defs.svg#icon-arrow-left"></use></svg>
</a>
  <a href="index.html" title="Crystallographic Restriction Theorem"><svg  class="icon icon-arrow-up "><use xlink:href="symbol-defs.svg#icon-arrow-up"></use></svg>
</a>
</nav>

<script type="text/javascript" src="js/jquery.min.js"></script>
<script type="text/javascript" src="js/plastex.js"></script>
<script type="text/javascript" src="js/svgxuse.js"></script>
<script type="text/javascript" src="js/js.cookie.min.js"></script>
<script type="text/javascript" src="js/showmore.js"></script>
</body>
</html>