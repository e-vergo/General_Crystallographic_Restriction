<!DOCTYPE html>
<html lang="en">
<head>
<script>
  MathJax = { 
    tex: {
		    inlineMath: [['$','$'], ['\\(','\\)']]
	} }
</script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
<meta name="generator" content="plasTeX" />
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Appendix</title>
<link rel="prev" href="sect0005.html" title="The Crystallographic Restriction Theorem" />
<link rel="up" href="index.html" title="Crystallographic Restriction Theorem" />
<link rel="stylesheet" href="styles/theme-blue.css" />
<link rel="stylesheet" href="styles/showmore.css" />
<link rel="stylesheet" href="styles/blueprint.css" />
<link rel="stylesheet" href="styles/amsthm.css" />
<link rel="stylesheet" href="styles/style.css" />
</head>

<body>
<header>
<svg  id="toc-toggle" class="icon icon-list-numbered "><use xlink:href="symbol-defs.svg#icon-list-numbered"></use></svg>
<h1 id="doc_title"><a href="index.html">Crystallographic Restriction Theorem</a></h1>
</header>

<div class="wrapper">
<nav class="toc">
<ul class="sub-toc-0">
<li class="">
  <a href="sect0001.html"><span class="toc_ref">1</span> <span class="toc_entry">Introduction</span></a>
 </li>
<li class="">
  <a href="sect0002.html"><span class="toc_ref">2</span> <span class="toc_entry">The Psi Function</span></a>
 </li>
<li class="">
  <a href="sect0003.html"><span class="toc_ref">3</span> <span class="toc_entry">Integer Matrix Orders</span></a>
 </li>
<li class="">
  <a href="sect0004.html"><span class="toc_ref">4</span> <span class="toc_entry">Companion Matrices</span></a>
 </li>
<li class="">
  <a href="sect0005.html"><span class="toc_ref">5</span> <span class="toc_entry">The Crystallographic Restriction Theorem</span></a>
 </li>
<li class=" active current">
  <a href="sect0006.html"><span class="toc_ref">A</span> <span class="toc_entry">Appendix</span></a>
 </li>
<li ><a href="dep_graph_document.html">Dependency graph</a></li>
</ul>
</nav>

<div class="content">
<div class="content-wrapper">


<div class="main-text">
<h1 id="a0000000007">A Appendix</h1>
<p>This appendix collects technical lemmas used throughout the proof. These are general-purpose results about finite sets, coprime products, Euler’s totient function, and matrix orders that support the main arguments. </p>
<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:sum-le-prod">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">A.0.1</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0006.html#lem:sum-le-prod">#</a>
    
    <a class="icon proof" href="sect0006.html#a0000000063"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Finset.sum_le_prod_of_all_ge_two" class="lean_decl">Finset.sum_le_prod_of_all_ge_two</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       For a finite set where all values \(\geq 2\), the sum is at most the product. </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000063">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>By induction on the size of the finite set. Base case: empty sum is \(0 \leq 1\) (empty product). Inductive step: if \(\sum _{x \in s} f(x) \leq \prod _{x \in s} f(x)\) and \(f(a) \geq 2\), then \(\sum _{x \in s \cup \{ a\} } f(x) = f(a) + \sum _s f \leq f(a) \cdot \prod _s f \leq \prod _{s \cup \{ a\} } f\) using \(1 + y \leq 2y\) for \(y \geq 1\) and \(f(a) \geq 2\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-docstring">/-- For a finset where all values of `f` are at least 2, the sum is bounded above by the product.

This is useful in combinatorial arguments where one wants to show that a sum of terms
(each at least 2) cannot exceed their product. The key insight is that for `a, b ≥ 2`,
we have `a + b ≤ a * b`, which extends by induction to finite products.

For upstreaming to Mathlib, this should be placed in `Mathlib.Algebra.Order.BigOperators.Group.Finset`. -/</span>
<span class="lean-text">@[</span><span class="lean-keyword" data-docs="The `blueprint` attribute tags a constant to add to the blueprint.

You may optionally add:
- `&quot;latex-label&quot;`: The LaTeX label to use for the node (default: the Lean name).
- `statement := /-- ... -/`: The statement of the node in LaTeX.
- `hasProof := true`: If the node has a proof part (default: true if the node is a theorem).
- `proof := /-- ... -/`: The proof of the node in LaTeX (default: the docstrings in proof tactics).
- `uses := [a, &quot;b&quot;]`: The dependencies of the node, as Lean constants or LaTeX labels (default: inferred from the used constants).
- `proofUses := [a, &quot;b&quot;]`: The dependencies of the proof of the node, as Lean constants or LaTeX labels (default: inferred from the used constants).
- `title := /-- Title -/`: The title of the node in LaTeX.
- `notReady := true`: Whether the node is not ready.
- `discussion := 123`: The discussion issue number of the node.
- `latexEnv := &quot;lemma&quot;`: The LaTeX environment to use for the node (default: &quot;theorem&quot; or &quot;definition&quot;).

For more information, see [LeanArchitect](https://github.com/hanwenzhu/LeanArchitect).

Use `blueprint?` to show the raw data of the added node.
">blueprint</span> <span class="lean-string">&quot;lem:sum-le-prod&quot;</span>
  <span class="lean-text">(</span><span class="lean-keyword">statement</span> <span class="lean-text">:=</span> <span class="lean-docstring">/-- For a finite set where all values $\geq 2$, the sum is at most the product. -/</span><span class="lean-text">)</span>
  <span class="lean-text">(</span><span class="lean-keyword">proof</span> <span class="lean-text">:=</span> <span class="lean-docstring">/-- By induction on the size of the finite set. Base case: empty sum is $0 \leq 1$ (empty product).
  Inductive step: if $\sum_{x \in s} f(x) \leq \prod_{x \in s} f(x)$ and $f(a) \geq 2$, then
  $\sum_{x \in s \cup \{a\}} f(x) = f(a) + \sum_s f \leq f(a) \cdot \prod_s f \leq \prod_{s \cup \{a\}} f$
  using $1 + y \leq 2y$ for $y \geq 1$ and $f(a) \geq 2$. -/</span><span class="lean-text">)</span><span class="lean-text">]</span>
<span class="lean-keyword">lemma</span> <span class="lean-text">sum_le_prod_of_all_ge_two</span></code><code class="lean-proof-body"> <span class="lean-text">{</span><span class="lean-text">α</span> <span class="lean-text">:</span> <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-text">}</span> <span class="lean-text">[</span><span class="lean-text">DecidableEq</span> <span class="lean-text">α</span><span class="lean-text">]</span>
    <span class="lean-text">(</span><span class="lean-text">s</span> <span class="lean-text">:</span> <span class="lean-text">Finset</span> <span class="lean-text">α</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">f</span> <span class="lean-text">:</span> <span class="lean-text">α</span> <span class="lean-text">→</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hf</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">x</span> <span class="lean-text">∈</span> <span class="lean-text">s</span><span class="lean-text">,</span> <span class="lean-text">2</span> <span class="lean-text">≤</span> <span class="lean-text">f</span> <span class="lean-text">x</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">∑</span> <span class="lean-text">x</span> <span class="lean-text">∈</span> <span class="lean-text">s</span><span class="lean-text">,</span> <span class="lean-text">f</span> <span class="lean-text">x</span> <span class="lean-text">≤</span> <span class="lean-text">∏</span> <span class="lean-text">x</span> <span class="lean-text">∈</span> <span class="lean-text">s</span><span class="lean-text">,</span> <span class="lean-text">f</span> <span class="lean-text">x</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
">induction</span> <span class="lean-text">s</span> <span class="lean-keyword">using</span> <span class="lean-text">Finset.induction</span> <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
">with</span>
  <span class="lean-text">|</span> <span class="lean-text">empty</span> <span class="lean-text">=&gt;</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span>
  <span class="lean-text">|</span> <span class="lean-text">@</span><span class="lean-text">insert</span> <span class="lean-text">a</span> <span class="lean-text">s&#x27;</span> <span class="lean-text">ha</span> <span class="lean-text">IH</span> <span class="lean-text">=&gt;</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">Finset.sum_insert</span> <span class="lean-text">ha</span><span class="lean-text">,</span> <span class="lean-text">Finset.prod_insert</span> <span class="lean-text">ha</span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">h2_a</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">≤</span> <span class="lean-text">f</span> <span class="lean-text">a</span> <span class="lean-text">:=</span> <span class="lean-text">hf</span> <span class="lean-text">a</span> <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_self</span> <span class="lean-text">a</span> <span class="lean-text">s&#x27;</span><span class="lean-text">)</span>
    <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> <span class="lean-text">hs_empty</span> <span class="lean-text">:</span> <span class="lean-text">s&#x27;</span> <span class="lean-text">=</span> <span class="lean-text">∅</span>
    <span class="lean-text">·</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-text">[</span><span class="lean-text">hs_empty</span><span class="lean-text">]</span>
    <span class="lean-text">·</span> <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hs_nonempty</span> <span class="lean-text">:</span> <span class="lean-text">s&#x27;.Nonempty</span> <span class="lean-text">:=</span> <span class="lean-text">Finset.nonempty_of_ne_empty</span> <span class="lean-text">hs_empty</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hs&#x27;_ge2</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">x</span> <span class="lean-text">∈</span> <span class="lean-text">s&#x27;</span><span class="lean-text">,</span> <span class="lean-text">2</span> <span class="lean-text">≤</span> <span class="lean-text">f</span> <span class="lean-text">x</span> <span class="lean-text">:=</span> <span class="lean-keyword">fun</span> <span class="lean-text">x</span> <span class="lean-text">hx</span> <span class="lean-text">=&gt;</span> <span class="lean-text">hf</span> <span class="lean-text">x</span> <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_of_mem</span> <span class="lean-text">hx</span><span class="lean-text">)</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">h2_prod</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">≤</span> <span class="lean-text">∏</span> <span class="lean-text">x</span> <span class="lean-text">∈</span> <span class="lean-text">s&#x27;</span><span class="lean-text">,</span> <span class="lean-text">f</span> <span class="lean-text">x</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
        <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-text">⟨</span><span class="lean-text">b</span><span class="lean-text">,</span> <span class="lean-text">hb</span><span class="lean-text">⟩</span> <span class="lean-text">:=</span> <span class="lean-text">hs_nonempty</span>
        <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">h1</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">x</span> <span class="lean-text">∈</span> <span class="lean-text">s&#x27;</span><span class="lean-text">,</span> <span class="lean-text">1</span> <span class="lean-text">≤</span> <span class="lean-text">f</span> <span class="lean-text">x</span> <span class="lean-text">:=</span> <span class="lean-keyword">fun</span> <span class="lean-text">x</span> <span class="lean-text">hx</span> <span class="lean-text">=&gt;</span> <span class="lean-text">Nat.one_le_of_lt</span> <span class="lean-text">(</span><span class="lean-text">hs&#x27;_ge2</span> <span class="lean-text">x</span> <span class="lean-text">hx</span><span class="lean-text">)</span>
        <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
">calc</span> <span class="lean-text">∏</span> <span class="lean-text">x</span> <span class="lean-text">∈</span> <span class="lean-text">s&#x27;</span><span class="lean-text">,</span> <span class="lean-text">f</span> <span class="lean-text">x</span> <span class="lean-text">≥</span> <span class="lean-text">f</span> <span class="lean-text">b</span> <span class="lean-text">:=</span> <span class="lean-text">Finset.single_le_prod&#x27;</span> <span class="lean-text">h1</span> <span class="lean-text">hb</span>
          <span class="lean-text">_</span> <span class="lean-text">≥</span> <span class="lean-text">2</span> <span class="lean-text">:=</span> <span class="lean-text">hs&#x27;_ge2</span> <span class="lean-text">b</span> <span class="lean-text">hb</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">IH&#x27;</span> <span class="lean-text">:=</span> <span class="lean-text">IH</span> <span class="lean-text">hs&#x27;_ge2</span>
      <span class="lean-keyword" data-docs="Step-wise reasoning over transitive relations.
```
calc
  a = b := pab
  b = c := pbc
  ...
  y = z := pyz
```
proves `a = z` from the given step-wise proofs. `=` can be replaced with any
relation implementing the typeclass `Trans`. Instead of repeating the right-
hand sides, subsequent left-hand sides can be replaced with `_`.
```
calc
  a = b := pab
  _ = c := pbc
  ...
  _ = z := pyz
```
It is also possible to write the *first* relation as `&lt;lhs&gt;\n  _ = &lt;rhs&gt; :=
&lt;proof&gt;`. This is useful for aligning relation symbols, especially on longer:
identifiers:
```
calc abc
  _ = bce := pabce
  _ = cef := pbcef
  ...
  _ = xyz := pwxyz
```

`calc` works as a term, as a tactic or as a `conv` tactic.

See [Theorem Proving in Lean 4][tpil4] for more information.

[tpil4]: https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#calculational-proofs
">calc</span> <span class="lean-text">f</span> <span class="lean-text">a</span> <span class="lean-text">+</span> <span class="lean-text">∑</span> <span class="lean-text">x</span> <span class="lean-text">∈</span> <span class="lean-text">s&#x27;</span><span class="lean-text">,</span> <span class="lean-text">f</span> <span class="lean-text">x</span>
          <span class="lean-text">≤</span> <span class="lean-text">f</span> <span class="lean-text">a</span> <span class="lean-text">+</span> <span class="lean-text">∏</span> <span class="lean-text">x</span> <span class="lean-text">∈</span> <span class="lean-text">s&#x27;</span><span class="lean-text">,</span> <span class="lean-text">f</span> <span class="lean-text">x</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span>
        <span class="lean-text">_</span> <span class="lean-text">≤</span> <span class="lean-text">f</span> <span class="lean-text">a</span> <span class="lean-text">*</span> <span class="lean-text">∏</span> <span class="lean-text">x</span> <span class="lean-text">∈</span> <span class="lean-text">s&#x27;</span><span class="lean-text">,</span> <span class="lean-text">f</span> <span class="lean-text">x</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.add_le_mul</span> <span class="lean-text">h2_a</span> <span class="lean-text">h2_prod</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/Lemmas.lean#L41-L74" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>

<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:lcm-factorization-le-sup">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">A.0.2</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0006.html#lem:lcm-factorization-le-sup">#</a>
    
    <a class="icon proof" href="sect0006.html#a0000000064"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Finset.lcm_factorization_le_sup" class="lean_decl">Finset.lcm_factorization_le_sup</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       The factorization of \(\mathrm{lcm}(S)\) at prime \(q\) is bounded by \(\sup _{x \in S} v_q(x)\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000064">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>The \(q\)-adic valuation of \(\mathrm{lcm}(S)\) is the maximum of \(q\)-adic valuations over elements of \(S\). This follows from the definition of lcm via factorization: \(v_q(\mathrm{lcm}(S)) = \sup _{x \in S} v_q(x)\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-docstring">/-- The factorization of a finset lcm at any prime is at most the supremum. -/</span>
<span class="lean-text">@[</span><span class="lean-keyword" data-docs="The `blueprint` attribute tags a constant to add to the blueprint.

You may optionally add:
- `&quot;latex-label&quot;`: The LaTeX label to use for the node (default: the Lean name).
- `statement := /-- ... -/`: The statement of the node in LaTeX.
- `hasProof := true`: If the node has a proof part (default: true if the node is a theorem).
- `proof := /-- ... -/`: The proof of the node in LaTeX (default: the docstrings in proof tactics).
- `uses := [a, &quot;b&quot;]`: The dependencies of the node, as Lean constants or LaTeX labels (default: inferred from the used constants).
- `proofUses := [a, &quot;b&quot;]`: The dependencies of the proof of the node, as Lean constants or LaTeX labels (default: inferred from the used constants).
- `title := /-- Title -/`: The title of the node in LaTeX.
- `notReady := true`: Whether the node is not ready.
- `discussion := 123`: The discussion issue number of the node.
- `latexEnv := &quot;lemma&quot;`: The LaTeX environment to use for the node (default: &quot;theorem&quot; or &quot;definition&quot;).

For more information, see [LeanArchitect](https://github.com/hanwenzhu/LeanArchitect).

Use `blueprint?` to show the raw data of the added node.
">blueprint</span> <span class="lean-string">&quot;lem:lcm-factorization-le-sup&quot;</span>
  <span class="lean-text">(</span><span class="lean-keyword">statement</span> <span class="lean-text">:=</span> <span class="lean-docstring">/-- The factorization of $\mathrm{lcm}(S)$ at prime $q$ is bounded by
  $\sup_{x \in S} v_q(x)$. -/</span><span class="lean-text">)</span>
  <span class="lean-text">(</span><span class="lean-keyword">proof</span> <span class="lean-text">:=</span> <span class="lean-docstring">/-- The $q$-adic valuation of $\mathrm{lcm}(S)$ is the maximum of $q$-adic valuations over elements of $S$.
  This follows from the definition of lcm via factorization: $v_q(\mathrm{lcm}(S)) = \sup_{x \in S} v_q(x)$. -/</span><span class="lean-text">)</span><span class="lean-text">]</span>
<span class="lean-keyword">lemma</span> <span class="lean-text">lcm_factorization_le_sup</span></code><code class="lean-proof-body"> <span class="lean-text">{</span><span class="lean-text">α</span> <span class="lean-text">:</span> <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-text">}</span> <span class="lean-text">[</span><span class="lean-text">DecidableEq</span> <span class="lean-text">α</span><span class="lean-text">]</span> <span class="lean-text">(</span><span class="lean-text">S</span> <span class="lean-text">:</span> <span class="lean-text">Finset</span> <span class="lean-text">α</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">f</span> <span class="lean-text">:</span> <span class="lean-text">α</span> <span class="lean-text">→</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span>
    <span class="lean-text">(</span><span class="lean-text">q</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hS_ne_zero</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">x</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">f</span> <span class="lean-text">x</span> <span class="lean-text">≠</span> <span class="lean-text">0</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">(</span><span class="lean-text">S.lcm</span> <span class="lean-text">f</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">factorization</span> <span class="lean-text">q</span> <span class="lean-text">≤</span> <span class="lean-text">S.sup</span> <span class="lean-text">(</span><span class="lean-keyword">fun</span> <span class="lean-text">x</span> <span class="lean-text">=&gt;</span> <span class="lean-text">(</span><span class="lean-text">f</span> <span class="lean-text">x</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">factorization</span> <span class="lean-text">q</span><span class="lean-text">)</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
">induction</span> <span class="lean-text">S</span> <span class="lean-keyword">using</span> <span class="lean-text">Finset.induction</span> <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
">with</span>
  <span class="lean-text">|</span> <span class="lean-text">empty</span> <span class="lean-text">=&gt;</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">Finset.lcm_empty</span><span class="lean-text">,</span> <span class="lean-text">Nat.factorization_one</span><span class="lean-text">,</span> <span class="lean-text">Finsupp.coe_zero</span><span class="lean-text">,</span> <span class="lean-text">Pi.zero_apply</span><span class="lean-text">,</span>
      <span class="lean-text">Finset.sup_empty</span><span class="lean-text">,</span> <span class="lean-text">bot_eq_zero</span><span class="lean-text">,</span> <span class="lean-text">le_refl</span><span class="lean-text">]</span>
  <span class="lean-text">|</span> <span class="lean-text">@</span><span class="lean-text">insert</span> <span class="lean-text">a</span> <span class="lean-text">s&#x27;</span> <span class="lean-text">ha</span> <span class="lean-text">IH</span> <span class="lean-text">=&gt;</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">Finset.lcm_insert</span><span class="lean-text">,</span> <span class="lean-text">Finset.sup_insert</span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="`by_cases (h :)? p` splits the main goal into two cases, assuming `h : p` in the first branch, and `h : ¬ p` in the second branch.
">by_cases</span> <span class="lean-text">hs&#x27;_empty</span> <span class="lean-text">:</span> <span class="lean-text">s&#x27;</span> <span class="lean-text">=</span> <span class="lean-text">∅</span>
    <span class="lean-text">·</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-text">[</span><span class="lean-text">hs&#x27;_empty</span><span class="lean-text">]</span>
    <span class="lean-text">·</span> <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hs&#x27;_ne_zero</span> <span class="lean-text">:</span> <span class="lean-text">s&#x27;.lcm</span> <span class="lean-text">f</span> <span class="lean-text">≠</span> <span class="lean-text">0</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
        <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">ne_eq</span><span class="lean-text">,</span> <span class="lean-text">Finset.lcm_eq_zero_iff</span><span class="lean-text">]</span>
        <span class="lean-keyword" data-docs="Push negations into the conclusion or a hypothesis.
For instance, a hypothesis `h : ¬ ∀ x, ∃ y, x ≤ y` will be transformed by `push_neg at h` into
`h : ∃ x, ∀ y, y &lt; x`. Binder names are preserved.

`push_neg` is a special case of the more general `push` tactic, namely `push Not`.
The `push` tactic can be extended using the `@[push]` attribute. `push` has special-casing
built in for `push Not`, so that it can preserve binder names, and so that `¬ (p ∧ q)` can be
transformed to either `p → ¬ q` (default) or `¬ p ∨ ¬ q` (`push_neg +distrib`).

Tactics that introduce a negation usually have a version that automatically calls `push_neg` on
that negation. These include `by_cases!`, `contrapose!` and `by_contra!`.

Another example: given a hypothesis
```lean
h : ¬ ∀ ε &gt; 0, ∃ δ &gt; 0, ∀ x, |x - x₀| ≤ δ → |f x - y₀| ≤ ε
```
writing `push_neg at h` will turn `h` into
```lean
h : ∃ ε &gt; 0, ∀ δ &gt; 0, ∃ x, |x - x₀| ≤ δ ∧ ε &lt; |f x - y₀|
```
Note that binder names are preserved by this tactic, contrary to what would happen with `simp`
using the relevant lemmas. One can use this tactic at the goal using `push_neg`,
at every hypothesis and the goal using `push_neg at *` or at selected hypotheses and the goal
using say `push_neg at h h&#x27; ⊢`, as usual.
">push_neg</span>
        <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">x</span> <span class="lean-text">hx</span>
        <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">hS_ne_zero</span> <span class="lean-text">x</span> <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_of_mem</span> <span class="lean-text">hx</span><span class="lean-text">)</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">ha_ne_zero</span> <span class="lean-text">:</span> <span class="lean-text">f</span> <span class="lean-text">a</span> <span class="lean-text">≠</span> <span class="lean-text">0</span> <span class="lean-text">:=</span> <span class="lean-text">hS_ne_zero</span> <span class="lean-text">a</span> <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_self</span> <span class="lean-text">a</span> <span class="lean-text">s&#x27;</span><span class="lean-text">)</span>
      <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">lcm_eq_nat_lcm</span><span class="lean-text">,</span> <span class="lean-text">Nat.factorization_lcm</span> <span class="lean-text">ha_ne_zero</span> <span class="lean-text">hs&#x27;_ne_zero</span><span class="lean-text">]</span>
      <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span> <span class="lean-keyword">only</span> <span class="lean-text">[</span><span class="lean-text">Finsupp.sup_apply</span><span class="lean-text">,</span> <span class="lean-text">sup_le_iff</span><span class="lean-text">]</span>
      <span class="lean-keyword" data-docs="If the main goal&#x27;s target type is an inductive type, `constructor` solves it with
the first matching constructor, or else fails.
">constructor</span>
      <span class="lean-text">·</span> <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">le_sup_left</span>
      <span class="lean-text">·</span> <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hIH</span> <span class="lean-text">:=</span> <span class="lean-text">IH</span> <span class="lean-text">(</span><span class="lean-keyword">fun</span> <span class="lean-text">x</span> <span class="lean-text">hx</span> <span class="lean-text">=&gt;</span> <span class="lean-text">hS_ne_zero</span> <span class="lean-text">x</span> <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_of_mem</span> <span class="lean-text">hx</span><span class="lean-text">)</span><span class="lean-text">)</span>
        <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">le_trans</span> <span class="lean-text">hIH</span> <span class="lean-text">le_sup_right</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/Lemmas.lean#L78-L106" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>

<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:primePow-mem-of-lcm-eq">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">A.0.3</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0006.html#lem:primePow-mem-of-lcm-eq">#</a>
    
    <a class="icon proof" href="sect0006.html#a0000000065"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.Finset.prime_pow_mem_of_lcm_eq" class="lean_decl">Crystallographic.Finset.prime_pow_mem_of_lcm_eq</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(\mathrm{lcm}(S) = p^k\) and all elements of \(S\) divide \(p^k\), then \(p^k \in S\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000065">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>Since \(\mathrm{lcm}(S) = p^k\) and all elements divide \(p^k\), each element has form \(p^j\) for some \(j \leq k\). Taking lcm over these powers gives \(p^{\max _j} = p^k\), so some element must have \(j = k\), meaning \(p^k \in S\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-docstring">/-- For a prime power `p^k`, if a finset `S` of divisors of `p^k` has lcm equal to `p^k`,
then `p^k` must be an element of `S`.

The proof proceeds by contradiction: if `p^k ∉ S`, then every element of `S` is a proper
divisor of `p^k`, hence divides `p^(k-1)`. But then `lcm(S) ∣ p^(k-1) &lt; p^k`, contradicting
that `lcm(S) = p^k`. -/</span>
<span class="lean-text">@[</span><span class="lean-keyword" data-docs="The `blueprint` attribute tags a constant to add to the blueprint.

You may optionally add:
- `&quot;latex-label&quot;`: The LaTeX label to use for the node (default: the Lean name).
- `statement := /-- ... -/`: The statement of the node in LaTeX.
- `hasProof := true`: If the node has a proof part (default: true if the node is a theorem).
- `proof := /-- ... -/`: The proof of the node in LaTeX (default: the docstrings in proof tactics).
- `uses := [a, &quot;b&quot;]`: The dependencies of the node, as Lean constants or LaTeX labels (default: inferred from the used constants).
- `proofUses := [a, &quot;b&quot;]`: The dependencies of the proof of the node, as Lean constants or LaTeX labels (default: inferred from the used constants).
- `title := /-- Title -/`: The title of the node in LaTeX.
- `notReady := true`: Whether the node is not ready.
- `discussion := 123`: The discussion issue number of the node.
- `latexEnv := &quot;lemma&quot;`: The LaTeX environment to use for the node (default: &quot;theorem&quot; or &quot;definition&quot;).

For more information, see [LeanArchitect](https://github.com/hanwenzhu/LeanArchitect).

Use `blueprint?` to show the raw data of the added node.
">blueprint</span> <span class="lean-string">&quot;lem:primePow-mem-of-lcm-eq&quot;</span>
  <span class="lean-text">(</span><span class="lean-keyword">statement</span> <span class="lean-text">:=</span> <span class="lean-docstring">/-- If $\mathrm{lcm}(S) = p^k$ and all elements of $S$ divide $p^k$,
  then $p^k \in S$. -/</span><span class="lean-text">)</span>
  <span class="lean-text">(</span><span class="lean-keyword">proof</span> <span class="lean-text">:=</span> <span class="lean-docstring">/-- Since $\mathrm{lcm}(S) = p^k$ and all elements divide $p^k$, each element has form $p^j$ for some $j \leq k$.
  Taking lcm over these powers gives $p^{\max_j} = p^k$, so some element must have $j = k$, meaning $p^k \in S$. -/</span><span class="lean-text">)</span><span class="lean-text">]</span>
<span class="lean-keyword">lemma</span> <span class="lean-text">Finset.prime_pow_mem_of_lcm_eq</span></code><code class="lean-proof-body"> <span class="lean-text">{</span><span class="lean-text">p</span> <span class="lean-text">k</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">}</span> <span class="lean-text">(</span><span class="lean-text">hp</span> <span class="lean-text">:</span> <span class="lean-text">p.Prime</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hk</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">k</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">S</span> <span class="lean-text">:</span> <span class="lean-text">Finset</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span>
    <span class="lean-text">(</span><span class="lean-text">hS_sub</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">d</span> <span class="lean-text">∣</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">k</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hS_lcm</span> <span class="lean-text">:</span> <span class="lean-text">S.lcm</span> <span class="lean-text">id</span> <span class="lean-text">=</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">k</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">k</span> <span class="lean-text">∈</span> <span class="lean-text">S</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="`by_contra h` proves `⊢ p` by contradiction,
introducing a hypothesis `h : ¬p` and proving `False`.
* If `p` is a negation `¬q`, `h : q` will be introduced instead of `¬¬q`.
* If `p` is decidable, it uses `Decidable.byContradiction` instead of `Classical.byContradiction`.
* If `h` is omitted, the introduced variable will be called `this`.
">by_contra</span> <span class="lean-text">hm_not_in</span>
  -- All elements of S are proper divisors of p^k, so they divide p^(k-1)
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hall_lt</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">d</span> <span class="lean-text">&lt;</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">k</span> <span class="lean-text">:=</span> <span class="lean-keyword">fun</span> <span class="lean-text">d</span> <span class="lean-text">hd</span> <span class="lean-text">=&gt;</span>
    <span class="lean-text">Nat.lt_of_le_of_ne</span> <span class="lean-text">(</span><span class="lean-text">Nat.le_of_dvd</span> <span class="lean-text">(</span><span class="lean-text">Nat.pow_pos</span> <span class="lean-text">hp.pos</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hS_sub</span> <span class="lean-text">d</span> <span class="lean-text">hd</span><span class="lean-text">)</span><span class="lean-text">)</span>
      <span class="lean-text">(</span><span class="lean-keyword">fun</span> <span class="lean-text">heq</span> <span class="lean-text">=&gt;</span> <span class="lean-text">hm_not_in</span> <span class="lean-text">(</span><span class="lean-text">heq</span> <span class="lean-text">▸</span> <span class="lean-text">hd</span><span class="lean-text">)</span><span class="lean-text">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hall_le</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">d</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">d</span> <span class="lean-text">∣</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">(</span><span class="lean-text">k</span> <span class="lean-text">-</span> <span class="lean-text">1</span><span class="lean-text">)</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">d</span> <span class="lean-text">hd</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hdvd</span> <span class="lean-text">:=</span> <span class="lean-text">hS_sub</span> <span class="lean-text">d</span> <span class="lean-text">hd</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hd_lt</span> <span class="lean-text">:=</span> <span class="lean-text">hall_lt</span> <span class="lean-text">d</span> <span class="lean-text">hd</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hpr</span> <span class="lean-text">:</span> <span class="lean-text">Prime</span> <span class="lean-text">p</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.Prime.prime</span> <span class="lean-text">hp</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">dvd_prime_pow</span> <span class="lean-text">hpr</span><span class="lean-text">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> <span class="lean-text">hdvd</span>
    <span class="lean-keyword" data-docs="The `obtain` tactic is a combination of `have` and `rcases`. See `rcases` for
a description of supported patterns.

```lean
obtain ⟨patt⟩ : type := proof
```
is equivalent to
```lean
have h : type := proof
rcases h with ⟨patt⟩
```

If `⟨patt⟩` is omitted, `rcases` will try to infer the pattern.

If `type` is omitted, `:= proof` is required.
">obtain</span> <span class="lean-text">⟨</span><span class="lean-text">j</span><span class="lean-text">,</span> <span class="lean-text">_</span><span class="lean-text">,</span> <span class="lean-text">hassoc</span><span class="lean-text">⟩</span> <span class="lean-text">:=</span> <span class="lean-text">hdvd</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hd_eq</span> <span class="lean-text">:=</span> <span class="lean-text">associated_iff_eq.mp</span> <span class="lean-text">hassoc</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">hd_eq</span><span class="lean-text">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> <span class="lean-text">hd_lt</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hj_lt</span> <span class="lean-text">:</span> <span class="lean-text">j</span> <span class="lean-text">&lt;</span> <span class="lean-text">k</span> <span class="lean-text">:=</span> <span class="lean-text">(</span><span class="lean-text">Nat.pow_lt_pow_iff_right</span> <span class="lean-text">hp.one_lt</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">mp</span> <span class="lean-text">hd_lt</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hj_le</span> <span class="lean-text">:</span> <span class="lean-text">j</span> <span class="lean-text">≤</span> <span class="lean-text">k</span> <span class="lean-text">-</span> <span class="lean-text">1</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.lt_succ_iff.mp</span> <span class="lean-text">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span><span class="lean-text">)</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">hd_eq</span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">Nat.pow_dvd_pow</span> <span class="lean-text">p</span> <span class="lean-text">hj_le</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hlcm_le</span> <span class="lean-text">:</span> <span class="lean-text">S.lcm</span> <span class="lean-text">id</span> <span class="lean-text">∣</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">(</span><span class="lean-text">k</span> <span class="lean-text">-</span> <span class="lean-text">1</span><span class="lean-text">)</span> <span class="lean-text">:=</span> <span class="lean-text">Finset.lcm_dvd_iff.mpr</span> <span class="lean-text">(</span><span class="lean-keyword">fun</span> <span class="lean-text">d</span> <span class="lean-text">hd</span> <span class="lean-text">=&gt;</span> <span class="lean-text">hall_le</span> <span class="lean-text">d</span> <span class="lean-text">hd</span><span class="lean-text">)</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">hS_lcm</span><span class="lean-text">]</span> <span class="lean-keyword" data-docs="Location specifications are used by many tactics that can operate on either the
hypotheses or the goal. It can have one of the forms:
* &#x27;empty&#x27; is not actually present in this syntax, but most tactics use
  `(location)?` matchers. It means to target the goal only.
* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`
* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal
* `at *`: target all hypotheses and the goal
">at</span> <span class="lean-text">hlcm_le</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hle</span> <span class="lean-text">:</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">k</span> <span class="lean-text">≤</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">(</span><span class="lean-text">k</span> <span class="lean-text">-</span> <span class="lean-text">1</span><span class="lean-text">)</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.le_of_dvd</span> <span class="lean-text">(</span><span class="lean-text">Nat.pow_pos</span> <span class="lean-text">hp.pos</span><span class="lean-text">)</span> <span class="lean-text">hlcm_le</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hpow_strict</span> <span class="lean-text">:</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">(</span><span class="lean-text">k</span> <span class="lean-text">-</span> <span class="lean-text">1</span><span class="lean-text">)</span> <span class="lean-text">&lt;</span> <span class="lean-text">p</span> <span class="lean-text">^</span> <span class="lean-text">k</span> <span class="lean-text">:=</span>
    <span class="lean-text">Nat.pow_lt_pow_right</span> <span class="lean-text">hp.one_lt</span> <span class="lean-text">(</span><span class="lean-text">Nat.sub_lt</span> <span class="lean-text">hk</span> <span class="lean-text">Nat.one_pos</span><span class="lean-text">)</span>
  <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/Lemmas.lean#L114-L151" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>

<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:totient-ge-two">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">A.0.4</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0006.html#lem:totient-ge-two">#</a>
    
    <a class="icon proof" href="sect0006.html#a0000000066"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.two_le_totient_of_two_lt" class="lean_decl">Crystallographic.two_le_totient_of_two_lt</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       For \(n {\gt} 2\), we have \(\varphi (n) \geq 2\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000066">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>Since \(n {\gt} 2\), we have \(n \neq 1\) and \(n \neq 2\). By the fact that \(\varphi (n) = 1\) if and only if \(n \in \{ 1, 2\} \), we conclude that \(\varphi (n) \neq 1\). Also \(\varphi (n) \neq 0\) since \(n {\gt} 0\). Therefore \(\varphi (n) \geq 2\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-docstring">/-- Euler&#x27;s totient function is at least 2 for any n &gt; 2. -/</span>
<span class="lean-text">@[</span><span class="lean-keyword" data-docs="The `blueprint` attribute tags a constant to add to the blueprint.

You may optionally add:
- `&quot;latex-label&quot;`: The LaTeX label to use for the node (default: the Lean name).
- `statement := /-- ... -/`: The statement of the node in LaTeX.
- `hasProof := true`: If the node has a proof part (default: true if the node is a theorem).
- `proof := /-- ... -/`: The proof of the node in LaTeX (default: the docstrings in proof tactics).
- `uses := [a, &quot;b&quot;]`: The dependencies of the node, as Lean constants or LaTeX labels (default: inferred from the used constants).
- `proofUses := [a, &quot;b&quot;]`: The dependencies of the proof of the node, as Lean constants or LaTeX labels (default: inferred from the used constants).
- `title := /-- Title -/`: The title of the node in LaTeX.
- `notReady := true`: Whether the node is not ready.
- `discussion := 123`: The discussion issue number of the node.
- `latexEnv := &quot;lemma&quot;`: The LaTeX environment to use for the node (default: &quot;theorem&quot; or &quot;definition&quot;).

For more information, see [LeanArchitect](https://github.com/hanwenzhu/LeanArchitect).

Use `blueprint?` to show the raw data of the added node.
">blueprint</span> <span class="lean-string">&quot;lem:totient-ge-two&quot;</span>
  <span class="lean-text">(</span><span class="lean-keyword">statement</span> <span class="lean-text">:=</span> <span class="lean-docstring">/-- For $n &gt; 2$, we have $\varphi(n) \geq 2$. -/</span><span class="lean-text">)</span>
  <span class="lean-text">(</span><span class="lean-keyword">proof</span> <span class="lean-text">:=</span> <span class="lean-docstring">/-- Since $n &gt; 2$, we have $n \neq 1$ and $n \neq 2$.
  By the fact that $\varphi(n) = 1$ if and only if $n \in \{1, 2\}$,
  we conclude that $\varphi(n) \neq 1$.
  Also $\varphi(n) \neq 0$ since $n &gt; 0$. Therefore $\varphi(n) \geq 2$. -/</span><span class="lean-text">)</span><span class="lean-text">]</span>
<span class="lean-keyword">theorem</span> <span class="lean-text">two_le_totient_of_two_lt</span></code><code class="lean-proof-body"> <span class="lean-text">(</span><span class="lean-text">n</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hn</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">&lt;</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">:</span> <span class="lean-text">2</span> <span class="lean-text">≤</span> <span class="lean-text">Nat.totient</span> <span class="lean-text">n</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.totient_pos.mpr</span> <span class="lean-text">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span> <span class="lean-text">:</span> <span class="lean-text">0</span> <span class="lean-text">&lt;</span> <span class="lean-text">n</span><span class="lean-text">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.totient_eq_one_iff.not.mpr</span> <span class="lean-text">(</span><span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span> <span class="lean-text">:</span> <span class="lean-text">¬</span><span class="lean-text">(</span><span class="lean-text">n</span> <span class="lean-text">=</span> <span class="lean-text">1</span> <span class="lean-text">∨</span> <span class="lean-text">n</span> <span class="lean-text">=</span> <span class="lean-text">2</span><span class="lean-text">)</span><span class="lean-text">)</span>
  <span class="lean-keyword" data-docs="The `omega` tactic, for resolving integer and natural linear arithmetic problems.

It is not yet a full decision procedure (no &quot;dark&quot; or &quot;grey&quot; shadows),
but should be effective on many problems.

We handle hypotheses of the form `x = y`, `x &lt; y`, `x ≤ y`, and `k ∣ x` for `x y` in `Nat` or `Int`
(and `k` a literal), along with negations of these statements.

We decompose the sides of the inequalities as linear combinations of atoms.

If we encounter `x / k` or `x % k` for literal integers `k` we introduce new auxiliary variables
and the relevant inequalities.

On the first pass, we do not perform case splits on natural subtraction.
If `omega` fails, we recursively perform a case split on
a natural subtraction appearing in a hypothesis, and try again.

The options
```
omega +splitDisjunctions +splitNatSub +splitNatAbs +splitMinMax
```
can be used to:
* `splitDisjunctions`: split any disjunctions found in the context,
  if the problem is not otherwise solvable.
* `splitNatSub`: for each appearance of `((a - b : Nat) : Int)`, split on `a ≤ b` if necessary.
* `splitNatAbs`: for each appearance of `Int.natAbs a`, split on `0 ≤ a` if necessary.
* `splitMinMax`: for each occurrence of `min a b`, split on `min a b = a ∨ min a b = b`
Currently, all of these are on by default.
">omega</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/Lemmas.lean#L155-L165" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>

<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:prod-coprime-dvd">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">A.0.5</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0006.html#lem:prod-coprime-dvd">#</a>
    
    <a class="icon proof" href="sect0006.html#a0000000067"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Finset.prod_coprime_dvd" class="lean_decl">Finset.prod_coprime_dvd</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If each \(f(a)\) divides \(d\) and the \(f(a)\) are pairwise coprime, then \(\prod _{a \in S} f(a)\) divides \(d\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000067">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>By induction on the finite set. Empty case: \(1 \mid d\) trivially. Insert case: we have \(f(q) \mid d\) and \(\prod _{s'} f(r) \mid d\) by IH. Show \(f(q)\) is coprime to \(\prod _{s'} f(r)\) using ‘Nat.Coprime.prod_right‘, then apply ‘Nat.Coprime.mul_dvd_of_dvd_of_dvd‘. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-docstring">/-- If each f(a) divides d and they&#x27;re pairwise coprime, then ∏ f(a) divides d. -/</span>
<span class="lean-text">@[</span><span class="lean-keyword" data-docs="The `blueprint` attribute tags a constant to add to the blueprint.

You may optionally add:
- `&quot;latex-label&quot;`: The LaTeX label to use for the node (default: the Lean name).
- `statement := /-- ... -/`: The statement of the node in LaTeX.
- `hasProof := true`: If the node has a proof part (default: true if the node is a theorem).
- `proof := /-- ... -/`: The proof of the node in LaTeX (default: the docstrings in proof tactics).
- `uses := [a, &quot;b&quot;]`: The dependencies of the node, as Lean constants or LaTeX labels (default: inferred from the used constants).
- `proofUses := [a, &quot;b&quot;]`: The dependencies of the proof of the node, as Lean constants or LaTeX labels (default: inferred from the used constants).
- `title := /-- Title -/`: The title of the node in LaTeX.
- `notReady := true`: Whether the node is not ready.
- `discussion := 123`: The discussion issue number of the node.
- `latexEnv := &quot;lemma&quot;`: The LaTeX environment to use for the node (default: &quot;theorem&quot; or &quot;definition&quot;).

For more information, see [LeanArchitect](https://github.com/hanwenzhu/LeanArchitect).

Use `blueprint?` to show the raw data of the added node.
">blueprint</span> <span class="lean-string">&quot;lem:prod-coprime-dvd&quot;</span>
  <span class="lean-text">(</span><span class="lean-keyword">statement</span> <span class="lean-text">:=</span> <span class="lean-docstring">/-- If each $f(a)$ divides $d$ and the $f(a)$ are pairwise coprime,
  then $\prod_{a \in S} f(a)$ divides $d$. -/</span><span class="lean-text">)</span>
  <span class="lean-text">(</span><span class="lean-keyword">proof</span> <span class="lean-text">:=</span> <span class="lean-docstring">/-- By induction on the finite set. Empty case: $1 \mid d$ trivially.
  Insert case: we have $f(q) \mid d$ and $\prod_{s&#x27;} f(r) \mid d$ by IH.
  Show $f(q)$ is coprime to $\prod_{s&#x27;} f(r)$ using `Nat.Coprime.prod_right`,
  then apply `Nat.Coprime.mul_dvd_of_dvd_of_dvd`. -/</span><span class="lean-text">)</span><span class="lean-text">]</span>
<span class="lean-keyword">theorem</span> <span class="lean-text">prod_coprime_dvd</span></code><code class="lean-proof-body"> <span class="lean-text">{</span><span class="lean-text">α</span> <span class="lean-text">:</span> <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-text">}</span> <span class="lean-text">[</span><span class="lean-text">DecidableEq</span> <span class="lean-text">α</span><span class="lean-text">]</span> <span class="lean-text">(</span><span class="lean-text">S</span> <span class="lean-text">:</span> <span class="lean-text">Finset</span> <span class="lean-text">α</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">f</span> <span class="lean-text">:</span> <span class="lean-text">α</span> <span class="lean-text">→</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">d</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span>
    <span class="lean-text">(</span><span class="lean-text">h_dvd</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">a</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">f</span> <span class="lean-text">a</span> <span class="lean-text">∣</span> <span class="lean-text">d</span><span class="lean-text">)</span>
    <span class="lean-text">(</span><span class="lean-text">h_coprime</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">a₁</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">∀</span> <span class="lean-text">a₂</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">a₁</span> <span class="lean-text">≠</span> <span class="lean-text">a₂</span> <span class="lean-text">→</span> <span class="lean-text">(</span><span class="lean-text">f</span> <span class="lean-text">a₁</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">Coprime</span> <span class="lean-text">(</span><span class="lean-text">f</span> <span class="lean-text">a₂</span><span class="lean-text">)</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">(</span><span class="lean-text">∏</span> <span class="lean-text">a</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">f</span> <span class="lean-text">a</span><span class="lean-text">)</span> <span class="lean-text">∣</span> <span class="lean-text">d</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
">induction</span> <span class="lean-text">S</span> <span class="lean-keyword">using</span> <span class="lean-text">Finset.induction</span> <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
">with</span>
  <span class="lean-text">|</span> <span class="lean-text">empty</span> <span class="lean-text">=&gt;</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span>
  <span class="lean-text">|</span> <span class="lean-text">@</span><span class="lean-text">insert</span> <span class="lean-text">q</span> <span class="lean-text">s&#x27;</span> <span class="lean-text">hq_notin</span> <span class="lean-text">IH</span> <span class="lean-text">=&gt;</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">Finset.prod_insert</span> <span class="lean-text">hq_notin</span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hq_dvd</span> <span class="lean-text">:</span> <span class="lean-text">f</span> <span class="lean-text">q</span> <span class="lean-text">∣</span> <span class="lean-text">d</span> <span class="lean-text">:=</span> <span class="lean-text">h_dvd</span> <span class="lean-text">q</span> <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_self</span> <span class="lean-text">q</span> <span class="lean-text">s&#x27;</span><span class="lean-text">)</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hs&#x27;_dvd</span> <span class="lean-text">:</span> <span class="lean-text">(</span><span class="lean-text">∏</span> <span class="lean-text">r</span> <span class="lean-text">∈</span> <span class="lean-text">s&#x27;</span><span class="lean-text">,</span> <span class="lean-text">f</span> <span class="lean-text">r</span><span class="lean-text">)</span> <span class="lean-text">∣</span> <span class="lean-text">d</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
      <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> <span class="lean-text">IH</span>
      <span class="lean-text">·</span> <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">r</span> <span class="lean-text">hr</span><span class="lean-text">;</span> <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">h_dvd</span> <span class="lean-text">r</span> <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_of_mem</span> <span class="lean-text">hr</span><span class="lean-text">)</span>
      <span class="lean-text">·</span> <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">a₁</span> <span class="lean-text">ha₁</span> <span class="lean-text">a₂</span> <span class="lean-text">ha₂</span> <span class="lean-text">hne</span>
        <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">h_coprime</span> <span class="lean-text">a₁</span> <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_of_mem</span> <span class="lean-text">ha₁</span><span class="lean-text">)</span> <span class="lean-text">a₂</span>
          <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_of_mem</span> <span class="lean-text">ha₂</span><span class="lean-text">)</span> <span class="lean-text">hne</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">h_cop</span> <span class="lean-text">:</span> <span class="lean-text">(</span><span class="lean-text">f</span> <span class="lean-text">q</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">Coprime</span> <span class="lean-text">(</span><span class="lean-text">∏</span> <span class="lean-text">r</span> <span class="lean-text">∈</span> <span class="lean-text">s&#x27;</span><span class="lean-text">,</span> <span class="lean-text">f</span> <span class="lean-text">r</span><span class="lean-text">)</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
      <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> <span class="lean-text">Nat.Coprime.prod_right</span>
      <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">r</span> <span class="lean-text">hr</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hne</span> <span class="lean-text">:</span> <span class="lean-text">q</span> <span class="lean-text">≠</span> <span class="lean-text">r</span> <span class="lean-text">:=</span> <span class="lean-keyword">fun</span> <span class="lean-text">heq</span> <span class="lean-text">=&gt;</span> <span class="lean-text">hq_notin</span> <span class="lean-text">(</span><span class="lean-text">heq</span> <span class="lean-text">▸</span> <span class="lean-text">hr</span><span class="lean-text">)</span>
      <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">h_coprime</span> <span class="lean-text">q</span> <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_self</span> <span class="lean-text">q</span> <span class="lean-text">s&#x27;</span><span class="lean-text">)</span> <span class="lean-text">r</span>
        <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_of_mem</span> <span class="lean-text">hr</span><span class="lean-text">)</span> <span class="lean-text">hne</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">h_cop.mul_dvd_of_dvd_of_dvd</span> <span class="lean-text">hq_dvd</span> <span class="lean-text">hs&#x27;_dvd</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/Lemmas.lean#L173-L202" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>

<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:totient-prod-coprime">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">A.0.6</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0006.html#lem:totient-prod-coprime">#</a>
    
    <a class="icon proof" href="sect0006.html#a0000000068"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Nat.totient_finset_prod_of_coprime" class="lean_decl">Nat.totient_finset_prod_of_coprime</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       For pairwise coprime \(\{ f(a)\} _{a \in S}\), we have \(\varphi (\prod _{a \in S} f(a)) = \prod _{a \in S} \varphi (f(a))\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000068">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>By induction on the finite set. Empty case: \(\varphi (1) = 1\) equals empty product. Insert case: use \(\varphi (ab) = \varphi (a)\varphi (b)\) for coprime \(a, b\) (‘Nat.totient_mul‘), where coprimality follows from ‘Nat.Coprime.prod_right‘. </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-docstring">/-- Euler&#x27;s totient function distributes over products of pairwise coprime values.

This generalizes `Nat.totient_mul` from binary products to arbitrary finite products.
The proof proceeds by induction: at each step, we use that the new element is coprime
to the product of the previous elements (via `Nat.Coprime.prod_right`), then apply
the binary `Nat.totient_mul`.

For upstreaming to Mathlib, this should be placed in `Mathlib.Data.Nat.Totient`. -/</span>
<span class="lean-text">@[</span><span class="lean-keyword" data-docs="The `blueprint` attribute tags a constant to add to the blueprint.

You may optionally add:
- `&quot;latex-label&quot;`: The LaTeX label to use for the node (default: the Lean name).
- `statement := /-- ... -/`: The statement of the node in LaTeX.
- `hasProof := true`: If the node has a proof part (default: true if the node is a theorem).
- `proof := /-- ... -/`: The proof of the node in LaTeX (default: the docstrings in proof tactics).
- `uses := [a, &quot;b&quot;]`: The dependencies of the node, as Lean constants or LaTeX labels (default: inferred from the used constants).
- `proofUses := [a, &quot;b&quot;]`: The dependencies of the proof of the node, as Lean constants or LaTeX labels (default: inferred from the used constants).
- `title := /-- Title -/`: The title of the node in LaTeX.
- `notReady := true`: Whether the node is not ready.
- `discussion := 123`: The discussion issue number of the node.
- `latexEnv := &quot;lemma&quot;`: The LaTeX environment to use for the node (default: &quot;theorem&quot; or &quot;definition&quot;).

For more information, see [LeanArchitect](https://github.com/hanwenzhu/LeanArchitect).

Use `blueprint?` to show the raw data of the added node.
">blueprint</span> <span class="lean-string">&quot;lem:totient-prod-coprime&quot;</span>
  <span class="lean-text">(</span><span class="lean-keyword">statement</span> <span class="lean-text">:=</span> <span class="lean-docstring">/-- For pairwise coprime $\{f(a)\}_{a \in S}$, we have
  $\varphi(\prod_{a \in S} f(a)) = \prod_{a \in S} \varphi(f(a))$. -/</span><span class="lean-text">)</span>
  <span class="lean-text">(</span><span class="lean-keyword">proof</span> <span class="lean-text">:=</span> <span class="lean-docstring">/-- By induction on the finite set. Empty case: $\varphi(1) = 1$ equals empty product.
  Insert case: use $\varphi(ab) = \varphi(a)\varphi(b)$ for coprime $a, b$
  (`Nat.totient_mul`), where coprimality follows from `Nat.Coprime.prod_right`. -/</span><span class="lean-text">)</span><span class="lean-text">]</span>
<span class="lean-keyword">theorem</span> <span class="lean-text">totient_finset_prod_of_coprime</span></code><code class="lean-proof-body"> <span class="lean-text">{</span><span class="lean-text">α</span> <span class="lean-text">:</span> <span class="lean-keyword" data-docs="The syntax `variable (X Y ... Z : Type*)` creates a new distinct implicit universe variable
`&gt; 0` for each variable in the sequence. ">Type*</span><span class="lean-text">}</span> <span class="lean-text">[</span><span class="lean-text">DecidableEq</span> <span class="lean-text">α</span><span class="lean-text">]</span> <span class="lean-text">(</span><span class="lean-text">S</span> <span class="lean-text">:</span> <span class="lean-text">Finset</span> <span class="lean-text">α</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">f</span> <span class="lean-text">:</span> <span class="lean-text">α</span> <span class="lean-text">→</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span>
    <span class="lean-text">(</span><span class="lean-text">h_coprime</span> <span class="lean-text">:</span> <span class="lean-text">∀</span> <span class="lean-text">a₁</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">∀</span> <span class="lean-text">a₂</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">a₁</span> <span class="lean-text">≠</span> <span class="lean-text">a₂</span> <span class="lean-text">→</span> <span class="lean-text">(</span><span class="lean-text">f</span> <span class="lean-text">a₁</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">Coprime</span> <span class="lean-text">(</span><span class="lean-text">f</span> <span class="lean-text">a₂</span><span class="lean-text">)</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">Nat.totient</span> <span class="lean-text">(</span><span class="lean-text">∏</span> <span class="lean-text">a</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">f</span> <span class="lean-text">a</span><span class="lean-text">)</span> <span class="lean-text">=</span> <span class="lean-text">∏</span> <span class="lean-text">a</span> <span class="lean-text">∈</span> <span class="lean-text">S</span><span class="lean-text">,</span> <span class="lean-text">Nat.totient</span> <span class="lean-text">(</span><span class="lean-text">f</span> <span class="lean-text">a</span><span class="lean-text">)</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  <span class="lean-keyword" data-docs="Assuming `x` is a variable in the local context with an inductive type,
`induction x` applies induction on `x` to the main goal,
producing one goal for each constructor of the inductive type,
in which the target is replaced by a general instance of that constructor
and an inductive hypothesis is added for each recursive argument to the constructor.
If the type of an element in the local context depends on `x`,
that element is reverted and reintroduced afterward,
so that the inductive hypothesis incorporates that hypothesis as well.

For example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,
`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,
and one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.
Here the names `a` and `ih₁` are chosen automatically and are not accessible.
You can use `with` to provide the variables names for each constructor.
- `induction e`, where `e` is an expression instead of a variable,
  generalizes `e` in the goal, and then performs induction on the resulting variable.
- `induction e using r` allows the user to specify the principle of induction that should be used.
  Here `r` should be a term whose result type must be of the form `C t`,
  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables
- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,
  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.
  In other words, the net effect is that each inductive hypothesis is generalized.
- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x&#x27; ih =&gt; tac₂`
  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.
">induction</span> <span class="lean-text">S</span> <span class="lean-keyword">using</span> <span class="lean-text">Finset.induction</span> <span class="lean-keyword" data-docs="After `with`, there is an optional tactic that runs on all branches, and
then a list of alternatives.
">with</span>
  <span class="lean-text">|</span> <span class="lean-text">empty</span> <span class="lean-text">=&gt;</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span>
  <span class="lean-text">|</span> <span class="lean-text">@</span><span class="lean-text">insert</span> <span class="lean-text">q</span> <span class="lean-text">s&#x27;</span> <span class="lean-text">hq_notin</span> <span class="lean-text">IH</span> <span class="lean-text">=&gt;</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">Finset.prod_insert</span> <span class="lean-text">hq_notin</span><span class="lean-text">,</span> <span class="lean-text">Finset.prod_insert</span> <span class="lean-text">hq_notin</span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">h_cop_q_s</span> <span class="lean-text">:</span> <span class="lean-text">(</span><span class="lean-text">f</span> <span class="lean-text">q</span><span class="lean-text">)</span><span class="lean-text">.</span><span class="lean-text">Coprime</span> <span class="lean-text">(</span><span class="lean-text">∏</span> <span class="lean-text">r</span> <span class="lean-text">∈</span> <span class="lean-text">s&#x27;</span><span class="lean-text">,</span> <span class="lean-text">f</span> <span class="lean-text">r</span><span class="lean-text">)</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
      <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> <span class="lean-text">Nat.Coprime.prod_right</span>
      <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">r</span> <span class="lean-text">hr</span>
      <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hne</span> <span class="lean-text">:</span> <span class="lean-text">q</span> <span class="lean-text">≠</span> <span class="lean-text">r</span> <span class="lean-text">:=</span> <span class="lean-keyword">fun</span> <span class="lean-text">heq</span> <span class="lean-text">=&gt;</span> <span class="lean-text">hq_notin</span> <span class="lean-text">(</span><span class="lean-text">heq</span> <span class="lean-text">▸</span> <span class="lean-text">hr</span><span class="lean-text">)</span>
      <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">h_coprime</span> <span class="lean-text">q</span> <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_self</span> <span class="lean-text">q</span> <span class="lean-text">s&#x27;</span><span class="lean-text">)</span> <span class="lean-text">r</span>
        <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_of_mem</span> <span class="lean-text">hr</span><span class="lean-text">)</span> <span class="lean-text">hne</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">Nat.totient_mul</span> <span class="lean-text">h_cop_q_s</span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="Apply congruence (recursively) to goals of the form `⊢ f as = f bs` and `⊢ f as ≍ f bs`.
The optional parameter is the depth of the recursive applications.
This is useful when `congr` is too aggressive in breaking down the goal.
For example, given `⊢ f (g (x + y)) = f (g (y + x))`,
`congr` produces the goals `⊢ x = y` and `⊢ y = x`,
while `congr 2` produces the intended `⊢ x + y = y + x`.
">congr</span> <span class="lean-text">1</span>
    <span class="lean-keyword" data-docs="`apply e` tries to match the current goal against the conclusion of `e`&#x27;s type.
If it succeeds, then the tactic returns as many subgoals as the number of premises that
have not been fixed by type inference or type class resolution.
Non-dependent premises are added before dependent ones.

The `apply` tactic uses higher-order pattern matching, type class resolution,
and first-order unification with dependent types.
">apply</span> <span class="lean-text">IH</span>
    <span class="lean-keyword" data-docs="Introduces one or more hypotheses, optionally naming and/or pattern-matching them.
For each hypothesis to be introduced, the remaining main goal&#x27;s target type must
be a `let` or function type.

* `intro` by itself introduces one anonymous hypothesis, which can be accessed
  by e.g. `assumption`. It is equivalent to `intro _`.
* `intro x y` introduces two hypotheses and names them. Individual hypotheses
  can be anonymized via `_`, given a type ascription, or matched against a pattern:
  ```lean
  -- ... ⊢ α × β → ...
  intro (a, b)
  -- ..., a : α, b : β ⊢ ...
  ```
* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side
  is a variable.
* Alternatively, `intro` can be combined with pattern matching much like `fun`:
  ```lean
  intro
  | n + 1, 0 =&gt; tac
  | ...
  ```
">intro</span> <span class="lean-text">a₁</span> <span class="lean-text">ha₁</span> <span class="lean-text">a₂</span> <span class="lean-text">ha₂</span> <span class="lean-text">hne</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">h_coprime</span> <span class="lean-text">a₁</span> <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_of_mem</span> <span class="lean-text">ha₁</span><span class="lean-text">)</span> <span class="lean-text">a₂</span>
      <span class="lean-text">(</span><span class="lean-text">Finset.mem_insert_of_mem</span> <span class="lean-text">ha₂</span><span class="lean-text">)</span> <span class="lean-text">hne</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/Lemmas.lean#L210-L242" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>

<div class="theorem_thmwrapper sbs-container theorem-style-definition" id="lem:orderOf-neg-of-odd-order">
  <div class="sbs-latex-column">
    <div class="theorem_thmheading">
      <span class="theorem_thmcaption">
      Theorem
      </span>
      <span class="theorem_thmlabel">A.0.7</span>
      <div class="thm_header_extras">

    
    ✓
          </div>
      <div class="thm_header_hidden_extras">

    <a class="icon proof" href="sect0006.html#lem:orderOf-neg-of-odd-order">#</a>
    
    <a class="icon proof" href="sect0006.html#a0000000069"><svg  class="icon icon-cogs "><use xlink:href="symbol-defs.svg#icon-cogs"></use></svg>
</a>
    
    
    
    <button class="modal lean">L∃∀N</button>
        <div class="modal-container">
      <div class="modal-content">
        <header>
          <h1>Lean declarations</h1>
          <button class="closebtn"><svg  class="icon icon-cross "><use xlink:href="symbol-defs.svg#icon-cross"></use></svg>
</button>
        </header>
        
        <ul class="uses">
          
          <li><a href="https://e-vergo.github.io/General_Crystallographic_Restriction/docs/find/#doc/Crystallographic.orderOf_neg_of_odd_order" class="lean_decl">Crystallographic.orderOf_neg_of_odd_order</a></li>
          
        </ul>
    
      </div>
    </div>

    
          </div>
    </div>
    <div class="theorem_thmcontent">
    <p>       If \(A\) has odd order \(k\), then \(-A\) has order \(2k\). </p>

    </div>
    <div class="proof_wrapper proof_inline" id="a0000000069">
      <div class="proof_heading">
        <span class="proof_caption">
        Proof
        </span>
        <span class="expand-proof">▶</span>
      </div>
      <div class="proof_content">
      <p>We have \(-A = (-1) \cdot A\) where \(-1\) commutes with \(A\). In characteristic \(0\), the order of \(-1\) is \(2\). Since \(k\) is odd, \(\gcd (2, k) = 1\), so by the product formula for commuting elements with coprime orders, the order of \(-A\) equals the order of \(-1\) times the order of \(A\), which is \(2k\). </p>

      </div>
    </div>
  </div>
  <div class="sbs-lean-column">
    <pre class="lean-code"><code class="lean-signature"><span class="lean-docstring">/-- If A has odd order k in a matrix ring over Z, then -A has order 2*k.
This uses orderOf(-1) = 2 (in char 0), commutativity of -1 with A,
and gcd(2, k) = 1 for odd k. -/</span>
<span class="lean-text">@[</span><span class="lean-keyword" data-docs="The `blueprint` attribute tags a constant to add to the blueprint.

You may optionally add:
- `&quot;latex-label&quot;`: The LaTeX label to use for the node (default: the Lean name).
- `statement := /-- ... -/`: The statement of the node in LaTeX.
- `hasProof := true`: If the node has a proof part (default: true if the node is a theorem).
- `proof := /-- ... -/`: The proof of the node in LaTeX (default: the docstrings in proof tactics).
- `uses := [a, &quot;b&quot;]`: The dependencies of the node, as Lean constants or LaTeX labels (default: inferred from the used constants).
- `proofUses := [a, &quot;b&quot;]`: The dependencies of the proof of the node, as Lean constants or LaTeX labels (default: inferred from the used constants).
- `title := /-- Title -/`: The title of the node in LaTeX.
- `notReady := true`: Whether the node is not ready.
- `discussion := 123`: The discussion issue number of the node.
- `latexEnv := &quot;lemma&quot;`: The LaTeX environment to use for the node (default: &quot;theorem&quot; or &quot;definition&quot;).

For more information, see [LeanArchitect](https://github.com/hanwenzhu/LeanArchitect).

Use `blueprint?` to show the raw data of the added node.
">blueprint</span> <span class="lean-string">&quot;lem:orderOf-neg-of-odd-order&quot;</span>
  <span class="lean-text">(</span><span class="lean-keyword">statement</span> <span class="lean-text">:=</span> <span class="lean-docstring">/-- If $A$ has odd order $k$, then $-A$ has order $2k$. -/</span><span class="lean-text">)</span>
  <span class="lean-text">(</span><span class="lean-keyword">proof</span> <span class="lean-text">:=</span> <span class="lean-docstring">/-- We have $-A = (-1) \cdot A$ where $-1$ commutes with $A$.
  In characteristic $0$, the order of $-1$ is $2$. Since $k$ is odd,
  $\gcd(2, k) = 1$, so by the product formula for commuting elements with
  coprime orders, the order of $-A$ equals the order of $-1$ times the order of $A$, which is $2k$. -/</span><span class="lean-text">)</span><span class="lean-text">]</span>
<span class="lean-keyword">theorem</span> <span class="lean-text">orderOf_neg_of_odd_order</span></code><code class="lean-proof-body"> <span class="lean-text">{</span><span class="lean-text">n</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">}</span> <span class="lean-text">[</span><span class="lean-text">NeZero</span> <span class="lean-text">n</span><span class="lean-text">]</span> <span class="lean-text">(</span><span class="lean-text">k</span> <span class="lean-text">:</span> <span class="lean-text">ℕ</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hk_odd</span> <span class="lean-text">:</span> <span class="lean-text">Odd</span> <span class="lean-text">k</span><span class="lean-text">)</span>
    <span class="lean-text">(</span><span class="lean-text">A</span> <span class="lean-text">:</span> <span class="lean-text">Matrix</span> <span class="lean-text">(</span><span class="lean-text">Fin</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">Fin</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">ℤ</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">hA_ord</span> <span class="lean-text">:</span> <span class="lean-text">orderOf</span> <span class="lean-text">A</span> <span class="lean-text">=</span> <span class="lean-text">k</span><span class="lean-text">)</span> <span class="lean-text">:</span>
    <span class="lean-text">orderOf</span> <span class="lean-text">(</span><span class="lean-text">-</span><span class="lean-text">A</span><span class="lean-text">)</span> <span class="lean-text">=</span> <span class="lean-text">2</span> <span class="lean-text">*</span> <span class="lean-text">k</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
  -- Express -A as (-1) * A
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hneg_eq</span> <span class="lean-text">:</span> <span class="lean-text">-</span><span class="lean-text">A</span> <span class="lean-text">=</span> <span class="lean-text">(</span><span class="lean-text">-</span><span class="lean-text">1</span> <span class="lean-text">:</span> <span class="lean-text">Matrix</span> <span class="lean-text">(</span><span class="lean-text">Fin</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">Fin</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">ℤ</span><span class="lean-text">)</span> <span class="lean-text">*</span> <span class="lean-text">A</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span> <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">hneg_eq</span><span class="lean-text">]</span>
  -- -1 and A commute
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hcomm</span> <span class="lean-text">:</span> <span class="lean-text">Commute</span> <span class="lean-text">(</span><span class="lean-text">-</span><span class="lean-text">1</span> <span class="lean-text">:</span> <span class="lean-text">Matrix</span> <span class="lean-text">(</span><span class="lean-text">Fin</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">Fin</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">ℤ</span><span class="lean-text">)</span> <span class="lean-text">A</span> <span class="lean-text">:=</span> <span class="lean-text">Commute.neg_one_left</span> <span class="lean-text">A</span>
  -- orderOf(-1) = 2 in char 0
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hord_neg1</span> <span class="lean-text">:</span> <span class="lean-text">orderOf</span> <span class="lean-text">(</span><span class="lean-text">-</span><span class="lean-text">1</span> <span class="lean-text">:</span> <span class="lean-text">Matrix</span> <span class="lean-text">(</span><span class="lean-text">Fin</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">Fin</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">ℤ</span><span class="lean-text">)</span> <span class="lean-text">=</span> <span class="lean-text">2</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">orderOf_neg_one</span><span class="lean-text">,</span> <span class="lean-span lean-error" title="Unknown identifier `ringChar_matrix_int`"><span class="lean-text">ringChar_matrix_int</span></span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or
non-dependent hypotheses. It has many variants:
- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.
- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]` and the given `hᵢ`&#x27;s, where the `hᵢ`&#x27;s are expressions.-
- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated
  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.
- `simp [*]` simplifies the main goal target using the lemmas tagged with the
  attribute `[simp]` and all hypotheses.
- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.
- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged
  with the attribute `[simp]`, but removes the ones named `idᵢ`.
- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If
  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis
  `hᵢ` is introduced, but the old one remains in the local context.
- `simp at *` simplifies all the hypotheses and the target.
- `simp [*] at *` simplifies target and all (propositional) hypotheses using the
  other hypotheses.
">simp</span>
  -- Coprimality: gcd(2, k) = 1 since k is odd
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hcop</span> <span class="lean-text">:</span> <span class="lean-text">Nat.Coprime</span> <span class="lean-text">2</span> <span class="lean-text">k</span> <span class="lean-text">:=</span> <span class="lean-text">Nat.Coprime.symm</span> <span class="lean-text">(</span><span class="lean-text">Odd.coprime_two_right</span> <span class="lean-text">hk_odd</span><span class="lean-text">)</span>
  <span class="lean-keyword" data-docs="The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.
The definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.

* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.
* `have h := e` uses the type of `e` for `t`.
* `have : t := e` and `have := e` use `this` for the name of the hypothesis.
* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,
  where `_` stands for the tactics that follow this one.
  It is convenient for types that have only one applicable constructor.
  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the
  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.
* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,
  which adds the equation `h : e = pat` to the local context.

The tactic supports all the same syntax variants and options as the `have` term.

## Properties and relations

* It is not possible to unfold a variable introduced using `have`, since the definition&#x27;s value is forgotten.
  The `let` tactic introduces definitions that can be unfolded.
* The `have h : t := e` is like doing `let h : t := e; clear_value h`.
* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.
* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,
  which may be important for performance reasons.
    Consider using the equivalent `let +nondep` to indicate the intent.

">have</span> <span class="lean-text">hord_cop</span> <span class="lean-text">:</span> <span class="lean-text">Nat.Coprime</span> <span class="lean-text">(</span><span class="lean-text">orderOf</span> <span class="lean-text">(</span><span class="lean-text">-</span><span class="lean-text">1</span> <span class="lean-text">:</span> <span class="lean-text">Matrix</span> <span class="lean-text">(</span><span class="lean-text">Fin</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">Fin</span> <span class="lean-text">n</span><span class="lean-text">)</span> <span class="lean-text">ℤ</span><span class="lean-text">)</span><span class="lean-text">)</span> <span class="lean-text">(</span><span class="lean-text">orderOf</span> <span class="lean-text">A</span><span class="lean-text">)</span> <span class="lean-text">:=</span> <span class="lean-keyword" data-docs="`by tac` constructs a term of the expected type by running the tactic(s) `tac`. ">by</span>
    <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">hord_neg1</span><span class="lean-text">,</span> <span class="lean-text">hA_ord</span><span class="lean-text">]</span>
    <span class="lean-keyword" data-docs="`exact e` closes the main goal if its target type matches that of `e`.
">exact</span> <span class="lean-text">hcop</span>
  -- Apply the product formula
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">hcomm.orderOf_mul_eq_mul_orderOf_of_coprime</span> <span class="lean-text">hord_cop</span><span class="lean-text">]</span>
  <span class="lean-keyword" data-docs="`rw` is like `rewrite`, but also tries to close the goal by &quot;cheap&quot; (reducible) `rfl` afterwards.
">rw</span> <span class="lean-text">[</span><span class="lean-text">hord_neg1</span><span class="lean-text">,</span> <span class="lean-text">hA_ord</span><span class="lean-text">]</span></code></pre>
    <a href="https://github.com/e-vergo/General_Crystallographic_Restriction/blob/main/Crystallographic/Main/Lemmas.lean#L250-L278" class="lean-github-hover" target="_blank" title="View on GitHub"><svg  class="icon icon-github "><use xlink:href="symbol-defs.svg#icon-github"></use></svg>
</a>
  </div>
</div>


</div> <!--main-text -->
</div> <!-- content-wrapper -->
</div> <!-- content -->
</div> <!-- wrapper -->

<nav class="prev_up_next">
  <svg  id="showmore-minus" class="icon icon-eye-minus showmore"><use xlink:href="symbol-defs.svg#icon-eye-minus"></use></svg>

  <svg  id="showmore-plus" class="icon icon-eye-plus showmore"><use xlink:href="symbol-defs.svg#icon-eye-plus"></use></svg>

  <a href="sect0005.html" title="The Crystallographic Restriction Theorem"><svg  class="icon icon-arrow-left "><use xlink:href="symbol-defs.svg#icon-arrow-left"></use></svg>
</a>
  <a href="index.html" title="Crystallographic Restriction Theorem"><svg  class="icon icon-arrow-up "><use xlink:href="symbol-defs.svg#icon-arrow-up"></use></svg>
</a>
</nav>

<script type="text/javascript" src="js/jquery.min.js"></script>
<script type="text/javascript" src="js/plastex.js"></script>
<script type="text/javascript" src="js/svgxuse.js"></script>
<script type="text/javascript" src="js/js.cookie.min.js"></script>
<script type="text/javascript" src="js/showmore.js"></script>
</body>
</html>